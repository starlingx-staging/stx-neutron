From 4a42482fbd8f631a8ee79f5642d7abb26ec59aa3 Mon Sep 17 00:00:00 2001
From: Forrest <forrest.zhao@intel.com>
Date: Tue, 10 Apr 2018 09:56:38 +0800
Subject: [PATCH 150/155] Remove AVS code from Neutron

Signed-off-by: Forrest <forrest.zhao@intel.com>
---
 neutron/agent/vswitch/api.py                       |    2 +-
 neutron/agent/vswitch/manager.py                   |   32 +-
 neutron/api/rpc/handlers/securitygroups_rpc.py     |   40 +-
 neutron/common/constants.py                        |    4 +-
 neutron/conf/agent/securitygroups_rpc.py           |   17 +-
 .../alembic_migrations/versions/CONTRACT_HEAD      |    2 +-
 ...cgts_7354_pci_passthrough_fix_vnic_vif_types.py |   51 -
 neutron/db/securitygroups_rpc_base.py              |   10 -
 neutron/extensions/wrs_binding.py                  |   11 +-
 neutron/extensions/wrs_net.py                      |    8 +-
 neutron/extensions/wrs_provider.py                 |   12 +-
 neutron/extensions/wrs_tm.py                       |    4 +-
 neutron/opts.py                                    |   14 -
 neutron/pecan_wsgi/app.py                          |    1 -
 neutron/pecan_wsgi/hooks/__init__.py               |    2 -
 neutron/pecan_wsgi/hooks/wrs_fields.py             |   65 -
 neutron/plugins/ml2/plugin.py                      |    3 +-
 neutron/plugins/wrs/agent/avr/__init__.py          |    1 +
 neutron/plugins/wrs/agent/avr/agent.py             | 1437 -----------
 neutron/plugins/wrs/agent/avs/__init__.py          |    1 +
 neutron/plugins/wrs/agent/avs/agent.py             | 2612 --------------------
 neutron/plugins/wrs/agent/avs/dvr.py               |  299 ---
 neutron/plugins/wrs/agent/avs/sfc.py               |  113 -
 neutron/plugins/wrs/drivers/firewall.py            |  174 --
 neutron/plugins/wrs/drivers/fm.py                  |   53 -
 setup.cfg                                          |    1 -
 26 files changed, 36 insertions(+), 4933 deletions(-)
 delete mode 100644 neutron/db/migration/alembic_migrations/versions/wrs_newton/contract/cgts_7354_pci_passthrough_fix_vnic_vif_types.py
 delete mode 100644 neutron/pecan_wsgi/hooks/wrs_fields.py
 delete mode 100644 neutron/plugins/wrs/drivers/firewall.py

diff --git a/neutron/agent/vswitch/api.py b/neutron/agent/vswitch/api.py
index 29e3995..6de054e 100644
--- a/neutron/agent/vswitch/api.py
+++ b/neutron/agent/vswitch/api.py
@@ -15,7 +15,7 @@
 #
 
 #
-# Copyright (c) 2013-2017 Wind River Systems, Inc.
+# Copyright (c) 2013-2016 Wind River Systems, Inc.
 #
 # The right to copy, distribute, modify, or otherwise make use
 # of this software may be licensed only pursuant to the terms
diff --git a/neutron/agent/vswitch/manager.py b/neutron/agent/vswitch/manager.py
index ba37cc2..4d6ed2c 100644
--- a/neutron/agent/vswitch/manager.py
+++ b/neutron/agent/vswitch/manager.py
@@ -13,7 +13,7 @@
 #    License for the specific language governing permissions and limitations
 #    under the License.
 #
-# Copyright (c) 2013-2017 Wind River Systems, Inc.
+# Copyright (c) 2013-2016 Wind River Systems, Inc.
 #
 # The right to copy, distribute, modify, or otherwise make use
 # of this software may be licensed only pursuant to the terms
@@ -1246,7 +1246,9 @@ class VSwitchManager(object):
         """
         try:
             return self.api.delete_snat_entry(interface_uuid,
-                src_address, src_port, self._convert_protocol_to_avs(protocol))
+                                              src_address,
+                                              src_port,
+                                              protocol)
         except exceptions.VSwitchError as e:
             msg = ("Failed to delete static SNAT entry {}:{} {} on {}: {}".
                    format(src_address, src_port, protocol, interface_uuid, e))
@@ -1329,9 +1331,9 @@ class VSwitchManager(object):
         Adds a VTEP endpoint entry to direct traffic destined to a given MAC to
         the IP address of a remote VTEP instance.
         """
-        endpoint = {'mac-address': mac_address,
-                    'peer-address': ip_address}
         try:
+            endpoint = {'mac-address': mac_address,
+                        'peer-address': ip_address}
             return self.api.add_vtep_endpoint(interface_uuid, endpoint)
         except exceptions.VSwitchError as e:
             msg = ("Failed to add static VTEP endpoint {}: {}".format(
@@ -1349,7 +1351,7 @@ class VSwitchManager(object):
                    format(mac_address, interface_uuid, e))
             raise VSwitchManagerError(msg)
 
-    def get_vtep_endpoints(self, interface_uuid, static=None):
+    def get_vtep_endpoints(self, interface_uuid, static=True):
         """
         Retrieves the current list of VTEP endpoints.
         """
@@ -1371,10 +1373,10 @@ class VSwitchManager(object):
         """
         try:
             peer = {'address': ip_address}
-            return self.api.add_vtep_peer(interface_uuid, peer)
+            return self.api.add_peer(interface_uuid, peer)
         except exceptions.VSwitchError as e:
-            msg = ("Failed to add VTEP peer {}: {}".format(
-                ip_address, e))
+            msg = ("Failed to add static VTEP peer {}: {}".format(
+                peer, e))
             raise VSwitchManagerError(msg)
 
     def delete_vtep_peer(self, interface_uuid, ip_address):
@@ -1382,9 +1384,9 @@ class VSwitchManager(object):
         Removes a VTEP peer entry.
         """
         try:
-            return self.api.delete_vtep_peer(interface_uuid, ip_address)
+            return self.api.delete_peer(interface_uuid, ip_address)
         except exceptions.VSwitchError as e:
-            msg = ("Failed to delete VTEP peer {} from {}: {}".
+            msg = ("Failed to delete static VTEP endpoint {} on {}: {}".
                    format(ip_address, interface_uuid, e))
             raise VSwitchManagerError(msg)
 
@@ -1393,22 +1395,20 @@ class VSwitchManager(object):
         Retrieves the current list of VTEP endpoints.
         """
         try:
-            return self.api.get_vtep_peer_list(interface_uuid)
+            return self.api.get_peers(interface_uuid)
         except exceptions.VSwitchError as e:
             msg = ("Failed to query VTEP peer list for {}, {}".
                    format(interface_uuid, e))
             raise VSwitchManagerError(msg)
 
-    def add_vtep_ip_endpoint(self, interface_uuid, ip_address,
-                             mac_address, peer_address):
+    def add_vtep_ip_endpoint(self, interface_uuid, ip_address, peer_address):
         """
         Adds a VTEP IP endpoint entry to direct traffic destined to a given
         device IP address to a specific remote VTEP instance.
         """
-        endpoint = {'mac-address': mac_address,
-                    'device-address': ip_address,
-                    'peer-address': peer_address}
         try:
+            endpoint = {'device-address': ip_address,
+                        'peer-address': peer_address}
             return self.api.add_vtep_ip_endpoint(interface_uuid, endpoint)
         except exceptions.VSwitchError as e:
             msg = ("Failed to add static VTEP IP endpoint {}: {}".format(
diff --git a/neutron/api/rpc/handlers/securitygroups_rpc.py b/neutron/api/rpc/handlers/securitygroups_rpc.py
index 670d33e..44d0ecf 100644
--- a/neutron/api/rpc/handlers/securitygroups_rpc.py
+++ b/neutron/api/rpc/handlers/securitygroups_rpc.py
@@ -14,11 +14,8 @@
 
 import collections
 
-import eventlet
-
 from neutron_lib.plugins import directory
 from neutron_lib.utils import net
-from oslo_config import cfg
 from oslo_log import log as logging
 import oslo_messaging
 
@@ -28,14 +25,10 @@ from neutron.callbacks import registry
 from neutron.common import constants
 from neutron.common import rpc as n_rpc
 from neutron.common import topics
-from neutron.conf.agent import securitygroups_rpc as sc_cfg
 from neutron.db import securitygroups_rpc_base as sg_rpc_base
 
-
 LOG = logging.getLogger(__name__)
 
-sc_cfg.register_securitygroups_opts()
-
 
 class SecurityGroupServerRpcApi(object):
     """RPC client for security group methods in the plugin.
@@ -140,9 +133,6 @@ class SecurityGroupAgentRpcApiMixin(object):
     #   1.1 Support Security Group RPC
     SG_RPC_VERSION = "1.1"
 
-    defer_notify_suppress = False
-    defer_notify_delay = cfg.CONF.SECURITYGROUP.notify_interval
-
     def _get_security_group_topic(self):
         return topics.get_topic_name(self.topic,
                                      topics.SECURITY_GROUP,
@@ -168,8 +158,8 @@ class SecurityGroupAgentRpcApiMixin(object):
         cctxt.cast(context, 'security_groups_member_updated',
                    security_groups=security_groups)
 
-    def _security_groups_provider_updated(self, context,
-                                          devices_to_update=None):
+    def security_groups_provider_updated(self, context,
+                                         devices_to_update=None):
         """Notify provider updated security groups."""
         # TODO(kevinbenton): remove in Queens
         # NOTE(ihrachys) the version here should really be 1.3, but since we
@@ -187,32 +177,6 @@ class SecurityGroupAgentRpcApiMixin(object):
         cctxt.cast(context, 'security_groups_provider_updated',
                    devices_to_update=devices_to_update)
 
-    def security_groups_provider_updated(self, context,
-                                         devices_to_update=None):
-        """Notify provider updated security groups."""
-        if not self.defer_notify_delay:
-            self._security_groups_provider_updated(
-                context, devices_to_update=devices_to_update)
-            return
-        # defer the notification, subsequent calls will not be sent
-        # until the previous notification has completed
-        if not self.defer_notify_suppress:
-            self.defer_notify_suppress = True
-            LOG.debug("spawning deferred security_groups_provider_updated")
-            try:
-                eventlet.spawn_after(self.defer_notify_delay,
-                                     self._security_groups_provider_updated,
-                                     context,
-                                     devices_to_update=devices_to_update)
-            except Exception:
-                LOG.error("failed to spawn "
-                          "security_groups_provider_updated thread")
-                self._security_groups_provider_updated(
-                    context, devices_to_update=devices_to_update)
-                self.defer_notify_suppress = False
-        else:
-            LOG.debug("suppressing security_groups_provider_updated")
-
 
 class SecurityGroupAgentRpcCallbackMixin(object):
     """A mix-in that enable SecurityGroup support in agent implementations.
diff --git a/neutron/common/constants.py b/neutron/common/constants.py
index 2e010f1..452504a 100644
--- a/neutron/common/constants.py
+++ b/neutron/common/constants.py
@@ -280,6 +280,8 @@ PROVIDERNET_GRE = 'gre'
 
 PROVIDERNET_VXLAN_DYNAMIC = 'dynamic'
 PROVIDERNET_VXLAN_STATIC = 'static'
+PROVIDERNET_VXLAN_EVPN = 'evpn'
+# TODO(alegacy): add evpn to valid list.
 PROVIDERNET_VXLAN_MODES = [PROVIDERNET_VXLAN_DYNAMIC,
                            PROVIDERNET_VXLAN_STATIC]
 
@@ -342,5 +344,3 @@ NONE_VLAN_TAG = 0
 
 # PCI-Passthrough support
 PORT_STATUS_UNKNOWN = 'UNKNOWN'
-
-WRS_FIELD_PREFIX = 'wrs-'
diff --git a/neutron/conf/agent/securitygroups_rpc.py b/neutron/conf/agent/securitygroups_rpc.py
index 17a11fd..b49592e 100644
--- a/neutron/conf/agent/securitygroups_rpc.py
+++ b/neutron/conf/agent/securitygroups_rpc.py
@@ -13,12 +13,6 @@
 #    License for the specific language governing permissions and limitations
 #    under the License.
 #
-# Copyright (c) 2013-2014,2017 Wind River Systems, Inc.
-#
-# The right to copy, distribute, modify, or otherwise make use
-# of this software may be licensed only pursuant to the terms
-# of an applicable Wind River license agreement.
-#
 
 
 from oslo_config import cfg
@@ -42,16 +36,7 @@ security_group_opts = [
         default=True,
         help=_('Use ipset to speed-up the iptables based security groups. '
                'Enabling ipset support requires that ipset is installed on L2 '
-               'agent node.')),
-    cfg.BoolOpt(
-        'ensure_default_security_group',
-        default=True,
-        help=_("Enable/Disable association of default security group "
-               "on port during port creation")),
-    cfg.IntOpt(
-        'notify_interval',
-        default=0,
-        help=_('Throttled firewall rule update notification interval')),
+               'agent node.'))
 ]
 
 
diff --git a/neutron/db/migration/alembic_migrations/versions/CONTRACT_HEAD b/neutron/db/migration/alembic_migrations/versions/CONTRACT_HEAD
index bd414f1..b0d0e20 100644
--- a/neutron/db/migration/alembic_migrations/versions/CONTRACT_HEAD
+++ b/neutron/db/migration/alembic_migrations/versions/CONTRACT_HEAD
@@ -1 +1 @@
-cgts_7354
+5c85685d616d
diff --git a/neutron/db/migration/alembic_migrations/versions/wrs_newton/contract/cgts_7354_pci_passthrough_fix_vnic_vif_types.py b/neutron/db/migration/alembic_migrations/versions/wrs_newton/contract/cgts_7354_pci_passthrough_fix_vnic_vif_types.py
deleted file mode 100644
index 1428aa2..0000000
--- a/neutron/db/migration/alembic_migrations/versions/wrs_newton/contract/cgts_7354_pci_passthrough_fix_vnic_vif_types.py
+++ /dev/null
@@ -1,51 +0,0 @@
-# Copyright 2016 OpenStack Foundation
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-#
-# Copyright (c) 2017 Wind River Systems, Inc.
-#
-# The right to copy, distribute, modify, or otherwise make use
-# of this software may be licensed only pursuant to the terms
-# of an applicable Wind River license agreement.
-#
-
-"""Fix vnic_type and vif_type for pci-passthrough NICs from 15.12
-
-Revision ID: cgts_7354
-Revises: 5c85685d616d
-Create Date: 2017-06-19 00:00:01.000000
-
-"""
-
-from alembic import op
-
-
-# revision identifiers, used by Alembic.
-revision = 'cgts_7354'
-down_revision = '5c85685d616d'
-
-
-def upgrade():
-    # In 15.12 pci-passthrough ports were configured with a vif_type of "avs"
-    # and a vnic_type of "normal".  Now we want those to be
-    # "hostdev_physical" and "direct-physical", respectively.
-    op.execute(
-        "UPDATE ml2_port_bindings "
-        "SET vnic_type='direct-physical',vif_type='hostdev_physical' "
-        "WHERE vif_type='avs' and vnic_type='normal' and "
-        "vif_model='pci-passthrough'")
-    op.execute(
-        "UPDATE ml2_distributed_port_bindings "
-        "SET vnic_type='direct-physical',vif_type='hostdev_physical' "
-        "WHERE vif_type='avs' and vnic_type='normal' and "
-        "vif_model='pci-passthrough'")
diff --git a/neutron/db/securitygroups_rpc_base.py b/neutron/db/securitygroups_rpc_base.py
index afbce41..55406ed 100644
--- a/neutron/db/securitygroups_rpc_base.py
+++ b/neutron/db/securitygroups_rpc_base.py
@@ -12,13 +12,6 @@
 #    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
 #    License for the specific language governing permissions and limitations
 #    under the License.
-#
-# Copyright (c) 2013-2014 Wind River Systems, Inc.
-#
-# The right to copy, distribute, modify, or otherwise make use
-# of this software may be licensed only pursuant to the terms
-# of an applicable Wind River license agreement.
-#
 
 import netaddr
 from neutron_lib import constants as const
@@ -330,9 +323,6 @@ class SecurityGroupInfoAPIMixin(object):
 
     def _apply_provider_rule(self, context, ports):
         for port in ports.values():
-            # DO NOT CREATE GENERATED RULES IF NO RULES CONFIGURED
-            if not port['security_group_rules']:
-                continue
             self._add_ingress_ra_rule(port)
             self._add_ingress_dhcp_rule(port)
 
diff --git a/neutron/extensions/wrs_binding.py b/neutron/extensions/wrs_binding.py
index 401d81f..9190802 100644
--- a/neutron/extensions/wrs_binding.py
+++ b/neutron/extensions/wrs_binding.py
@@ -23,19 +23,15 @@
 from neutron_lib.api import extensions as api_extensions
 from neutron_lib import constants
 
-from neutron.common import constants as n_const
-
 # The MTU value is associated to the network to which the port is attached
-# wrs-binding:mtu
-MTU = '%sbinding:mtu' % n_const.WRS_FIELD_PREFIX
+MTU = 'wrs-binding:mtu'
 
 # The VIF model describes the type of emulated device in the guest.  This is
 # analoguous to the hw_vif_model property in Nova.  For clarity, the
 # 'vif_type' above represents the type of virtual switch that runs on the
 # host, and this field represents type type of hardware emulated in the
 # guest.
-# wrs-binding:vif_model
-VIF_MODEL = '%sbinding:vif_model' % n_const.WRS_FIELD_PREFIX
+VIF_MODEL = 'wrs-binding:vif_model'
 
 VIF_MODEL_DEFAULT = 'default'
 VIF_MODEL_VIRTIO = 'virtio'
@@ -43,8 +39,7 @@ VIF_MODEL_PCI_PASSTHROUGH = 'pci-passthrough'
 
 # The mac_filtering attribute describes whether the MAC filtering was enabled
 # as an attribute of the project that this port is owned by.
-# wrs-binding:mac_filtering
-MAC_FILTERING = '%sbinding:mac_filtering' % n_const.WRS_FIELD_PREFIX
+MAC_FILTERING = 'wrs-binding:mac_filtering'
 
 VIF_TYPE_AVS = 'avs'
 
diff --git a/neutron/extensions/wrs_net.py b/neutron/extensions/wrs_net.py
index e241c62..a232381 100644
--- a/neutron/extensions/wrs_net.py
+++ b/neutron/extensions/wrs_net.py
@@ -24,16 +24,12 @@ from oslo_log import log as logging
 
 from neutron_lib.api import extensions as api_extensions
 
-from neutron.common import constants as n_const
-
 
 LOG = logging.getLogger(__name__)
 
-# wrs-net:vlan_id
-VLAN = '%snet:vlan_id' % n_const.WRS_FIELD_PREFIX
+VLAN = 'wrs-net:vlan_id'
 
-# wrs-net:host
-HOST = '%snet:host' % n_const.WRS_FIELD_PREFIX
+HOST = 'wrs-net:host'
 
 
 EXTENDED_ATTRIBUTES_2_0 = {
diff --git a/neutron/extensions/wrs_provider.py b/neutron/extensions/wrs_provider.py
index 3d3cb76..e9f6052 100644
--- a/neutron/extensions/wrs_provider.py
+++ b/neutron/extensions/wrs_provider.py
@@ -58,15 +58,11 @@ def _validate_ip_mcast_address(data, valid_values=None):
 
 validators.add_validator('type:ip_mcast_address', _validate_ip_mcast_address)
 
-# wrs-provider:network_type
-# wrs-provider:physical_network
-# wrs-provider:segmentation_id
-NETWORK_TYPE = '%sprovider:network_type' % n_const.WRS_FIELD_PREFIX
-PHYSICAL_NETWORK = '%sprovider:physical_network' % n_const.WRS_FIELD_PREFIX
-SEGMENTATION_ID = '%sprovider:segmentation_id' % n_const.WRS_FIELD_PREFIX
+NETWORK_TYPE = 'wrs-provider:network_type'
+PHYSICAL_NETWORK = 'wrs-provider:physical_network'
+SEGMENTATION_ID = 'wrs-provider:segmentation_id'
 ATTRIBUTES = [NETWORK_TYPE, PHYSICAL_NETWORK, SEGMENTATION_ID]
-# wrs-provider:mtu
-MTU = '%sprovider:mtu' % n_const.WRS_FIELD_PREFIX
+MTU = 'wrs-provider:mtu'
 
 EXTENDED_ATTRIBUTES_2_0 = {
     'subnets': {
diff --git a/neutron/extensions/wrs_tm.py b/neutron/extensions/wrs_tm.py
index 04e9f7d..fd31dcc 100644
--- a/neutron/extensions/wrs_tm.py
+++ b/neutron/extensions/wrs_tm.py
@@ -29,7 +29,6 @@ from neutron._i18n import _
 from neutron.api import extensions
 from neutron.api.v2 import attributes as attr
 from neutron.api.v2 import base
-from neutron.common import constants as n_const
 
 import six
 
@@ -60,8 +59,7 @@ RESOURCE_ATTRIBUTE_MAP = {
     },
 }
 
-# wrs-tm:qos
-QOS = "%stm:qos" % n_const.WRS_FIELD_PREFIX
+QOS = "wrs-tm:qos"
 
 EXTENDED_ATTRIBUTES_2_0 = {
     'ports': {QOS: {'allow_post': True,
diff --git a/neutron/opts.py b/neutron/opts.py
index d653284..0ff219d 100644
--- a/neutron/opts.py
+++ b/neutron/opts.py
@@ -60,7 +60,6 @@ import neutron.extensions.l3
 import neutron.extensions.securitygroup
 import neutron.plugins.ml2.config
 import neutron.plugins.ml2.drivers.mech_sriov.agent.common.config
-import neutron.plugins.wrs.agent.avs.agent
 import neutron.plugins.wrs.drivers.mech_vswitch
 import neutron.setting
 import neutron.wsgi
@@ -323,19 +322,6 @@ def list_pnet_connectivity_opts():
     ]
 
 
-def list_avs_agent_opts():
-    return [
-        ('avs',
-         neutron.plugins.wrs.agent.avs.agent.avs_opts),
-        ('agent',
-         neutron.plugins.wrs.agent.avs.agent.agent_opts),
-        ('vxlan',
-         neutron.plugins.wrs.agent.avs.agent.vxlan_opts),
-        ('securitygroup',
-         neutron.conf.agent.securitygroups_rpc.security_group_opts)
-    ]
-
-
 def list_vhost_opts():
     return [
         ('vhost',
diff --git a/neutron/pecan_wsgi/app.py b/neutron/pecan_wsgi/app.py
index dc6d97c..279b3f3 100644
--- a/neutron/pecan_wsgi/app.py
+++ b/neutron/pecan_wsgi/app.py
@@ -33,7 +33,6 @@ def v2_factory(global_config, **local_config):
         hooks.ContextHook(),  # priority 95
         hooks.ExceptionTranslationHook(),  # priority 100
         hooks.BodyValidationHook(),  # priority 120
-        hooks.WrsFieldsHook(),  # priority 121
         hooks.OwnershipValidationHook(),  # priority 125
         hooks.QuotaEnforcementHook(),  # priority 130
         hooks.NotifierHook(),  # priority 135
diff --git a/neutron/pecan_wsgi/hooks/__init__.py b/neutron/pecan_wsgi/hooks/__init__.py
index 2a3a668..e557988 100644
--- a/neutron/pecan_wsgi/hooks/__init__.py
+++ b/neutron/pecan_wsgi/hooks/__init__.py
@@ -22,7 +22,6 @@ from neutron.pecan_wsgi.hooks import query_parameters
 from neutron.pecan_wsgi.hooks import quota_enforcement
 from neutron.pecan_wsgi.hooks import translation
 from neutron.pecan_wsgi.hooks import userfilters
-from neutron.pecan_wsgi.hooks import wrs_fields
 
 
 ExceptionTranslationHook = translation.ExceptionTranslationHook
@@ -34,4 +33,3 @@ QuotaEnforcementHook = quota_enforcement.QuotaEnforcementHook
 NotifierHook = notifier.NotifierHook
 QueryParametersHook = query_parameters.QueryParametersHook
 UserFilterHook = userfilters.UserFilterHook
-WrsFieldsHook = wrs_fields.WrsFieldsHook
diff --git a/neutron/pecan_wsgi/hooks/wrs_fields.py b/neutron/pecan_wsgi/hooks/wrs_fields.py
deleted file mode 100644
index cb87906..0000000
--- a/neutron/pecan_wsgi/hooks/wrs_fields.py
+++ /dev/null
@@ -1,65 +0,0 @@
-# All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License"); you may
-# not use this file except in compliance with the License. You may obtain
-# a copy of the License at
-#
-#      http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-# License for the specific language governing permissions and limitations
-# under the License.
-#
-# Copyright (c) 2017-2018 Wind River Systems, Inc.
-#
-# The right to copy, distribute, modify, or otherwise make use
-# of this software may be licensed only pursuant to the terms
-# of an applicable Wind River license agreement.
-#
-
-from neutron.common import constants as n_const
-from pecan import hooks
-
-
-class WrsFieldsHook(hooks.PecanHook):
-
-    # Do this at around the same as body validation hook
-    # we use this to strip out wrs- attributes when the request
-    # comes from a non-wrs client
-    # this is part of compliance to refstack, tempest, functest etc
-    priority = 121
-
-    def after(self, state):
-        # filter out wrs fields when the request does not
-        # comes from a wrs client
-        if state.request.headers.get('wrs-header') is not None:
-            return
-
-        try:
-            data = state.response.json
-        except ValueError:
-            return
-        resource = state.request.context.get('resource')
-        collection = state.request.context.get('collection')
-        if collection not in data and resource not in data:
-            return
-        is_single = resource in data
-        key = resource if resource in data else collection
-        if is_single:
-            data[key] = self._filter_item(
-                state.response.json[key])
-        else:
-            data[key] = [
-                self._filter_item(i)
-                for i in state.response.json[key]
-            ]
-        state.response.json = data
-
-    def _filter_item(self, item):
-        return {
-            field: value
-            for field, value in item.items()
-            if not field.startswith(n_const.WRS_FIELD_PREFIX)
-        }
diff --git a/neutron/plugins/ml2/plugin.py b/neutron/plugins/ml2/plugin.py
index ed127be..c0a0be7 100644
--- a/neutron/plugins/ml2/plugin.py
+++ b/neutron/plugins/ml2/plugin.py
@@ -1450,8 +1450,7 @@ class Ml2Plugin(db_base_plugin_v2.NeutronDbPluginV2,
             attrs[addr_pair.ADDRESS_PAIRS] = []
 
         if port_security:
-            if cfg.CONF.SECURITYGROUP.ensure_default_security_group:
-                self._ensure_default_security_group_on_port(context, port)
+            self._ensure_default_security_group_on_port(context, port)
         elif self._check_update_has_security_groups(port):
             raise psec_exc.PortSecurityAndIPRequiredForSecurityGroups()
 
diff --git a/neutron/plugins/wrs/agent/avr/__init__.py b/neutron/plugins/wrs/agent/avr/__init__.py
index e69de29..8b13789 100644
--- a/neutron/plugins/wrs/agent/avr/__init__.py
+++ b/neutron/plugins/wrs/agent/avr/__init__.py
@@ -0,0 +1 @@
+
diff --git a/neutron/plugins/wrs/agent/avr/agent.py b/neutron/plugins/wrs/agent/avr/agent.py
index b2386fa..8b13789 100644
--- a/neutron/plugins/wrs/agent/avr/agent.py
+++ b/neutron/plugins/wrs/agent/avr/agent.py
@@ -1,1438 +1 @@
-# Copyright 2015 OpenStack Foundation
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-#
-# Copyright (c) 2015 Wind River Systems, Inc.
-#
-# The right to copy, distribute, modify, or otherwise make use
-# of this software may be licensed only pursuant to the terms
-# of an applicable Wind River license agreement.
-#
 
-from random import randint
-import sys
-
-import eventlet
-eventlet.monkey_patch()
-
-import netaddr
-import six
-
-from neutron_lib import constants
-from neutron_lib import context
-from neutron_lib.utils import helpers
-from oslo_config import cfg
-from oslo_log import log as logging
-import oslo_messaging
-from oslo_service import loopingcall
-from oslo_service import service
-from oslo_utils import importutils
-
-from neutron._i18n import _
-from neutron.agent.l3 import agent as l3_agent
-from neutron.agent.linux import external_process
-from neutron.agent.linux import interface
-from neutron.agent.linux import ip_lib
-from neutron.agent.metadata import driver as metadata_driver
-from neutron.agent import rpc
-from neutron.agent.vswitch import api as vswitch_api
-from neutron.agent.vswitch import constants as vswitch_constants
-from neutron.agent.vswitch import manager as vswitch_manager
-from neutron.common import config as common_config
-from neutron.common import constants as n_const
-from neutron.common import topics
-from neutron.common import utils
-from neutron.conf.agent import common as config
-from neutron.conf.agent.metadata import config as meta_conf
-from neutron.extensions import wrs_binding
-from neutron import manager
-from neutron import service as neutron_service
-
-
-LOG = logging.getLogger(__name__)
-
-ROUTER_NS_PREFIX = 'avr-'
-METADATA_DEV_PREFIX = 'md-'
-METADATA_DEFAULT_PREFIX = 16
-METADATA_DEFAULT_IP = '169.254.169.254'
-METADATA_ROUTER_IP = '169.254.169.253'
-METADATA_DEFAULT_CIDR = '%s/%d' % (METADATA_DEFAULT_IP,
-                                   METADATA_DEFAULT_PREFIX)
-
-ROUTER_OWNERS = [constants.DEVICE_OWNER_ROUTER_INTF,
-                 constants.DEVICE_OWNER_DVR_INTERFACE]
-
-# Event Queue Priorities (lower value is higher priority)
-RPC_EVENT_PRIORITY = 0
-ROUTER_SYNC_PRIORITY = 1
-
-# Event Queue actions
-UPDATE_EVENT = 1
-DELETE_EVENT = 2
-SYNC_EVENT = 3
-
-ROUTER_MAX_QUEUE_SIZE = 64
-
-# Floating IP addresses are added with a fixed prefix len
-FLOATING_IP_PREFIX_LEN = 32
-
-
-def get_staggered_timeout(value, stagger=None):
-    """
-    Return an integer of value +/- stagger.
-    """
-    if not stagger:
-        return value
-    stagger = min(value / 2, stagger)
-    return randint(value - stagger, value + stagger)
-
-
-class EventMessage(object):
-    """
-    Represents a queued RPC event or periodic task notification.
-    """
-    def __init__(self, action, priority, router_ids=None):
-        self.action = action
-        self.priority = priority
-        self.router_ids = router_ids
-
-    def __repr__(self):
-        return "EventMessage(action={}, priority={} ids={})".format(
-            self.action, self.priority, self.router_ids)
-
-    def merge(self, other):
-        """
-        Combines the router_ids list from both objects
-        """
-        if not self.router_ids:
-            self.router_ids = other.router_ids
-        if not other.router_ids:
-            return
-        self.router_ids = list(set(self.router_ids) | set(other.router_ids))
-
-    def __lt__(self, other):
-        """
-        Exposes ordering rules for the priority queue class.
-        """
-        return self.priority < other.priority
-
-
-class AVRAgentManager(manager.Manager):
-    """Manager for AVR (L3) Agent"""
-
-    OPTS = [
-        cfg.IntOpt('resync_interval', default=300,
-                   help=_("Interval to periodically resync.")),
-        cfg.BoolOpt('enable_metadata_proxy', default=True,
-                    help=_("Allow running metadata proxy.")),
-        cfg.IntOpt('metadata_port',
-                   default=80,
-                   help=_("TCP Port used by Neutron metadata namespace "
-                          "proxy.")),
-        cfg.StrOpt('metadata_mac_address',
-                   default="fa:16:3d:00:00:01",
-                   help=_("MAC Address to be used by metadata namespace "
-                          "proxy interface.")),
-        cfg.IntOpt('snat_interface_weight', default=250,
-                   help=_("Weight assigned to SNAT router interfaces.")),
-    ]
-
-    target = oslo_messaging.Target(version='1.2')
-
-    def __init__(self, host):
-        super(AVRAgentManager, self).__init__(host=host)
-        self.conf = cfg.CONF
-        self.root_helper = config.get_root_helper(self.conf)
-        self.routers = {}
-        self.agent_gateway_ports = {}
-        self.agent_state = {
-            'binary': 'neutron-avr-agent',
-            'host': host,
-            'availability_zone': cfg.CONF.AGENT.availability_zone,
-            'topic': topics.L3_AGENT,
-            'start_flag': True,
-            'agent_type': constants.AGENT_TYPE_L3,
-            'configurations': {
-                'agent_mode': constants.L3_AGENT_MODE_DVR_SNAT,
-                'interface_driver': self.conf.interface_driver}}
-
-        self.vswitch_mgr = vswitch_manager.VSwitchManager(
-            vswitch_api.VSwitchManagementAPI())
-
-        try:
-            self.vif_driver = importutils.import_object(
-                self.conf.interface_driver,
-                self.conf
-            )
-        except Exception:
-            msg = ("Error importing interface driver "
-                   "'%s'") % self.conf.interface_driver
-            LOG.error(msg)
-            raise SystemExit(1)
-
-        self.context = context.get_admin_context_without_session()
-        self.plugin_rpc = l3_agent.L3PluginApi(topics.L3PLUGIN, host)
-        self.queue = eventlet.queue.LightQueue(maxsize=ROUTER_MAX_QUEUE_SIZE)
-
-        self.use_call = True
-        self.state_rpc = rpc.PluginReportStateAPI(topics.PLUGIN)
-        report_interval = self.conf.AGENT.report_interval
-        if report_interval:
-            self.heartbeat = loopingcall.FixedIntervalLoopingCall(
-                self._report_state)
-            self.heartbeat.start(interval=report_interval)
-        resync_interval = get_staggered_timeout(self.conf.resync_interval, 30)
-        if resync_interval:
-            self.resync_task = loopingcall.FixedIntervalLoopingCall(
-                self._sync_routers_task)
-            self.resync_task.start(interval=resync_interval)
-        self.process_monitor = external_process.ProcessMonitor(
-            config=self.conf,
-            resource_type='router')
-
-    def after_start(self):
-        eventlet.spawn_n(self._event_handler)
-        LOG.info("AVR agent started")
-
-    def after_stop(self):
-        for router_id in self.routers:
-            self._destroy_metadata_proxy({'id': router_id})
-        LOG.info("AVR agent stopped")
-
-    def agent_updated(self, context, payload):
-        """Handle the agent_updated notification event."""
-        LOG.info("agent_updated by server side %s!", payload)
-        self._event_notify(SYNC_EVENT, ROUTER_SYNC_PRIORITY)
-
-    def routers_updated(self, context, routers):
-        """Deal with routers modification and creation RPC message."""
-        LOG.info("routers_updated by server side %s!", routers)
-        self._event_notify(UPDATE_EVENT, RPC_EVENT_PRIORITY, routers)
-
-    def router_deleted(self, context, router_id):
-        """Deal with routers modification and creation RPC message."""
-        LOG.info("router_deleted by server side %s!", router_id)
-        self._event_notify(DELETE_EVENT, RPC_EVENT_PRIORITY, [router_id])
-
-    def add_arp_entry(self, context, payload):
-        """Add static ARP entry into router context. Called from RPC."""
-        router_id = payload['router_id']
-        if router_id in self.routers:
-            LOG.info("Add static ARP entry: {}".format(payload))
-            self._event_notify(UPDATE_EVENT, RPC_EVENT_PRIORITY, [router_id])
-        else:
-            LOG.debug("Ignored broadcast ARP entry update: {}".format(payload))
-
-    def del_arp_entry(self, context, payload):
-        """Delete static ARP entry from router context. Called from RPC."""
-        router_id = payload['router_id']
-        if router_id in self.routers:
-            LOG.info("Delete static ARP entry: {}".format(payload))
-            self._event_notify(UPDATE_EVENT, RPC_EVENT_PRIORITY, [router_id])
-        else:
-            LOG.debug("Ignored broadcast ARP entry delete: {}".format(payload))
-
-    def fipnamespace_delete_on_ext_net(self, context, ext_net_id):
-        """Delete fip namespace after external network removed."""
-        LOG.info("Delete FIP namespace for net: {}".format(ext_net_id))
-        # We do not have FIP namespaces just log for now.
-
-    def router_added_to_agent(self, context, payload):
-        LOG.info("Router added to agent: {}".format(payload))
-        self._event_notify(UPDATE_EVENT, RPC_EVENT_PRIORITY, payload)
-
-    def router_removed_from_agent(self, context, payload):
-        LOG.info("Router removed from agent: {}".format(payload))
-        router_id = payload['router_id']
-        self.router_deleted(context, router_id)
-
-    def _drain_event_queue(self):
-        events = []
-        sync_event = None
-        # Wait until a message arrives.  No need to timeout because the
-        # sync_routers periodic task will be sending messages at regular
-        # intervals to wake us up.
-        events.append(self.queue.get())
-        # Then drain the queue of all pending events coalescing all
-        # consecutive events of the same type in to a single event
-        while True:
-            try:
-                event = self.queue.get_nowait()
-                last = events[-1]
-                if last.action == event.action:
-                    event.merge(last)
-                    events[-1] = event
-                elif event.action == SYNC_EVENT:
-                    # process sync events last
-                    sync_event = event
-                else:
-                    events.append(event)
-            except eventlet.queue.Empty:
-                break
-        return events + ([] if not sync_event else [sync_event])
-
-    @utils.exception_logger()
-    def _event_handler(self):
-        while True:
-            events = self._drain_event_queue()
-            for event in events:
-                if event.action == DELETE_EVENT:
-                    self._remove_routers(event.router_ids)
-                else:
-                    self._sync_routers(router_ids=event.router_ids)
-
-                # run full audit on every periodic sync
-                if event.action == SYNC_EVENT:
-                    self._audit_routers()
-
-    def _event_notify(self, action, priority, router_ids=None):
-        try:
-            event = EventMessage(action, priority, router_ids=router_ids)
-            # wake up router event processing thread
-            self.queue.put_nowait(event)
-        except eventlet.queue.Full as e:
-            LOG.exception(e)
-
-    def _sync_routers_task(self):
-        self._event_notify(SYNC_EVENT, ROUTER_SYNC_PRIORITY)
-
-    def _report_state(self):
-        try:
-            configurations = self.agent_state['configurations']
-            configurations['routers'] = len(self.routers)
-            status = self.state_rpc.report_state(
-                self.context, self.agent_state, self.use_call)
-            if status == n_const.AGENT_REVIVED:
-                self._event_notify(SYNC_EVENT, ROUTER_SYNC_PRIORITY)
-            self.agent_state.pop('start_flag', None)
-            self.use_call = False
-        except AttributeError:
-            # This means the server does not support report_state
-            LOG.warning("Neutron server does not support state report."
-                        " State report for this agent will be disabled.")
-            self.heartbeat.stop()
-            return
-        except Exception:
-            LOG.exception("Failed reporting state!")
-
-    def _is_gateway_owner(self, router):
-        if not router.get('distributed', False):
-            return True
-        gateway_host = router.get('gw_port_host', None)
-        if gateway_host and (gateway_host == self.host):
-            return True
-        return False
-
-    def _sanitize_duplicate_interfaces_r5(self, router):
-        """
-        After a compute node is upgraded, AVR should ignore all vlan-tagged
-        subnets, as they have been replaced by newly-created subnets in order
-        to migrate away from using vlan-tagged subnets.
-        """
-        _interfaces = router.get(constants.INTERFACE_KEY, [])
-        _snat_router_interfaces = router.get(n_const.SNAT_ROUTER_INTF_KEY, [])
-        all_interfaces = list(_interfaces) + list(_snat_router_interfaces)
-        # Make copy of list to iterate through, so can be removed from original
-        for _interface in all_interfaces:
-            subnets = _interface.get('subnets', [])
-            for subnet in subnets:
-                if subnet.get('wrs-net:vlan_id', 0) > 0:
-                    if _interface in _interfaces:
-                        _interfaces.remove(_interface)
-                    elif _interface in _snat_router_interfaces:
-                        _snat_router_interfaces.remove(_interface)
-                    else:
-                        continue
-                    LOG.info("AVR ignoring r4 {} interface: {}"
-                             .format(_interface.get('device_owner'),
-                                     _interface.get('id')))
-
-    def _sanitize_router(self, router):
-        self._sanitize_duplicate_interfaces_r5(router)
-        if not router.get('distributed', False):
-            return router
-        if not self._is_gateway_owner(router):
-            router.pop('gw_port', None)
-            router.pop('gw_port_host', None)
-        return router
-
-    def _remove_routers(self, router_ids=None):
-        for router_id in router_ids or []:
-            if router_id not in self.routers:
-                continue
-            self._remove_router(self.routers[router_id])
-            del self.routers[router_id]
-
-    def _sync_routers(self, router_ids=None):
-        """
-        Sync the current set of routers in AVS against the current set of
-        routers in the DB.  If a list of router id values is specified in the
-        router_ids argument then the sync audit is constrained to only that set
-        of routers.
-        """
-        LOG.debug("AVR syncing routers: router_ids={}".format(router_ids))
-        try:
-            # NOTE(alegacy): An empty list is a request to audit all
-            # routers.  In this case, we invoke the get_router_ids API because
-            # it calls auto_schedule_routers to pick up any unscheduled
-            # routers.
-            ids = router_ids or self.plugin_rpc.get_router_ids(self.context)
-            # retrieve the latest list of routers keyed by id
-            routers = dict((r['id'], r) for r in
-                           self.plugin_rpc.get_routers(self.context, ids))
-            router_ids = set(router_ids or [])
-
-            # adjust routers to remove components not owned or assigned to
-            # this router.
-            for router_id, router in six.iteritems(routers):
-                routers[router_id] = self._sanitize_router(router)
-
-            current = set(routers)
-            existing = set(self.routers)
-            if router_ids:
-                existing &= router_ids
-
-            added = current - existing
-            removed = existing - current
-            updated = existing & current
-
-            for router_id in removed:
-                self._remove_router(self.routers[router_id])
-                del self.routers[router_id]
-
-            for router_id in added:
-                self._add_router(routers[router_id])
-
-            for router_id in updated:
-                self._update_router(routers[router_id])
-
-            # save current set of routers for next interval
-            self.routers.update(routers)
-
-        except Exception:
-            msg = "Failed to sync router information"
-            LOG.exception(msg)
-
-    def _audit_routers(self):
-        """
-        Audit the current set of routers in AVS against the current set of
-        routers maintained in the agent.
-        """
-        LOG.debug("AVR audit routers")
-        try:
-            local_routers = self.routers
-            remote_routers = self.vswitch_mgr.get_router_list()
-
-            local = set(local_routers)
-            remote = set(remote_routers)
-
-            missing = local - remote
-            orphaned = remote - local
-            audit = local & remote
-
-            for router_id in orphaned:
-                LOG.warning("AVR remove orphaned router {}".format(
-                    router_id))
-                self.vswitch_mgr.delete_router(router_id)
-
-            for router_id in missing:
-                LOG.warning("AVR add missing router {}".format(router_id))
-                self._add_router(local_routers[router_id])
-
-            for router_id in audit:
-                self._audit_router(local_routers[router_id],
-                                   remote_routers[router_id])
-        except Exception:
-            msg = "Failed to audit router information"
-            LOG.exception(msg)
-
-    def _add_router(self, router):
-        LOG.info("AVR add router: {}".format(router))
-        router_name = self.vswitch_mgr.get_router_name(router['id'])
-        snat_enabled = router.get('enable_snat', False)
-        self.vswitch_mgr.add_router(router['id'], router_name,
-                                    True, snat_enabled)
-        self._add_gateway_port(router)
-        self._add_internal_ports(router)
-        self._add_snat_ports(router)
-        self._add_fip_addresses(router)
-        self._add_dnat_rules(router)
-        self._add_routes(router)
-        self._spawn_metadata_proxy(router)
-
-    def _update_router(self, router):
-        LOG.debug("AVR update router: {}".format(router))
-
-        existing_router = self.routers.get(router['id'])
-        existing_snat = existing_router.get('enable_snat', False)
-        current_snat = router.get('enable_snat', False)
-        if existing_snat != current_snat:
-            self.vswitch_mgr.update_router(router['id'], current_snat)
-
-        self._update_gateway_port(router)
-        self._update_internal_ports(router)
-        self._update_snat_ports(router)
-        self._update_fip_addresses(router)
-        self._update_dnat_rules(router)
-        self._update_routes(router)
-
-    def _remove_router(self, router):
-        LOG.info("AVR remove router: {}".format(router))
-        self._delete_agent_gateway_port(router)
-        self.vswitch_mgr.delete_router(router['id'])
-        self._destroy_metadata_proxy(router)
-
-    def _audit_router(self, local_router, remote_router):
-        LOG.debug("AVR audit router: {}".format(local_router))
-
-        # Audit the router specific properties
-        router_id = local_router.get('id')
-        local_snat = local_router.get('enable_snat', False)
-        remote_snat = getattr(remote_router, 'snat-enabled', False)
-        if local_snat != remote_snat:
-            LOG.warning("AVR correct router SNAT state {} to {}".
-                        format(router_id, local_snat))
-            self.vswitch_mgr.update_router(router_id, local_snat)
-
-        self._audit_router_ports(local_router)
-        self._audit_fip_addresses(local_router)
-        self._audit_dnat_rules(local_router)
-        self._audit_routes(local_router)
-
-    def _audit_router_ports(self, router):
-        router_id = router.get('id')
-        router_interfaces = self.vswitch_mgr.get_router_interfaces(router_id)
-
-        self._audit_metadata_port(router, router_interfaces)
-        self._audit_gateway_port(router, router_interfaces)
-        self._audit_internal_ports(router, router_interfaces)
-        self._audit_snat_ports(router, router_interfaces)
-
-        # remove orphaned interfaces
-        for interface_uuid in router_interfaces.keys():
-            LOG.warning("AVR remove orphaned interface {}".
-                        format(interface_uuid))
-            self.vswitch_mgr.delete_interface(interface_uuid)
-
-    def _add_gateway_port(self, router):
-        port = router.get('gw_port', None)
-        if port:
-            name = self.vswitch_mgr.get_router_name(router['id'])
-            name += "-gwy"
-            self._add_router_port(router, port, name=name, gateway=True)
-            self._add_gateway_default_route(router, port)
-
-    def _delete_gateway_port(self, port):
-        self._delete_router_port(port)
-
-    def _update_gateway_port(self, router):
-        router_id = router.get('id')
-        current_port = router.get('gw_port', None)
-        existing_router = self.routers.get(router_id)
-        existing_port = existing_router.get('gw_port', None)
-
-        if not existing_port and current_port:
-            self._add_gateway_port(router)
-        elif existing_port and not current_port:
-            self._delete_gateway_port(existing_port)
-        else:
-            self._add_gateway_port(router)
-
-    def _audit_gateway_port(self, router, router_interfaces):
-        gw_port = router.get('gw_port', None)
-        if gw_port:
-            interface_uuid = gw_port.get('id')
-            if interface_uuid not in router_interfaces:
-                # add missing gateway port
-                LOG.warning("AVR add missing gateway port {}".
-                            format(interface_uuid))
-                self._add_gateway_port(router)
-            else:
-                # interface exists, and is not an orphan
-                del router_interfaces[interface_uuid]
-
-    def _get_existing_neighbours(self, interface_uuid):
-        data = self.vswitch_mgr.get_neighbours(interface_uuid)
-        neighbours = {}
-        for entry in data:
-            if entry['type'] != vswitch_constants.VSWITCH_NEIGH_STATIC:
-                continue
-            neighbours[entry['address']] = entry['mac-address']
-        return neighbours
-
-    def _add_subnet_static_arp_entries(self, interface_uuid, subnet):
-        subnet_id = subnet.get('id')
-        neighbours = self._get_existing_neighbours(interface_uuid)
-        ports = self.plugin_rpc.get_ports_by_subnet(self.context, subnet_id)
-        for port in ports:
-            if port['device_owner'] in ROUTER_OWNERS:
-                continue
-            for addr in port['fixed_ips'] or []:
-                if addr['subnet_id'] != subnet_id:
-                    continue
-                if (addr['ip_address'] not in neighbours or
-                        port['mac_address'] != neighbours[addr['ip_address']]):
-                    self.vswitch_mgr.add_neighbour(interface_uuid,
-                                                   addr['ip_address'],
-                                                   port['mac_address'])
-                neighbours.pop(addr['ip_address'], None)
-        for ip_address, mac_address in six.iteritems(neighbours):
-            LOG.warning("Removing stale neighbour {} on {}".format(
-                ip_address, interface_uuid))
-            self.vswitch_mgr.delete_neighbour(interface_uuid, ip_address)
-
-    def _add_static_arp_entries(self, router, port):
-        interface_uuid = port.get('id')
-        for subnet in port['subnets']:
-            self._add_subnet_static_arp_entries(interface_uuid, subnet)
-
-    def _add_internal_ports(self, router):
-        ports = router.get(constants.INTERFACE_KEY, [])
-        for port in ports:
-            self._add_internal_port(router, port)
-
-    def _update_internal_ports(self, router):
-        router_id = router.get('id')
-        existing_router = self.routers.get(router_id)
-        current_ports = {port['id']: port for port in
-                         router.get(constants.INTERFACE_KEY, [])}
-        existing_ports = {port['id']: port for port in
-                          existing_router.get(constants.INTERFACE_KEY, [])}
-
-        current_set = set(current_ports)
-        existing_set = set(existing_ports)
-
-        added = current_set - existing_set
-        removed = existing_set - current_set
-        updated = existing_set & current_set
-
-        for port_id in removed:
-            self._delete_internal_port(existing_ports[port_id])
-        for port_id in added:
-            self._add_internal_port(router, current_ports[port_id])
-        for port_id in updated:
-            self._update_internal_port(router, current_ports[port_id])
-
-    def _audit_internal_ports(self, router, router_interfaces):
-        ports = router.get(constants.INTERFACE_KEY, [])
-        for port in ports:
-            interface_uuid = port.get('id')
-            if interface_uuid not in router_interfaces:
-                # add missing gateway port
-                LOG.warning("AVR add missing internal port {}".
-                            format(interface_uuid))
-                self._add_internal_port(router, port)
-            else:
-                # interface exists, and is not an orphan
-                del router_interfaces[interface_uuid]
-
-    def _add_internal_port(self, router, port):
-        self._add_router_port(router, port)
-        self._update_ndp_params(port)
-        if router.get('distributed', False):
-            self._add_static_arp_entries(router, port)
-
-    def _delete_internal_port(self, port):
-        self._delete_router_port(port)
-
-    def _update_internal_port(self, router, port):
-        self._add_router_port(router, port)
-        self._update_ndp_params(port)
-        if router.get('distributed', False):
-            self._add_static_arp_entries(router, port)
-
-    @staticmethod
-    def _translate_ndp_ra_mode(ramodes):
-        if constants.IPV6_SLAAC in ramodes:
-            return vswitch_constants.VSWITCH_NDP_RA_MODE_SLAAC
-        elif constants.DHCPV6_STATEFUL in ramodes:
-            return vswitch_constants.VSWITCH_NDP_RA_MODE_STATEFUL
-        elif constants.DHCPV6_STATELESS in ramodes:
-            return vswitch_constants.VSWITCH_NDP_RA_MODE_STATELESS
-        else:
-            return vswitch_constants.VSWITCH_NDP_RA_MODE_NONE
-
-    def _update_ndp_params(self, port):
-        interface_uuid = port.get('id')
-        ramodes = set()
-        for subnet in port.get('subnets'):
-            ramodes.add(subnet.get('ipv6_ra_mode'))
-        ramode = self._translate_ndp_ra_mode(ramodes)
-        params = {'ndp-interface-info':
-                  {'ra-mode': ramode}}
-        self.vswitch_mgr.update_interface(interface_uuid, params)
-
-    def _add_snat_ports(self, router):
-        ports = router.get(n_const.SNAT_ROUTER_INTF_KEY, [])
-        for port in ports:
-            self._add_snat_port(router, port)
-
-    def _get_snat_ports(self, router, force=False):
-        if self._is_gateway_owner(router) or force:
-            return dict((port['id'], port) for port in
-                        router.get(n_const.SNAT_ROUTER_INTF_KEY, []))
-        return {}
-
-    def _get_snat_ips(self, router):
-        snat_ips = []
-        for port in router.get(n_const.SNAT_ROUTER_INTF_KEY, []):
-            fixed_ips = port.get('fixed_ips', [])
-            snat_ips.extend(fixed_ip['ip_address'] for fixed_ip in fixed_ips)
-        return snat_ips
-
-    def _update_snat_ports(self, router):
-        router_id = router.get('id')
-        existing_router = self.routers.get(router_id)
-
-        current_ports = self._get_snat_ports(router)
-        existing_ports = self._get_snat_ports(existing_router)
-        configured_ports = self._get_snat_ports(router, force=True)
-
-        current_set = set(current_ports)
-        existing_set = set(existing_ports)
-
-        added = current_set - existing_set
-        removed = existing_set - current_set
-
-        for port_id in removed:
-            self._delete_snat_port(existing_router, existing_ports[port_id])
-
-        if not self._is_gateway_owner(router):
-            if len(configured_ports) == 0:
-                default_route = self._get_default_route(router)
-                if default_route:
-                    prefix = default_route.prefix
-                    self._delete_router_route(router, prefix, 0)
-            elif (self._get_default_route_gateway(router) not in
-                  self._get_snat_ips(router)):
-                # The snat default route may have been configured to point to
-                # an interface that is being removed, therefore replace the
-                # route with an interface that is still configured.
-                for port_id in configured_ports:
-                    self._update_snat_route(router, configured_ports[port_id])
-                    break  # only need one
-
-        for port_id in added:
-            self._add_snat_port(router, current_ports[port_id])
-
-    def _audit_snat_ports(self, router, router_interfaces):
-        if not self._is_gateway_owner(router):
-            return
-
-        ports = router.get(n_const.SNAT_ROUTER_INTF_KEY, [])
-        for port in ports:
-            interface_uuid = port.get('id')
-            if interface_uuid not in router_interfaces:
-                # add missing gateway port
-                LOG.warning("AVR add missing SNAT port {}".
-                            format(interface_uuid))
-                self._add_snat_port(router, port)
-            else:
-                # interface exists, and is not an orphan
-                del router_interfaces[interface_uuid]
-
-    def _add_snat_port(self, router, port):
-        if self._is_gateway_owner(router):
-            # router is the owner of the centralized snat port
-            name = self.vswitch_mgr.get_router_name(router['id'])
-            name += "-snat%u"
-
-            # SNAT interfaces are assigned a lower priority weight to ensure
-            # they are not selected as the internal network interface during
-            # next hop selection.
-            weight = self.conf.snat_interface_weight
-
-            self._add_router_port(router, port, weight=weight, name=name)
-        else:
-            # router must route packets to the centralized snat router
-            self._add_snat_default_route(router, port)
-
-    def _delete_snat_port(self, router, port):
-        if self._is_gateway_owner(router):
-            self._delete_router_port(port)
-
-    def _update_snat_route(self, router, port):
-        if not self._is_gateway_owner(router):
-            # attempt to replace the route in case it was configured by a
-            # different snat interface that may have be deleted
-            self._add_snat_default_route(router, port)
-
-    def _get_external_network_id(self, router):
-        info = router.get('external_gateway_info')
-        if info:
-            return info.get('network_id')
-        return None
-
-    def _add_fip_interface(self, router):
-        if not router.get('distributed'):
-            router.get('gw_port')
-
-        network_id = self._get_external_network_id(router)
-        port = self.agent_gateway_ports.get(network_id)
-        if port:
-            # validate that the cached port is configured, if not invalidate it
-            interface_uuid = port.get('id')
-            try:
-                self.vswitch_mgr.get_interface(interface_uuid)
-            except vswitch_manager.VSwitchManagerError:
-                self.agent_gateway_ports.pop(network_id)
-        self._add_agent_gateway_port(router)
-
-    def _get_fip_interface(self, router, create=False):
-        if not router.get('distributed', False):
-            return router.get('gw_port')
-        network_id = self._get_external_network_id(router)
-        interface = self.agent_gateway_ports.get(network_id)
-        if create and not interface:
-            return self._add_agent_gateway_port(router)
-        return interface
-
-    def _add_fip_router(self, router):
-        network_id = self._get_external_network_id(router)
-        port = self.agent_gateway_ports.get(network_id)
-        if port and (router['id'] in port['routers']):
-            # Already created and registered for this router
-            return port
-        elif port:
-            # Already created but not linked to this router
-            LOG.info("AVR Linking router {} to FIP router {}".format(
-                router['id'], network_id))
-            port['routers'].add(router['id'])
-            return port
-        LOG.info("AVR Add new FIP router {} for router {}".format(
-            network_id, router['id']))
-        port = self.plugin_rpc.get_agent_gateway_port(self.context, network_id)
-        # Create a router context
-        router_name = self.vswitch_mgr.get_fip_router_name(network_id)
-        self.vswitch_mgr.add_router(network_id, router_name)
-        # Create an interface from the router to the external network
-        fip_router = {'id': network_id}
-        name = "fip-" + network_id[:8]
-        self._add_router_port(fip_router, port, name=name, gateway=True)
-        self._add_gateway_default_route(fip_router, port)
-        # Setup the router association table and save the port
-        port['routers'] = set([router['id']])
-        self.agent_gateway_ports[network_id] = port
-        return port
-
-    def _delete_fip_router(self, router):
-        network_id = self._get_external_network_id(router)
-        if not network_id:
-            return
-        port = self.agent_gateway_ports.get(network_id)
-        if not port:
-            return
-        if router['id'] not in port['routers']:
-            LOG.warning("AVR router {} not holding reference "
-                        "to FIP router {}".
-                        format(router['id'], network_id))
-            return
-        port['routers'].remove(router['id'])
-        if len(port['routers']) != 0:
-            LOG.info("AVR Keeping FIP router {} with {} references: {}".
-                     format(network_id, len(port['routers']), port['routers']))
-            return
-        LOG.info("AVR Deleting orphaned FIP router {}".format(network_id))
-        self.vswitch_mgr.delete_router(network_id)
-        self.plugin_rpc.delete_agent_gateway_port(self.context, network_id)
-        del self.agent_gateway_ports[network_id]
-
-    def _add_agent_gateway_port(self, router):
-        if not router.get('distributed', False):
-            # No need for an agent gateway port
-            return
-        return self._add_fip_router(router)
-
-    def _update_agent_gateway_port(self, router):
-        if not router.get('distributed', False):
-            # No need for an agent gateway port
-            return
-        existing_router = self.routers[router['id']]
-        existing_network_id = self._get_external_network_id(existing_router)
-        current_network_id = self._get_external_network_id(router)
-        if existing_network_id == current_network_id:
-            return
-        if existing_network_id:
-            self._delete_fip_router(existing_router)
-        if current_network_id:
-            self._add_fip_router(router)
-
-    def _delete_agent_gateway_port(self, router):
-        if not router.get('distributed', False):
-            # No need for an agent gateway port
-            return
-        existing_network_id = self._get_external_network_id(router)
-        if existing_network_id:
-            self._delete_fip_router(router)
-
-    def _add_fip_address(self, router, interface, fip):
-        LOG.info("AVR Add FIP address {}".format(fip))
-        nat = {'internal-address': fip['fixed_ip_address'],
-               'router-uuid': fip['router_id']}
-        self.vswitch_mgr.add_address(fip['floating_ip_address'],
-                                     FLOATING_IP_PREFIX_LEN,
-                                     interface['id'],
-                                     **nat)
-
-    def _delete_fip_address(self, router, interface, fip):
-        if not interface:
-            LOG.error("AVR Delete FIP address has no interface {}".
-                      format(fip))
-        LOG.info("AVR Delete FIP address {}".format(fip))
-        self.vswitch_mgr.delete_address(fip['floating_ip_address'],
-                                        FLOATING_IP_PREFIX_LEN,
-                                        interface['id'])
-
-    def _get_floating_ips(self, router):
-        fips = router.get(constants.FLOATINGIP_KEY, [])
-        if router.get('distributed', False):
-            return [f for f in fips if f['host'] == self.host]
-        return fips
-
-    def _add_fip_addresses(self, router):
-        status = {}
-        fips = self._get_floating_ips(router)
-        if fips:
-            self._add_fip_interface(router)
-        interface = self._get_fip_interface(router)
-        for fip in fips:
-            self._add_fip_address(router, interface, fip)
-            status[fip['id']] = constants.FLOATINGIP_STATUS_ACTIVE
-        self.plugin_rpc.update_floatingip_statuses(
-            self.context, router['id'], status)
-
-    def _update_fip_addresses(self, router):
-        existing_router = self.routers[router['id']]
-        fips = self._get_floating_ips(router)
-        current_fips = {f['id']: f for f in fips}
-        fips = self._get_floating_ips(existing_router)
-        existing_fips = {f['id']: f for f in fips}
-        # Calculate the delta between the old and new router
-        added = set(current_fips) - set(existing_fips)
-        removed = set(existing_fips) - set(current_fips)
-        # Create an agent gateway port if necessary
-        existing_interface = self._get_fip_interface(existing_router)
-        interface = self._get_fip_interface(router, create=bool(current_fips))
-        # Adjust the local floating ip addresses
-        status = {}
-        for fip_id in removed:
-            self._delete_fip_address(
-                router, existing_interface, existing_fips[fip_id])
-            status[fip_id] = constants.FLOATINGIP_STATUS_DOWN
-        for fip_id in added:
-            self._add_fip_address(router, interface, current_fips[fip_id])
-            status[fip_id] = constants.FLOATINGIP_STATUS_ACTIVE
-        self.plugin_rpc.update_floatingip_statuses(
-            self.context, router['id'], status)
-        if existing_fips and not current_fips:
-            # The neutron-server automatically deletes the port when the last
-            # FIP is deleted on a DVR router so we need to do the same.
-            self._delete_agent_gateway_port(router)
-
-    def _audit_fip_addresses(self, local_router):
-        router_id = local_router.get('id')
-        fips = self._get_floating_ips(local_router)
-        local_addresses = {f['floating_ip_address']: f for f in fips}
-        remote_addresses = \
-            {a['address']: a for a in
-             self.vswitch_mgr.get_router_fip_addresses(router_id)}
-
-        local = set(local_addresses)
-        remote = set(remote_addresses)
-
-        missing = local - remote
-        orphaned = remote - local
-
-        interface = self._get_fip_interface(local_router, create=bool(fips))
-        for addr in missing:
-            LOG.warning("AVR add missing FIP address {}".format(addr))
-            self._add_fip_address(local_router, interface,
-                                  local_addresses[addr])
-
-        for addr in orphaned:
-            LOG.warning("AVR remove orphan FIP address {}".format(addr))
-            self.vswitch_mgr.delete_address(addr,
-                                            FLOATING_IP_PREFIX_LEN,
-                                            interface['id'])
-
-    def _get_dnat_rules(self, router):
-        snat_enabled = router.get('enable_snat', False)
-        dnat_rules = router.get(n_const.PORTFORWARDING_KEY, [])
-        gw_port = router.get('gw_port')
-        if not snat_enabled or not gw_port or not dnat_rules:
-            return []
-        return dnat_rules
-
-    def _add_dnat_rule(self, router, rule):
-        gw_port = router.get('gw_port')
-        if gw_port:
-            LOG.info("AVR adding DNAT rule {}".format(rule))
-            self.vswitch_mgr.add_snat_entry(gw_port['id'],
-                                            rule['inside_addr'],
-                                            rule['inside_port'],
-                                            rule['outside_port'],
-                                            rule['protocol'])
-
-    def _delete_dnat_rule(self, router, rule):
-        gw_port = router.get('gw_port')
-        if gw_port:
-            LOG.info("AVR removing DNAT rule {}".format(rule))
-            self.vswitch_mgr.delete_snat_entry(gw_port['id'],
-                                               rule['inside_addr'],
-                                               rule['inside_port'],
-                                               rule['protocol'])
-
-    def _add_dnat_rules(self, router):
-        dnat_rules = self._get_dnat_rules(router)
-        if not dnat_rules:
-            # Nothing to do
-            return
-        for rule in dnat_rules:
-            self._add_dnat_rule(router, rule)
-
-    def _make_dnat_key(self, rule):
-        """
-        Create a dictionary key string that can be used to compare unique
-        values in the local config versus the AVS config.  This is required
-        because AVS does not have a UUID against each SNAT entry and the local
-        config does.  We use this key to compare the 2 sets instead of a UUID
-        value.
-        """
-        return "{}-{}-{}-{}".format(rule['inside_addr'],
-                                    rule['inside_port'],
-                                    rule['outside_port'],
-                                    rule['protocol'].lower())
-
-    def _update_dnat_rules(self, router):
-        router_id = router.get('id')
-        existing_router = self.routers.get(router_id)
-        dnat_rules = self._get_dnat_rules(existing_router)
-        existing_dnat_rules = {self._make_dnat_key(d): d for d in dnat_rules}
-        dnat_rules = self._get_dnat_rules(router)
-        current_dnat_rules = {self._make_dnat_key(d): d for d in dnat_rules}
-        # Calculate the delta between the old and new router
-        added = set(current_dnat_rules) - set(existing_dnat_rules)
-        removed = set(existing_dnat_rules) - set(current_dnat_rules)
-        # Adjust the installed DNAT rules
-        for key in removed:
-            self._delete_dnat_rule(router, existing_dnat_rules[key])
-        for key in added:
-            self._add_dnat_rule(router, current_dnat_rules[key])
-
-    def _get_avs_dnat_rules(self, router):
-        gw_port = router.get('gw_port')
-        if not gw_port:
-            return []
-        static_snat_rules = self.vswitch_mgr.get_snat_entries(gw_port['id'])
-        # Normalize the list of AVS SNAT rules to provide the equivalent
-        # neutron DNAT rule dict.
-        return [{'inside_addr': s['src-address'],
-                 'inside_port': s['src-proto-key'],
-                 'outside_port': s['nat-proto-key'],
-                 'protocol': s['protocol'].lower()} for s in static_snat_rules]
-
-    def _audit_dnat_rules(self, router):
-        dnat_rules = self._get_dnat_rules(router)
-        local_dnat_rules = {self._make_dnat_key(d): d for d in dnat_rules}
-        dnat_rules = self._get_avs_dnat_rules(router)
-        avs_dnat_rules = {self._make_dnat_key(d): d for d in dnat_rules}
-        # Calculate the delta between the local config and the AVS config
-        missing = set(local_dnat_rules) - set(avs_dnat_rules)
-        stale = set(avs_dnat_rules) - set(local_dnat_rules)
-        # Adjust the installed DNAT rules
-        for key in stale:
-            self._delete_dnat_rule(router, avs_dnat_rules[key])
-        for key in missing:
-            self._add_dnat_rule(router, local_dnat_rules[key])
-
-    def _add_router_port(self, router, port, weight=None, name=None,
-                         gateway=False):
-        LOG.info("AVR add router port: {}".format(port))
-
-        router_id = router.get('id')
-        interface_uuid = port.get('id')
-        mac_address = port.get('mac_address')
-        mtu = port.get(wrs_binding.MTU, n_const.DEFAULT_MTU)
-
-        self.vswitch_mgr.add_router_interface(
-            interface_uuid, router_id, mac_address, mtu,
-            weight=weight, name=name, gateway=gateway)
-
-        self._add_port_addresses(port)
-
-    def _delete_router_port(self, port):
-        LOG.info("AVR delete router port: {}".format(port))
-
-        interface_uuid = port.get('id')
-        self.vswitch_mgr.delete_interface(interface_uuid)
-
-    def _remove_stale_addresses(self, port):
-        """
-        remove stale address entries from the port but exclude automatically
-        acquired addresses, floating-ip address and any link-local addresses.
-        """
-        interface_uuid = port.get('id')
-        addresses = self.vswitch_mgr.get_address_list(
-            interface_uuid=interface_uuid)
-
-        ips = port.get('fixed_ips', [])
-        for ip in ips:
-            address = ip.get('ip_address')
-            if address in addresses:
-                del addresses[address]
-
-        for k, a in six.iteritems(addresses):
-            if (getattr(a, 'floating-ip', False) or
-                    getattr(a, 'autoconf', False)):
-                continue
-            address = netaddr.IPAddress(a['address'])
-            if address.is_link_local():
-                continue
-            LOG.warning("AVR deleting stale address: {} from {}".format(
-                a['address'], interface_uuid))
-            self.vswitch_mgr.delete_address(
-                a['address'], a['prefix-length'], interface_uuid)
-
-    def _add_port_addresses(self, port):
-        # Remove stale addresses before adding new ones to avoid a deficiency
-        # in AVS in how the prefix routes are handled when there are multiple
-        # addresses from the same subnet on the same interface (i.e., deleting
-        # one address in a subnet when another still exists will accidentally
-        # remove the related prefix route which will break further LPM lookups
-        # in that same subnet).
-        self._remove_stale_addresses(port)
-        ips = port.get('fixed_ips', [])
-        for ip in ips:
-            address = ip.get('ip_address')
-            prefixlen = ip.get('prefixlen')
-            self._add_port_address(port, address, prefixlen)
-
-    def _add_port_address(self, port, address, prefixlen):
-        LOG.info("AVR add port address: {}/{} to port {}".
-                 format(address, prefixlen, port))
-        interface_uuid = port.get('id')
-        self.vswitch_mgr.add_address(address, prefixlen, interface_uuid)
-
-    def _delete_port_address(self, port, address, subnet):
-        LOG.info("AVR add port address: {} from {}".format(address, port))
-
-        interface_uuid = port.get('id')
-        prefixlen = netaddr.IPNetwork(subnet['cidr']).prefixlen
-        self.vswitch_mgr.delete_address(address, prefixlen, interface_uuid)
-
-    @staticmethod
-    def _get_default_route_prefix(subnet):
-        cidr = netaddr.IPNetwork(subnet['cidr'])
-        return '0.0.0.0' if cidr.version == 4 else '::'
-
-    def _get_gateway_subnets(self, port):
-        subnets = {}
-        for subnet in port.get('subnets'):
-            if subnet.get('gateway_ip'):
-                cidr = netaddr.IPNetwork(subnet['cidr'])
-                subnets.setdefault(cidr.version, [])
-                subnets[cidr.version].append(subnet)
-        return subnets
-
-    def _add_gateway_default_route(self, router, port):
-        interface_uuid = port.get('id')
-        for version, subnets in self._get_gateway_subnets(port).items():
-            if len(subnets) > 1:
-                LOG.warning(
-                    "AVR gateway port {} has multiple ({}) subnets".format(
-                        interface_uuid, len(subnets)))
-            subnet = subnets[0]
-            gateway = subnet.get('gateway_ip')
-            prefix = self._get_default_route_prefix(subnet)
-            prefixlen = 0
-            self._add_router_route(router, prefix, prefixlen,
-                                   interface_uuid, gateway, replace=True)
-
-    def _add_snat_default_route(self, router, port):
-        # TODO(alegacy) not sure if it is possible to have multiple subnets on
-        # the SNAT port.
-        interface_uuid = port.get('id')
-        subnets = port.get('subnets')
-        if len(subnets) != 1:
-            LOG.warning("AVR SNAT port {} has multiple ({}) subnets".
-                        format(interface_uuid, len(subnets)))
-        subnet = subnets[0]
-        # default route via centralized snat router interface
-        gateway = port['fixed_ips'][0]['ip_address']
-        prefix = self._get_default_route_prefix(subnet)
-        prefixlen = 0
-        self._add_router_route(router, prefix, prefixlen, None, gateway,
-                               replace=True)
-
-    def _get_default_route(self, router):
-        router_id = router.get('id')
-        routes = self.vswitch_mgr.get_router_routes(router_id)
-        for route in routes:
-            if getattr(route, 'prefix-length') == 0:
-                return route
-
-    def _get_default_route_gateway(self, router):
-        route = self._get_default_route(router)
-        if route:
-            for nexthop in route.nexthops:
-                if 'gateway' in nexthop:
-                    return nexthop['gateway']
-
-    def _add_routes(self, router):
-        routes = router.get('routes', [])
-        for route in routes:
-            self._add_route(router, route)
-
-    def _update_routes(self, router):
-        router_id = router.get('id')
-        existing_router = self.routers.get(router_id)
-
-        new_routes = router.get('routes', [])
-        old_routes = existing_router.get('routes', [])
-
-        added, removed = helpers.diff_list_of_dict(old_routes, new_routes)
-        for route in removed:
-            self._delete_route(router, route)
-        for route in added:
-            self._add_route(router, route)
-
-    @staticmethod
-    def _transform_remote_routes(routes):
-        """Transform a route retrieved from vswitch into a neutron route"""
-        for r in routes:
-            # only the router "extra-routes" are considered, therefore filter
-            # out the default route and prefix routes
-            if int(r['prefix-length']) != 0 and r['type'] == 'external':
-                for n in r.nexthops:
-                    yield {
-                        'destination': "%s/%s" % (r['prefix'],
-                                                  r['prefix-length']),
-                        'nexthop': n['gateway']
-                    }
-
-    def _audit_routes(self, local_router):
-        router_id = local_router.get('id')
-        local_routes = local_router.get('routes', [])
-        remote_routes = self._transform_remote_routes(
-            self.vswitch_mgr.get_router_routes(router_id))
-
-        orphaned, missing = helpers.diff_list_of_dict(local_routes,
-                                                      remote_routes)
-
-        for route in orphaned:
-            LOG.warning("AVR remove orphaned route {}".format(route))
-            self._delete_route(local_router, route)
-
-        for route in missing:
-            LOG.warning("AVR add missing route {}".format(route))
-            self._add_route(local_router, route)
-
-    def _add_route(self, router, route):
-        destination = netaddr.IPNetwork(route['destination'])
-        gateway = route.get('nexthop')
-        prefix = destination.ip
-        prefixlen = destination.prefixlen
-        self._add_router_route(router, prefix, prefixlen, None, gateway)
-
-    def _delete_route(self, router, route):
-        destination = netaddr.IPNetwork(route['destination'])
-        prefix = destination.ip
-        prefixlen = destination.prefixlen
-        self._delete_router_route(router, prefix, prefixlen)
-
-    def _add_router_route(self, router, prefix, prefixlen,
-                          interface_uuid, gateway, replace=False):
-        LOG.info("AVR add router route: {}/{} via {} {}".format(
-            prefix, prefixlen, interface_uuid, gateway))
-
-        router_id = router.get('id')
-        self.vswitch_mgr.add_route(router_id, prefix, prefixlen,
-                                   interface_uuid, gateway, replace)
-
-    def _delete_router_route(self, router, prefix, prefixlen):
-        LOG.info("AVR delete router route: {}/{}".format(
-            prefix, prefixlen))
-
-        router_id = router.get('id')
-        self.vswitch_mgr.delete_route(router_id, prefix, prefixlen)
-
-    @staticmethod
-    def _get_router_namespace(router_id):
-        return ROUTER_NS_PREFIX + router_id
-
-    def _create_namespace(self, name):
-        ip_wrapper_root = ip_lib.IPWrapper()
-        ip_ns = ip_wrapper_root.ensure_namespace(name)
-        ip_ns.netns.execute(['sysctl', '-w', 'net.ipv4.ip_forward=1'])
-        ip_ns.netns.execute(['sysctl', '-w', 'net.ipv6.conf.all.forwarding=1'])
-
-    def _delete_namespace(self, name):
-        ip_ns = ip_lib.IPWrapper(namespace=name)
-        try:
-            ip_ns.netns.delete(name)
-        except RuntimeError:
-            msg = 'Failed trying to delete namespace: %s' % name
-            LOG.exception(msg)
-
-    def _get_metadata_proxy_process_manager(self, router_id, ns_name,
-                                            addl_env=None):
-        return external_process.ProcessManager(
-            self.conf,
-            router_id,
-            ns_name,
-            cmd_addl_env=addl_env)
-
-    def _add_metadata_ips(self, router_id, device_name, namespace):
-        device = ip_lib.IPDevice(device_name, namespace=namespace)
-
-        # Add the local metadata IP address
-        ip_cidr = METADATA_DEFAULT_CIDR
-        try:
-            if ip_cidr not in (ip['cidr'] for ip in device.addr.list()):
-                device.addr.add(ip_cidr)
-        except RuntimeError:
-            LOG.warning("Unable to configure IP address for "
-                        "Metadata proxy: %s", ip_cidr)
-
-        # Add the router IP address
-        self.vswitch_mgr.add_address(METADATA_ROUTER_IP,
-                                     METADATA_DEFAULT_PREFIX,
-                                     router_id)
-
-    def _add_metadata_default_route(self, device_name, namespace):
-        ipd = ip_lib.IPDevice(device_name, namespace=namespace)
-        ipd.route.add_gateway(METADATA_ROUTER_IP)
-
-    def _get_metadata_device_name(self, router_id):
-        return (METADATA_DEV_PREFIX + router_id)[:self.vif_driver.DEV_NAME_LEN]
-
-    def _create_metadata_port(self, router_id, ns_name):
-        interface_name = self._get_metadata_device_name(router_id)
-        self._create_metadata_host_port(router_id,
-                                        interface_name,
-                                        self.conf.metadata_mac_address,
-                                        n_const.DEFAULT_MTU,
-                                        namespace=ns_name)
-        self._add_metadata_ips(router_id, interface_name, ns_name)
-        self._add_metadata_default_route(interface_name, ns_name)
-
-    def _destroy_metadata_port(self, router_id, ns_name):
-        interface_name = self._get_metadata_device_name(router_id)
-        self._destroy_metadata_host_port(router_id,
-                                         interface_name,
-                                         namespace=ns_name)
-
-    def _audit_metadata_port(self, router, router_interfaces):
-        router_id = router.get('id')
-        interface_uuid = self._get_metadata_port_uuid(router_id)
-        if interface_uuid not in router_interfaces:
-            self._spawn_metadata_proxy(router)
-        else:
-            # interface exists, and is not an orphan
-            del router_interfaces[interface_uuid]
-
-    def _spawn_metadata_proxy(self, router):
-        if not self.conf.enable_metadata_proxy:
-            return
-
-        router_id = router.get('id')
-        ns_name = self._get_router_namespace(router_id)
-
-        self._create_namespace(ns_name)
-        self._create_metadata_port(router_id, ns_name)
-        metadata_driver.MetadataDriver.spawn_monitored_metadata_proxy(
-            self.process_monitor, ns_name,
-            self.conf.metadata_port,
-            self.conf, router_id=router_id)
-
-    def _destroy_metadata_proxy(self, router):
-        if not self.conf.enable_metadata_proxy:
-            return
-
-        router_id = router.get('id')
-        ns_name = self._get_router_namespace(router_id)
-
-        metadata_driver.MetadataDriver.destroy_monitored_metadata_proxy(
-            self.process_monitor, router_id, self.conf, ns_name)
-        self._destroy_metadata_port(router_id, ns_name)
-
-        self._delete_namespace(ns_name)
-
-    def _get_metadata_port_uuid(self, router_id):
-        # return str(uuid.uuid5(uuid.UUID(router_id), router_id))
-        return router_id
-
-    def _create_metadata_host_port(self, router_id, device_name, mac_address,
-                                   mtu, namespace=None):
-        port_id = self._get_metadata_port_uuid(router_id)
-        ip_wrapper = ip_lib.IPWrapper()
-        ip_ns = ip_wrapper.ensure_namespace(namespace)
-        if not ip_lib.device_exists(device_name,
-                                    namespace=namespace):
-            self.vswitch_mgr.add_port(port_id, device_name,
-                                      mac_address, mtu, neutron=False)
-            self.vswitch_mgr.attach_router_interface(router_id, port_id)
-            self.vswitch_mgr.unlock_port(port_id)
-
-            # Get a reference to the device for link operations
-            device = ip_wrapper.device(device_name)
-
-            # Attempt to move the device to a namespace
-            ip_ns.add_device_to_namespace(device)
-            LOG.info("Device %(name)s has been added "
-                     "to namespace %(namespace)s",
-                     {'name': device_name, 'namespace': namespace})
-        else:
-            LOG.info("Device %s already exists", device_name)
-            # ensure it is attached to the router
-            self.vswitch_mgr.attach_router_interface(router_id, port_id)
-            # Get a reference to the device for link operations
-            device = ip_ns.device(device_name)
-
-        # Attempt to set the interface MTU
-        mtu_value = mtu if mtu else self.conf.network_device_mtu
-        if mtu_value:
-            device.link.set_mtu(mtu_value)
-        # Attempt to bring up linux interface
-        device.link.set_up()
-        LOG.info("Device %s has been set to up", device_name)
-
-    def _destroy_metadata_host_port(self, router_id, device_name,
-                                    namespace=None):
-        if ip_lib.device_exists(device_name,
-                                namespace=namespace):
-            port_id = self._get_metadata_port_uuid(router_id)
-            self.vswitch_mgr.destroy_port(port_id)
-
-
-def _register_opts(conf):
-    conf.register_opts(AVRAgentManager.OPTS)
-    config.register_interface_driver_opts_helper(conf)
-    config.register_agent_state_opts_helper(conf)
-    config.register_availability_zone_opts_helper(conf)
-    config.register_root_helper(conf)
-    meta_conf.register_meta_conf_opts(meta_conf.SHARED_OPTS, conf)
-    conf.register_opts(interface.OPTS)
-    conf.register_opts(external_process.OPTS)
-
-
-def main(manager='neutron.plugins.wrs.agent.avr.agent.AVRAgentManager'):
-    _register_opts(cfg.CONF)
-    common_config.init(sys.argv[1:])
-    config.setup_logging()
-    server = neutron_service.Service.create(
-        binary='neutron-avr-agent',
-        topic=topics.L3_AGENT,
-        report_interval=cfg.CONF.AGENT.report_interval,
-        manager=manager)
-    service.launch(cfg.CONF, server).wait()
diff --git a/neutron/plugins/wrs/agent/avs/__init__.py b/neutron/plugins/wrs/agent/avs/__init__.py
index e69de29..8b13789 100644
--- a/neutron/plugins/wrs/agent/avs/__init__.py
+++ b/neutron/plugins/wrs/agent/avs/__init__.py
@@ -0,0 +1 @@
+
diff --git a/neutron/plugins/wrs/agent/avs/agent.py b/neutron/plugins/wrs/agent/avs/agent.py
index fecd3a2..8b13789 100644
--- a/neutron/plugins/wrs/agent/avs/agent.py
+++ b/neutron/plugins/wrs/agent/avs/agent.py
@@ -1,2613 +1 @@
-#!/usr/bin/env python
-#
-# All Rights Reserved.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-#
-# Copyright (c) 2013-2016 Wind River Systems, Inc.
-#
-# The right to copy, distribute, modify, or otherwise make use
-# of this software may be licensed only pursuant to the terms
-# of an applicable Wind River license agreement.
-#
 
-import collections
-import copy
-import socket
-import sys
-import threading
-import time
-
-import eventlet
-eventlet.monkey_patch()
-
-import netaddr
-from neutron_lib import constants
-from neutron_lib import context
-from oslo_config import cfg
-from oslo_log import log as logging
-import oslo_messaging
-from oslo_service import loopingcall
-from oslo_utils import uuidutils
-import six
-from tsconfig import tsconfig
-
-from neutron._i18n import _
-from neutron.agent import fm as agent_fm
-from neutron.agent import rpc as agent_rpc
-from neutron.agent import securitygroups_rpc as sg_rpc
-from neutron.agent.vswitch import api
-from neutron.agent.vswitch import constants as avs_constants
-from neutron.agent.vswitch import manager
-from neutron.agent.vswitch import vif_api
-from neutron.api.rpc.handlers import dvr_rpc
-from neutron.api.rpc.handlers import pnet_connectivity_rpc
-from neutron.api.rpc.handlers import qos_rpc
-from neutron.api.rpc.handlers import resources_rpc
-from neutron.common import config as common_config
-from neutron.common import constants as n_const
-from neutron.common import ipv6_utils
-from neutron.common import rpc as n_rpc
-from neutron.common import topics
-from neutron.common import utils
-from neutron.conf.agent import common as config
-from neutron.drivers import fm
-from neutron.extensions import securitygroup as ext_sg
-from neutron.extensions import wrs_provider
-from neutron.plugins.common import constants as p_const
-from neutron.plugins.ml2.drivers.l2pop.rpc_manager import l2population_rpc
-from neutron.plugins.wrs.agent.avs import dvr
-from neutron.plugins.wrs.agent.avs import sfc
-from neutron.services.trunk import constants as trunk_constants
-from neutron.services.trunk.rpc import agent as trunk_rpc
-
-
-avs_opts = [
-    cfg.BoolOpt('remove_stale_ports', default=False,
-                help=_("Enable stale port audit which removes ports that do "
-                       "not exist in the DB")),
-    cfg.StrOpt('maintenance_host', default='localhost',
-               help=_("The host name of the maintenance client "
-                      "event listener.")),
-    cfg.IntOpt('maintenance_port', default=2303,
-               help=_("The port number of the maintenance client "
-                      "event listener.")),
-    cfg.IntOpt('status_interval', default=30,
-               help=_("The status reporting interval for tracked resources.")),
-    cfg.IntOpt('polling_interval', default=2,
-               help=_("The number of seconds the agent will wait between "
-                      "polling for local device changes.")),
-    cfg.IntOpt('metering_interval', default=30,
-               help=_("The number of seconds the agent will wait between "
-                      "sending metering notification events.")),
-    cfg.BoolOpt('managed_host_state', default=False,
-                help=_("If false, then host_state_up is always set to true, "
-                       "rather than making a call to get_host_details()")),
-    cfg.BoolOpt('report_port_status', default=False,
-                help=_("If false, then no fault state reports are "
-                       "generated.")),
-    cfg.BoolOpt('managed_providers', default=False,
-                help=_("If false, then provider details are not queried "
-                       "from the server; local config is used instead.")),
-]
-
-agent_opts = [
-    cfg.ListOpt('physical_interface_mappings',
-                default=[],
-                help=_("List of <physical_interface>:<physical_network>")),
-    cfg.BoolOpt('enable_distributed_routing',
-                default=False,
-                help=_("Enable distributed virtual routing")),
-]
-
-vxlan_opts = [
-    cfg.StrOpt('default_group',
-               default=n_const.DEFAULT_VXLAN_GROUP,
-               help=_("Defines the default multicast group to use for "
-                      "VXLAN interfaces")),
-    cfg.IntOpt('default_port',
-               default=n_const.DEFAULT_VXLAN_UDP_PORT,
-               help=_("Defines the default destination UDP port to use for "
-                      "VXLAN interfaces ")),
-    cfg.IntOpt('default_ttl',
-               default=n_const.DEFAULT_VXLAN_TTL,
-               help=_("Defines the default time-to-live value to use for "
-                      "VXLAN interfaces"))
-]
-
-sdn_opts = [
-    cfg.StrOpt('integration_bridge_name',
-               default='br-int',
-               help=_("Defines the default integration bridge name")),
-]
-
-
-LOG = logging.getLogger(__name__)
-
-LB_PORT_NAME_PREFIX = "tap"
-LB_PORT_UUID_TAP_LEN = 11
-
-# Interface status severity
-INTERFACE_SEVERITY_CLEAR = fm.FM_SEVERITY_CLEAR
-INTERFACE_SEVERITY_MAJOR = fm.FM_SEVERITY_MAJOR
-INTERFACE_SEVERITY_CRITICAL = fm.FM_SEVERITY_CRITICAL
-
-# DVR MAC Address Audit Interval in seconds
-DVR_MAC_ADDRESS_AUDIT_INTERVAL = 10
-
-# Fault Audit Interval in seconds
-FAULT_AUDIT_INTERVAL = 60
-
-# Represents the list of neutron device owner values that are mapped to an
-# actual AVS port rather than an AVS interface.
-#
-AVS_VIRTUAL_PORT_TYPES = [constants.DEVICE_OWNER_DHCP, ]
-
-# Represents the list of neutron device owner values that are associated with
-# external bridges when running in SDN mode
-#
-DEVICES_ON_EXTERNAL_NETWORKS = [constants.DEVICE_OWNER_ROUTER_GW,
-                                constants.DEVICE_OWNER_AGENT_GW]
-
-# FDB operations
-FDB_ADD = "add"
-FDB_REMOVE = "remove"
-
-FLOODING_ENTRY_MAC = '00:00:00:00:00:00'
-
-# These modes need L2POP assistance
-L2POP_VXLAN_MODES = [n_const.PROVIDERNET_VXLAN_STATIC]
-
-
-def is_primary_address(address):
-    return bool(address.preference == "primary")
-
-
-def is_avs_port(device_owner):
-    """
-    Determine whether a device is represented by an AVS port rather than an AVS
-    interface.
-    """
-    if device_owner in AVS_VIRTUAL_PORT_TYPES:
-        return True
-    elif device_owner.startswith('compute:'):
-        return True
-    elif device_owner.startswith('trunk:'):
-        return True
-    return False
-
-
-class VSwitchBaseRpcCallbacksMixin(object):
-
-    def port_update(self, context, **kwargs):
-        """
-        RPC request handler to service data updates on ports from plugin.
-        """
-        port = kwargs.get('port')
-        LOG.debug("RPC port_update received %(port)s", locals())
-        if not self.is_port_present(port['id']):
-            # Since this command only expects to update ports that have already
-            # been setup properly we need to ignore any updates until the port
-            # has been discovered and attached to its network
-            #
-            LOG.debug("Ignoring port_update for {} until auto-discovered".
-                      format(port['id']))
-            return
-
-        device_owner = port.get('device_owner')
-        if device_owner and is_avs_port(device_owner):
-            # Only neutron ports that map to an AVS port (i.e., a router
-            # interface is an interface in AVS and not a port and as such does
-            # not support a lock/unlock action).  The server state has changed
-            # for this port so force it to run through our update path to make
-            # sure that we send up our latest local state.
-            self.mark_port_for_refresh(port['id'])
-
-    def network_delete(self, context, **kwargs):
-        """
-        RPC request handler to service network delete operations from plugin.
-        """
-        network_id = kwargs.get('network_id')
-        LOG.debug("RPC network_delete received %(network_id)s", locals())
-        networks = self.virtual_networks
-        in_use_interfaces = self._pnet_connectivity_interface_uuids()
-        if network_id in networks:
-            network = networks[network_id]
-            if network['type'] == avs_constants.VSWITCH_LAYER2_NETWORK:
-                self.remove_network(network_id, in_use_interfaces)
-
-    def agent_updated(self, context, payload):
-        """Handle the agent_updated notification event."""
-        LOG.info("agent_updated by server side %s", payload)
-        self.admin_state_up = payload['admin_state_up']
-
-    def host_updated(self, context, payload):
-        """Handle the host_updated notification event."""
-        LOG.info("host_updated by server side %s", payload)
-        self.host_state_up = payload['host_state_up']
-
-
-class VSwitchTrunkStub(trunk_rpc.TrunkStub):
-    """
-    API for all agent to server RPC communications.
-    """
-    def get_trunk_details(self, context, parent_port_id):
-        try:
-            return super(VSwitchTrunkStub, self).get_trunk_details(
-                context, parent_port_id)
-        except resources_rpc.ResourceNotFound:
-            LOG.debug("Port %s has no associated trunk.", parent_port_id)
-            return
-
-
-class VSwitchTrunkSkeletonMixin(trunk_rpc.TrunkSkeleton):
-    """
-    API for all server to agent RPC communications.
-    """
-    def __init__(self, **kwargs):
-        super(VSwitchTrunkSkeletonMixin, self).__init__()
-
-    def handle_trunks(self, context, resource_type, trunks, event_type):
-        """Handle trunk events."""
-        LOG.debug("handle_trunks event_type={} trunks={}".format(
-            event_type, trunks))
-        for trunk in trunks:
-            if self.is_port_present(trunk['port_id']):
-                self.mark_port_for_refresh(trunk['port_id'])
-
-    def handle_subports(self, context, resource_type, subports, event_type):
-        """Handle subports event."""
-        LOG.debug("handle_subports event_type={} trunks={} ".format(
-            event_type, subports))
-        for subport in subports:
-            trunk_details = self.trunk_details.get(subport['trunk_id'])
-            if trunk_details:
-                self.mark_port_for_refresh(trunk_details['port_id'])
-
-
-class VSwitchFDBCache(object):
-    """Tracks which FDB entries have been successfully added/removed.
-
-    This class implements a cache that manages VTEP gateway and device
-    records.  We use the cache in order to be able to audit the AVS VXLAN
-    endpoint records in the event that the process restarts and we have to
-    re-sync AVS to the neutron DB.
-    """
-
-    def __init__(self):
-        # cache all gateways and devices by provider interface_uuid
-        self.cache = collections.defaultdict(self._default_cache_item)
-        self.networks = {}
-
-    @staticmethod
-    def _default_cache_item():
-        return {'gateways': set(), 'devices': {}, 'ip-devices': {}}
-
-    def map_network(self, network_id, interface_uuid):
-        self.networks[network_id] = interface_uuid
-
-    def unmap_network(self, network_id):
-        return self.networks.pop(network_id, None)
-
-    def remove_interface(self, interface_uuid):
-        if interface_uuid in self.cache:
-            del self.cache[interface_uuid]
-
-    @staticmethod
-    def make_device_key(device):
-        return device['mac_address']
-
-    @staticmethod
-    def _make_device(mac_address, gateway_ip):
-        device = {'mac_address': mac_address,
-                  'gateway_ip': gateway_ip}
-        return device
-
-    def add_device(self, interface_uuid, mac_address, gateway_ip):
-        device = self._make_device(mac_address, gateway_ip)
-        key = self.make_device_key(device)
-        cache = self.cache[interface_uuid]
-        cache['devices'][key] = device
-
-    def remove_device(self, interface_uuid, mac_address):
-        cache = self.cache[interface_uuid]
-        if mac_address in cache['devices']:
-            del cache['devices'][mac_address]
-
-    def remove_gateway_devices(self, interface_uuid, gateway_ip):
-        cache = self.cache[interface_uuid]
-        for device in cache['devices'].values():
-            if device['gateway_ip'] == gateway_ip:
-                key = self.make_device_key(device)
-                del cache['devices'][key]
-
-    def _get_device(self, interface_uuid, key):
-        cache = self.cache[interface_uuid]
-        if key in cache['devices']:
-            return cache['devices'][key]
-
-    def get_device(self, interface_uuid, mac_address):
-        return self._get_device(interface_uuid, mac_address)
-
-    def device_installed(self, interface_uuid, mac_address, gateway_ip):
-        device = self.get_device(interface_uuid, mac_address)
-        if device:
-            return bool(not gateway_ip or device['gateway_ip'] == gateway_ip)
-
-    def get_devices(self, interface_uuid):
-        cache = self.cache[interface_uuid]
-        return cache['devices'].values()
-
-    @staticmethod
-    def make_ip_device_key(device):
-        return device['ip_address']
-
-    @staticmethod
-    def _make_ip_device(ip_address, mac_address, gateway_ip):
-        device = {'mac_address': mac_address,
-                  'ip_address': ip_address,
-                  'gateway_ip': gateway_ip}
-        return device
-
-    def add_ip_device(self, interface_uuid, ip_address, mac_address,
-                      gateway_ip):
-        device = self._make_ip_device(ip_address, mac_address, gateway_ip)
-        key = self.make_ip_device_key(device)
-        cache = self.cache[interface_uuid]
-        cache['ip-devices'][key] = device
-
-    def remove_ip_device(self, interface_uuid, ip_address):
-        cache = self.cache[interface_uuid]
-        if ip_address in cache['ip-devices']:
-            del cache['ip-devices'][ip_address]
-
-    def remove_gateway_ip_devices(self, interface_uuid, gateway_ip):
-        cache = self.cache[interface_uuid]
-        for device in cache['ip-devices'].values():
-            if device['gateway_ip'] == gateway_ip:
-                key = self.make_ip_device_key(device)
-                del cache['ip-devices'][key]
-
-    def _get_ip_device(self, interface_uuid, key):
-        cache = self.cache[interface_uuid]
-        if key in cache['ip-devices']:
-            return cache['ip-devices'][key]
-
-    def get_ip_device(self, interface_uuid, ip_address):
-        return self._get_ip_device(interface_uuid, ip_address)
-
-    def ip_device_installed(self, interface_uuid, ip_address, mac_address,
-                            gateway_ip):
-        device = self.get_ip_device(interface_uuid, ip_address)
-        if device:
-            return bool(device['mac_address'] == mac_address and
-                        (not gateway_ip or device['gateway_ip'] == gateway_ip))
-
-    def get_ip_devices(self, interface_uuid):
-        cache = self.cache[interface_uuid]
-        return cache['ip-devices'].values()
-
-    def add_gateway(self, interface_uuid, gateway_ip):
-        cache = self.cache[interface_uuid]
-        cache['gateways'].add(gateway_ip)
-
-    def remove_gateway(self, interface_uuid, gateway_ip):
-        cache = self.cache[interface_uuid]
-        if gateway_ip in cache['gateways']:
-            cache['gateways'].remove(gateway_ip)
-
-    def get_gateway(self, interface_uuid, gateway_ip):
-        cache = self.cache[interface_uuid]
-        if gateway_ip in cache['gateways']:
-            return gateway_ip
-
-    def get_gateways(self, interface_uuid):
-        cache = self.cache[interface_uuid]
-        return cache['gateways']
-
-
-class VSwitchRpcCallbacksMixin(VSwitchBaseRpcCallbacksMixin,
-                               VSwitchTrunkSkeletonMixin,
-                               sg_rpc.SecurityGroupAgentRpcCallbackMixin,
-                               qos_rpc.QoSAgentRpcCallbackMixin,
-                               dvr_rpc.DVRAgentRpcCallbackMixin,
-                               l2population_rpc.L2populationRpcCallBackMixin,
-                               pnet_connectivity_rpc.PnetConnectivityRpc):
-
-    # Set RPC API version to 1.0 by default.
-    # history
-    #   1.1 Support Security Group RPC
-    #   1.2 Support QoS RPC
-    #   1.3 Support DVR (Distributed Virtual Router) RPC
-
-    target = oslo_messaging.Target(version='1.2')
-
-    def port_update(self, context, **kwargs):
-        """
-        RPC request handler to service data updates on ports from plugin.
-        """
-        port = kwargs.get('port')
-        if not self.is_port_present(port['id']):
-            # Since this command only expects to update ports that have already
-            # been setup properly we need to ignore any updates until the port
-            # has been discovered and attached to its network
-            #
-            LOG.debug("Ignoring port_update for {} until auto-discovered".
-                      format(port['id']))
-            return
-
-        if ext_sg.SECURITYGROUPS in port:
-            devices = [VSwitchNeutronAgent._get_device_name(port['id'])]
-            if port[ext_sg.SECURITYGROUPS]:
-                self.sg_agent.prepare_devices_filter(devices)
-                self.sg_agent.refresh_firewall()
-            else:
-                self.sg_agent.remove_devices_filter(devices)
-
-        super(VSwitchRpcCallbacksMixin, self).port_update(context, **kwargs)
-
-    def subnet_create(self, context, **kwargs):
-        """
-        RPC request handler to service subnet create operations from plugin.
-        """
-        LOG.debug("RPC subnet_create received {}".format(kwargs))
-
-    def subnet_delete(self, context, **kwargs):
-        """
-        RPC request handler to service subnet delete operations from plugin.
-        """
-        LOG.debug("RPC subnet_delete received {}".format(kwargs))
-
-    def _fdb_resolve_interface(self, segment):
-        """
-        Determine which VXLAN interface these FDB entries are targeting.
-        """
-        physical_network = segment['physical_network']
-        if 'segment_id' in segment:
-            # Data coming from l2pop RPC with incorrect attribute name
-            segmentation_id = segment['segment_id']
-        else:
-            segmentation_id = segment['segmentation_id']
-        interface_uuid = self.interface_mappings[physical_network]
-        return self.vswitch_mgr.get_provider_interface_uuid(
-            interface_uuid, segment['network_type'], segmentation_id)
-
-    def _is_local_agent_ip(self, physical_network, agent_ips):
-        """
-        Determine whether the FDB record references this agent.
-        """
-        local_ips = self.tunneling_ips.get(physical_network, '')
-        agent_set = set(agent_ips.split(',') if agent_ips else [])
-        local_set = set(local_ips.split(',') if local_ips else [])
-        return bool(local_set & agent_set)
-
-    def _select_local_agent_ip(self, physical_network, agent_ips):
-        """
-        Determine which address we should use to contact the remote VTEP.  If
-        we have both an IPv4 and IPv6 and so does the remote VTEP then we will
-        prefer an IPv6 address; otherwise, use a compatible address.
-        """
-        local_ips = self.tunneling_ips.get(physical_network)
-        if not local_ips:
-            LOG.warning("unable to select a local IP for "
-                        "physical network {}".format(physical_network))
-            return None
-        agent_list = agent_ips.split(',')
-        local_list = local_ips.split(',')
-        agent_v6 = [a for a in agent_list if netaddr.IPAddress(a).version == 6]
-        local_v6 = [a for a in local_list if netaddr.IPAddress(a).version == 6]
-        if agent_v6 and local_v6:
-            return agent_v6[0]
-        agent_v4 = [a for a in agent_list if netaddr.IPAddress(a).version == 4]
-        local_v4 = [a for a in local_list if netaddr.IPAddress(a).version == 4]
-        if agent_v4 and local_v4:
-            return agent_v4[0]
-        return None
-
-    def _fdb_ip_add_entry(self, interface_uuid, ip_address,
-                          mac_address, agent_ip):
-        if mac_address == FLOODING_ENTRY_MAC:
-            return  # let the layer2 handler deal with this
-        if self.fdb_cache.ip_device_installed(
-                interface_uuid, ip_address, mac_address, agent_ip):
-            return
-        LOG.info("adding VTEP IP endpoint for {}/{} via {} over {}".
-                 format(mac_address, ip_address, agent_ip, interface_uuid))
-        self.vswitch_mgr.add_vtep_ip_endpoint(
-            interface_uuid, ip_address, mac_address, agent_ip)
-        self.fdb_cache.add_ip_device(
-            interface_uuid, ip_address, mac_address, agent_ip)
-
-    def _fdb_ip_delete_entry(self, interface_uuid, ip_address,
-                             mac_address, agent_ip):
-        if mac_address == FLOODING_ENTRY_MAC:
-            return  # let the layer2 handler deal with this
-        if not self.fdb_cache.ip_device_installed(
-                interface_uuid, ip_address, mac_address, agent_ip):
-            if self.fdb_cache.get_ip_device(interface_uuid, ip_address):
-                # Only log if we have this entry but via a different gwy
-                LOG.warning("not removing VTEP IP endpoint {}/{} "
-                            "via {} over {}".format(
-                                mac_address, ip_address, agent_ip or '*',
-                                interface_uuid))
-            return
-        LOG.info("removing VTEP IP endpoint for {}/{} via {} over {}".
-                 format(mac_address, ip_address, agent_ip or '*',
-                        interface_uuid))
-        self.vswitch_mgr.delete_vtep_ip_endpoint(
-            interface_uuid, ip_address)
-        self.fdb_cache.remove_ip_device(interface_uuid, ip_address)
-
-    def _fdb_add_entry(self, interface_uuid, mac_address, agent_ip):
-        """
-        Handle insertion of one FDB entry.
-        """
-        if mac_address == FLOODING_ENTRY_MAC:
-            if self.fdb_cache.get_gateway(interface_uuid, agent_ip):
-                return
-            LOG.info("adding VTEP peer {} over {}".format(
-                agent_ip, interface_uuid))
-            self.vswitch_mgr.add_vtep_peer(interface_uuid, agent_ip)
-            self.fdb_cache.add_gateway(interface_uuid, agent_ip)
-        else:
-            if not self.fdb_cache.get_gateway(interface_uuid, agent_ip):
-                # NOTE(alegacy): There are some cases where the server does
-                # not send a flood entry because it thinks that all nodes
-                # have already added it back when the first FDB entry was
-                # sent for that network.   That creates a race condition
-                # where a new node creates its first port on the network
-                # just as the server sends out another FDB update for that
-                # network (without a flood entry added).  To avoid this race
-                # condition we will just go ahead and add the flood entry
-                # on our own.
-                self._fdb_add_entry(interface_uuid, FLOODING_ENTRY_MAC,
-                                    agent_ip)
-
-            if self.fdb_cache.device_installed(
-                    interface_uuid, mac_address, agent_ip):
-                LOG.debug("ignoring VTEP endpoint for {} via {} over {}".
-                          format(mac_address, agent_ip, interface_uuid))
-                return
-            LOG.info("adding VTEP endpoint for {} via {} over {}".format(
-                mac_address, agent_ip, interface_uuid))
-            self.vswitch_mgr.add_vtep_endpoint(
-                interface_uuid, mac_address, agent_ip)
-            self.fdb_cache.add_device(
-                interface_uuid, mac_address, agent_ip)
-
-    def _fdb_delete_entry(self, interface_uuid, mac_address, agent_ip):
-        """
-        Handle removal of one FDB entry.
-        """
-        if mac_address == FLOODING_ENTRY_MAC and not agent_ip:
-            # NOTE(alegacy): ignore wildcard agent_ip delete operations
-            return
-        if mac_address == FLOODING_ENTRY_MAC:
-            if not self.fdb_cache.get_gateway(interface_uuid, agent_ip):
-                return
-            LOG.info("removing VTEP peer {} over {}".format(
-                agent_ip, interface_uuid))
-            self.vswitch_mgr.delete_vtep_peer(interface_uuid, agent_ip)
-            self.fdb_cache.remove_gateway_ip_devices(interface_uuid, agent_ip)
-            self.fdb_cache.remove_gateway_devices(interface_uuid, agent_ip)
-            self.fdb_cache.remove_gateway(interface_uuid, agent_ip)
-        else:
-            if not self.fdb_cache.device_installed(
-                    interface_uuid, mac_address, agent_ip):
-                # NOTE(alegacy): avoid removing entries from mismatched agent
-                # ip addresses.  The server sends down withdraw events when
-                # a port is deleted from a server regardless if that port has
-                # already been successfully installed on a different server
-                # therefore it is possible that a late withdraw notification
-                # could delete a valid entry.
-                if self.fdb_cache.get_device(interface_uuid, mac_address):
-                    # Only log if we have this entry but via a different gwy
-                    LOG.warning("not removing VTEP endpoint {} via {} over {}".
-                                format(mac_address, agent_ip or '*',
-                                       interface_uuid))
-                return
-            LOG.info("removing VTEP endpoint for {} via {} over {}".
-                     format(mac_address, agent_ip or '*', interface_uuid))
-            self.vswitch_mgr.delete_vtep_endpoint(interface_uuid, mac_address)
-            self.fdb_cache.remove_device(interface_uuid, mac_address)
-
-    def _get_fdb_installed_gateways(self, interface_uuid):
-        data = self.vswitch_mgr.get_vtep_peers(interface_uuid)
-        return [d['address'] for d in data]
-
-    def _get_fdb_installed_ip_devices(self, interface_uuid):
-        data = self.vswitch_mgr.get_vtep_ip_endpoints(interface_uuid)
-        devices = [{'mac_address': d['mac-address'],
-                    'ip_address': d['device-address']} for d in data]
-        return devices
-
-    def _get_fdb_installed_devices(self, interface_uuid):
-        data = self.vswitch_mgr.get_vtep_endpoints(
-            interface_uuid, static=True)
-        devices = [{'mac_address': d['mac-address']} for d in data]
-        return devices
-
-    def _fdb_audit_network_gateways(self, interface_uuid):
-        cached = self.fdb_cache.get_gateways(interface_uuid)
-        installed = self._get_fdb_installed_gateways(interface_uuid)
-        stale = set(installed) - set(cached)
-        for gateway in stale:
-            LOG.info("removing stale VTEP Peer {} over {}".format(
-                gateway, interface_uuid))
-            self.vswitch_mgr.delete_vtep_peer(
-                interface_uuid, gateway)
-
-    def _fdb_audit_network_devices(self, interface_uuid):
-        cached = self.fdb_cache.get_devices(interface_uuid)
-        installed = self._get_fdb_installed_devices(interface_uuid)
-        previous = set([d['mac_address'] for d in installed])
-        current = set([d['mac_address'] for d in cached])
-        stale = previous - current
-        for mac_address in stale:
-            LOG.info("removing stale VTEP endpoint for {} over {}".format(
-                mac_address, interface_uuid))
-            self.vswitch_mgr.delete_vtep_endpoint(
-                interface_uuid, mac_address)
-
-    def _fdb_audit_network_ip_devices(self, interface_uuid):
-        cached = self.fdb_cache.get_ip_devices(interface_uuid)
-        installed = self._get_fdb_installed_ip_devices(interface_uuid)
-        previous = set([d['ip_address'] for d in installed])
-        current = set([d['ip_address'] for d in cached])
-        stale = previous - current
-        for ip_address in stale:
-            LOG.info("removing stale VTEP IP endpoint for {}/{} over {}".
-                     format(d['mac_address'], d['ip_address'], interface_uuid))
-            self.vswitch_mgr.delete_vtep_ip_endpoint(
-                interface_uuid, ip_address)
-
-    def _fdb_audit_for_network(self, interface_uuid):
-        """Audit FDB between local DB and AVS.
-
-        The audit is triggered after successfully processing a full FDB sync
-        record from the server so we assume that all DB records are installed
-        in AVS; otherwise an error would have occurred.  For that reason the
-        audit only worries about finding stale entries and not missing
-        entries.
-        """
-        self._fdb_audit_network_ip_devices(interface_uuid)
-        self._fdb_audit_network_devices(interface_uuid)
-        self._fdb_audit_network_gateways(interface_uuid)
-
-    @utils.synchronized('avs-fdb-cache')
-    def fdb_audit(self):
-        for interface_uuid in self.fdb_audits.keys():
-            LOG.info("Auditing FDB for interface {}".format(
-                interface_uuid))
-            self._fdb_audit_for_network(interface_uuid)
-            del self.fdb_audits[interface_uuid]
-
-    def _trigger_fdb_audit_for_network(self, interface_uuid):
-        self.fdb_audits[interface_uuid] = True
-
-    def get_fdb_handlers(self):
-        return {FDB_ADD: {"mac": self._fdb_add_entry,
-                          "ip": self._fdb_ip_add_entry},
-                FDB_REMOVE: {"mac": self._fdb_delete_entry,
-                             "ip": self._fdb_ip_delete_entry}}
-
-    def _process_fdb_for_network(self, network_id, fdb_entries, operation):
-        """
-        Handle new FDB entries for a given network_id.
-        """
-        interface_uuid = self._fdb_resolve_interface(fdb_entries)
-        self.fdb_cache.map_network(network_id, interface_uuid)
-        port_entries = fdb_entries['ports']
-        LOG.debug("processing VTEP endpoints for interface "
-                  "{} on network {}".format(interface_uuid, network_id))
-        for agent_ips, ports in six.iteritems(port_entries):
-            if self._is_local_agent_ip(
-                    fdb_entries['physical_network'], agent_ips):
-                # If the device is now present on the local vswitch we want
-                # to make sure that we do not have any stale records that are
-                # pointing to another compute node for these MAC/IP pairs.
-                # This can happen in some cases where the previous agent dies
-                # before it can do a proper "update_device_down()" to signal
-                # that the port is no longer present on that node.
-                handlers = self.get_fdb_handlers()[FDB_REMOVE]
-                reverse = True
-                agent_ip = None
-                LOG.debug("attempting to remove stale FDB records for "
-                          "local devices: {}".format(ports))
-            else:
-                handlers = self.get_fdb_handlers()[operation]
-                reverse = True if operation == FDB_REMOVE else False
-                agent_ip = self._select_local_agent_ip(
-                    fdb_entries['physical_network'], agent_ips)
-                if not agent_ip:
-                    LOG.warning("no compatible address to reach {}".format(
-                        agent_ips))
-                    continue
-
-            sorted_ports = sorted(copy.deepcopy(ports),
-                                  key=lambda x: x.mac_address,
-                                  reverse=reverse)
-            for p in sorted_ports:
-                handlers['mac'](interface_uuid, p.mac_address, agent_ip)
-                handlers['ip'](
-                    interface_uuid, p.ip_address, p.mac_address, agent_ip)
-
-        if fdb_entries.get('audit'):
-            self._trigger_fdb_audit_for_network(interface_uuid)
-
-    def _is_static_vxlan_segment(self, network_id, segment):
-        if 'segment_id' in segment:
-            # fix l2pop data
-            segment['segmentation_id'] = segment['segment_id']
-        providernet_key = self.get_providernet_key(segment)
-        details = self.providernet_cache.get(providernet_key)
-        if details and details['type'] == 'vxlan':
-            if details['vxlan']['mode'] in L2POP_VXLAN_MODES:
-                return True
-        return False
-
-    @utils.synchronized('avs-fdb-cache')
-    def fdb_add(self, context, fdb_entries):
-        """
-        Handle new FDB entries published to this agent (or all agents).
-        """
-        source = fdb_entries.get('source', topics.L2POPULATION)
-        LOG.debug("fdb_add received from {}: {}".format(source, fdb_entries))
-        for network_id, fdb_entries in six.iteritems(fdb_entries):
-            if network_id not in self.virtual_networks:
-                # NOTE(alegacy): skip for now but it will be replayed by the
-                # mech driver when/if we enable the first port on this network
-                LOG.debug("skipping FDB add on missing network {}, fdb: {}".
-                          format(network_id, fdb_entries))
-                continue
-            if not self._is_static_vxlan_segment(network_id, fdb_entries):
-                continue
-            self._process_fdb_for_network(network_id, fdb_entries, FDB_ADD)
-
-    @utils.synchronized('avs-fdb-cache')
-    def fdb_remove(self, context, fdb_entries):
-        """
-        Handle new FDB entries published to this agent (or all agents).
-        """
-        source = fdb_entries.get('source', topics.L2POPULATION)
-        LOG.debug("fdb_remove received from {}: {}".format(
-            source, fdb_entries))
-        for network_id, fdb_entries in six.iteritems(fdb_entries):
-            if network_id not in self.virtual_networks:
-                LOG.debug("skipping FDB delete on missing network {}, fdb: {}".
-                          format(network_id, fdb_entries))
-                continue
-            if not self._is_static_vxlan_segment(network_id, fdb_entries):
-                continue
-            self._process_fdb_for_network(network_id, fdb_entries, FDB_REMOVE)
-
-    def _process_ip_change_for_network(self, network_id, ip_changes):
-        """
-        Handle new FDB entries for a given network_id.
-        """
-        segment = self.segment_cache[network_id]  # not available in ip_chg
-        if not self._is_static_vxlan_segment(network_id, segment):
-            return
-        interface_uuid = self._fdb_resolve_interface(segment)
-        self.fdb_cache.map_network(network_id, interface_uuid)
-        LOG.debug("processing VTEP IP endpoints for interface {} on "
-                  "network {}".format(interface_uuid, network_id))
-        for agent_ips, changes in six.iteritems(ip_changes):
-            if self._is_local_agent_ip(segment['physical_network'], agent_ips):
-                continue
-            agent_ip = self._select_local_agent_ip(
-                segment['physical_network'], agent_ips)
-            if not agent_ip:
-                LOG.warning("no compatible address to reach {}".format(
-                    agent_ips))
-                continue
-            for port_info in changes.get('before', []):
-                self._fdb_ip_delete_entry(
-                    interface_uuid, port_info.ip_address,
-                    port_info.mac_address, agent_ip)
-            for port_info in changes.get('after', []):
-                self._fdb_ip_add_entry(
-                    interface_uuid, port_info.ip_address,
-                    port_info.mac_address, agent_ip)
-
-    @utils.synchronized('avs-fdb-cache')
-    def fdb_update(self, context, fdb_entries):
-        source = fdb_entries.get('source', topics.L2POPULATION)
-        LOG.debug("fdb_update received from {}: {}".format(
-            source, fdb_entries))
-        ip_delta = fdb_entries['chg_ip']
-        for network_id, ip_changes in six.iteritems(ip_delta):
-            if network_id not in self.virtual_networks:
-                LOG.debug("skipping FDB IP change on missing network {}, "
-                          "fdb: {}".format(network_id, ip_changes))
-                continue
-            self._process_ip_change_for_network(network_id, ip_changes)
-
-
-class VSwitchSdnRpcCallbacksMixin(VSwitchBaseRpcCallbacksMixin):
-
-    def subnet_create(self, context, **kwargs):
-        # Nothing to be done for SDN
-        pass
-
-    def subnet_delete(self, context, **kwargs):
-        # Nothing to be done for SDN
-        pass
-
-
-class VSwitchSecurityGroupAgentRpc(sg_rpc.SecurityGroupAgentRpc):
-
-    def register_manager(self, manager):
-        if hasattr(self.firewall, 'register_manager'):
-            self.firewall.register_manager(manager)
-
-    @property
-    def use_enhanced_rpc(self):
-        # FIXME(alegacy) we do not yet support the new, more compact, form of
-        # security group rule queries.  Until we do we need to force the use
-        # of the legacy code by returning false with this method
-        return False
-
-
-class VSwitchNetworkSegmentInterface(object):
-
-    def __init__(self, providernet_id, providernet_name, providernet_type,
-                 segment, interface_uuid, lower_uuid=None):
-        self.providernet_id = providernet_id
-        self.providernet_name = providernet_name
-        self.providernet_type = providernet_type
-        self.segment = segment
-        self.interface_uuid = interface_uuid
-        self.lower_uuid = lower_uuid
-
-
-class VSwitchBaseNeutronAgent(vif_api.VifAgentListenerMixin,
-                              agent_fm.FmAgentMixin):
-
-    def __init__(self,
-                 interface_mappings,
-                 polling_interval,
-                 metering_interval,
-                 status_interval,
-                 vswitch_api,
-                 enable_distributed_routing=False):
-        super(VSwitchBaseNeutronAgent, self).__init__()
-        self.admin_state_up = True
-        self.host_state_up = None
-        self.interface_mappings = interface_mappings
-        self.polling_interval = polling_interval
-        self.metering_interval = metering_interval
-        self.status_interval = status_interval
-        self.enable_distributed_routing = enable_distributed_routing
-        self.vswitch_mgr = manager.VSwitchManager(
-            vswitch_api, interface_mappings)
-        self._notifier = n_rpc.get_notifier('metering')
-        self.host = cfg.CONF.host
-        self.tunnel_types = [p_const.TYPE_VXLAN]
-        self.tunneling_ips = None
-        self.agent_state = {
-            'binary': 'neutron-avs-agent',
-            'host': self.host,
-            'availability_zone': cfg.CONF.AGENT.availability_zone,
-            'topic': constants.L2_AGENT_TOPIC,
-            'configurations': {
-                'mappings': interface_mappings,
-                'enable_distributed_routing': self.enable_distributed_routing,
-                'tunnel_types': self.tunnel_types},
-            'agent_type': n_const.AGENT_TYPE_WRS_VSWITCH,
-            'start_flag': True}
-        self.setup_vif_listener()
-        self.setup_rpc()
-        self.init_fm()
-        self.port_details = {}
-        self.trunk_details = {}
-        self.sfc_details = {}
-        self.interface_details = {}
-        self.port_stats = {}
-        self.virtual_ports = {}
-        self.virtual_networks = {}
-        self.segment_cache = {}
-        self.providernet_cache = {}
-        self.interfaces = {}
-        self.stale_interfaces = set()
-        self.deferred_ports = collections.defaultdict(dict)
-        self.phys_ports = {}
-        self.router_interfaces = {}
-        self.metering_timestamp = 0
-        self.stale_ports = {}
-        self.updated_ports = set()
-
-    def remove_network(self, network_id, in_use_interfaces):
-        self.vswitch_mgr.delete_network(network_id, in_use_interfaces)
-        self.virtual_networks.pop(network_id, None)
-        segment = self.segment_cache.pop(network_id, None)
-        self.providernet_cache.pop(
-            self.get_providernet_key(segment), None)
-        for uuid, iface in self.interface_details.items():
-            if iface['network_id'] == network_id:
-                self.interface_details.pop(uuid, None)
-
-    def notify_mainloop(self):
-        self.vif_event.set()
-        eventlet.greenthread.sleep(0)  # yield
-
-    def vif_created(self, vif_id):
-        LOG.debug("VIF created with uuid={}".format(vif_id))
-        self.notify_mainloop()
-
-    def vif_deleted(self, vif_id):
-        LOG.debug("VIF deleted with uuid={}".format(vif_id))
-        self.notify_mainloop()
-
-    def vif_error_handler(self, exception):
-        LOG.exception("VIF listener exception {}".format(exception))
-
-    def setup_vif_listener(self):
-        self.vif_event = threading.Event()
-        self.vif_listener = vif_api.VifAgentListener(self)
-
-    def rpc_consumers(self):
-        return [[topics.HOST, topics.UPDATE, self.host],
-                [topics.PORT, topics.UPDATE],
-                [topics.NETWORK, topics.DELETE],
-                [topics.SUBNET, topics.CREATE],
-                [topics.SUBNET, topics.DELETE]]
-
-    def setup_rpc(self):
-        self.agent_id = '%s-%s' % ('avs', socket.gethostname())
-        LOG.debug("RPC agent_id: %s", self.agent_id)
-        self.topic = topics.AGENT
-        self.plugin_rpc = agent_rpc.PluginApi(topics.PLUGIN)
-        self.state_rpc = agent_rpc.PluginReportStateAPI(topics.PLUGIN)
-        # RPC network init
-        self.context = context.get_admin_context_without_session()
-        # Handle updates from service
-        self.endpoints = [self]
-        self.connection = agent_rpc.create_consumers(self.endpoints,
-                                                     self.topic,
-                                                     self.rpc_consumers())
-        report_interval = cfg.CONF.AGENT.report_interval
-        if report_interval:
-            heartbeat = loopingcall.FixedIntervalLoopingCall(
-                self._report_agent_state)
-            heartbeat.start(interval=report_interval)
-
-    def get_vif_port_by_id(self, port_id):
-        """
-        Retrieve the virtual interface port by id (if it exists)
-        """
-        if port_id in self.virtual_ports:
-            return self.virtual_ports.get(port_id)
-        else:
-            return None
-
-    def _query_host_state(self):
-        if cfg.CONF.AVS.managed_host_state:
-            data = self.plugin_rpc.get_host_details(self.context,
-                                                    self.host,
-                                                    self.agent_id)
-            self.host_state_up = data['host_state_up']
-        else:
-            self.host_state_up = True
-        LOG.info("host_state_up={} on startup".format(self.host_state_up))
-
-    def _get_tunnel_addresses(self, iface_uuid):
-        """
-        Return the IP addresses configured against a particular interface which
-        will be used for all tunnel traffic leaving the node.  Nodes can have
-        multiple addresses so return a list of both IPv4 and IPv6 addresses.
-        """
-        data = self.vswitch_mgr.get_address_list(interface_uuid=iface_uuid)
-        addresses = [a for a in data.keys() if is_primary_address(data[a])]
-        # Prefer an IPv6 address if one is present
-        addresses = sorted(addresses,
-                           key=lambda x: netaddr.IPAddress(x).version,
-                           reverse=True)
-        LOG.debug("found tunnel addresses for iface {}: {}".format(
-            iface_uuid, addresses))
-        return addresses
-
-    def get_tunneling_ips(self):
-        """
-        Return the IP address to be used for all tunnel traffic leaving the
-        node on individual physical networks.
-        """
-        if self.tunneling_ips is None:
-            self.tunneling_ips = {}
-            mappings = self.interface_mappings
-            for physical_network, iface_uuid in six.iteritems(mappings):
-                addresses = self._get_tunnel_addresses(iface_uuid)
-                if addresses:
-                    self.tunneling_ips[physical_network] = ','.join(addresses)
-            LOG.info("found tunneling_ips for agent: {}".format(
-                self.tunneling_ips))
-        return self.tunneling_ips
-
-    def _report_agent_state(self):
-        try:
-            config = self.agent_state.get('configurations')
-            config['devices'] = self.vswitch_mgr.get_virtual_port_count()
-            config['tunneling_ips'] = self.get_tunneling_ips()
-            self.state_rpc.report_state(self.context, self.agent_state)
-            self.agent_state.pop('start_flag', None)
-        except Exception as e:
-            LOG.exception("Failed to report state, {}".format(e))
-        try:
-            if self.host_state_up is None:
-                self._query_host_state()
-        except Exception as e:
-            LOG.exception("Failed to query state, {}".format(e))
-
-    def _is_agent_enabled(self):
-        return self.admin_state_up is True and self.host_state_up is True
-
-    @staticmethod
-    def _is_port_up(port):
-        """
-        Determine if a port's state should be reported to the plugin as up or
-        down.  This function only considers the admin state of the port since
-        this is an indication that the agent has attached the port to its
-        network and finally it has unlocked the port.  The reason why the link
-        state is not taken in to consideration is that for AVP port types the
-        VM must be up and running (i.e., not paused) for the link state to
-        change.  In Juno, Nova will not unpause the VM until the port status
-        is reported by the Neutron server as an indication of that the VIF
-        "plug" operation has succeeded.
-        """
-        admin_state = getattr(port, 'admin-state')
-        if admin_state == avs_constants.VSWITCH_ADMIN_STATE_DOWN:
-            return False
-        return True
-
-    def is_port_present(self, port_uuid):
-        """
-        Determine if a port is present in the vswitch.  Base this on the
-        virtual device caches rather than querying the vswitch everytime we
-        need to check this information.
-        """
-        virtual_devices = (self.virtual_ports.keys() + self.interfaces.keys())
-        return bool(port_uuid in virtual_devices)
-
-    @staticmethod
-    def _get_device_name(uuid):
-        """
-        Format a fake tap name as:  tap<uuid[0:11]>.
-        """
-        return LB_PORT_NAME_PREFIX + uuid[:LB_PORT_UUID_TAP_LEN]
-
-    def _get_port_tenant_id(self, uuid):
-        if uuid in self.port_details:
-            return getattr(self.port_details[uuid], 'tenant_id', None)
-        else:
-            return None
-
-    def _get_port_network_id(self, uuid):
-        if uuid in self.port_details:
-            return getattr(self.port_details[uuid], 'network_id', None)
-        else:
-            return None
-
-    def _get_port_link_speed(self, uuid):
-        if uuid in self.phys_ports:
-            return getattr(self.phys_ports[uuid], 'link-speed', None)
-        else:
-            return None
-
-    def _get_interface_tenant_id(self, uuid):
-        if uuid in self.interface_details:
-            if_details = self.interface_details[uuid]
-            return if_details['tenant_id']
-        else:
-            return None
-
-    def _get_interface_network_id(self, uuid):
-        if uuid in self.interface_details:
-            if_details = self.interface_details[uuid]
-            return if_details['network_id']
-        else:
-            return None
-
-    def _report_port_state(self, port):
-        """
-        Report current port state to the plugin
-        """
-        port_uuid = port['uuid']
-        if 'local-state' not in port:
-            port['local-state'] = self._is_port_up(port)
-        LOG.debug("Reporting port state {} for port {}".format(
-            port['local-state'], port_uuid))
-        device_name = self._get_device_name(port_uuid)
-        if port['local-state']:
-            self.plugin_rpc.update_device_up(
-                self.context, device_name, self.agent_id, cfg.CONF.host)
-        else:
-            self.plugin_rpc.update_device_down(
-                self.context, device_name, self.agent_id, cfg.CONF.host)
-
-    def _report_trunk_state(self, port):
-        """
-        Report current port state to the plugin
-        """
-        port_uuid = port['uuid']
-        trunk_details = self.get_trunk_details(port_uuid)
-        if not trunk_details:
-            return  # nothing to do for regular ports
-        if 'local-state' not in port:
-            port['local-state'] = self._is_port_up(port)
-        LOG.debug("Reporting trunk state {} for port {}".format(
-                port['local-state'], port_uuid))
-        if port['local-state']:
-            status = trunk_constants.ACTIVE_STATUS
-        else:
-            status = trunk_constants.DOWN_STATUS
-        self.trunk_plugin_rpc.update_trunk_status(
-            self.context, trunk_details['id'], status)
-
-    def _port_should_be_deleted(self, count):
-        """
-        Determine if the 'stale' count exceeds the allowed threshold
-        """
-        threshold = (avs_constants.VSWITCH_STALE_PORT_THRESHOLD_MINS * 60 /
-                     self.polling_interval)
-        return count >= threshold
-
-    def _handle_stale_port(self, uuid, ports):
-        """
-        Handle ports that are present in the vswitch but not in the neutron DB
-        """
-        ports.pop(uuid, None)
-        self.stale_ports[uuid] = self.stale_ports.get(uuid, 0) + 1
-        if not cfg.CONF.AVS.remove_stale_ports:
-            if self.stale_ports[uuid] == 1:
-                LOG.error("Port {} not in DB; "
-                          "stale port audit disabled".format(uuid))
-        elif self._port_should_be_deleted(self.stale_ports[uuid]):
-            LOG.error("Deleting port {} after being "
-                      "missing from DB for {} minutes".format(
-                          uuid,
-                          avs_constants.VSWITCH_STALE_PORT_THRESHOLD_MINS))
-            self.vswitch_mgr.destroy_port(uuid)
-            self.stale_ports.pop(uuid, None)
-        elif self.stale_ports[uuid] == 1:
-            LOG.error("Port {} not in DB; removing in {} minutes".format(
-                uuid, avs_constants.VSWITCH_STALE_PORT_THRESHOLD_MINS))
-
-    def _extend_port_vxlan_details(self, port_details, provider_details):
-        if provider_details:
-            vxlan = copy.deepcopy(provider_details['vxlan'])
-            port_details['vxlan'] = vxlan
-        else:
-            # Build the same info based on the defaults stored locally
-            port_details['vxlan'] = {'group': cfg.CONF.VXLAN.default_group,
-                                     'port': cfg.CONF.VXLAN.default_port,
-                                     'ttl': cfg.CONF.VXLAN.default_ttl}
-
-    @staticmethod
-    def get_providernet_key(segment):
-        """Build a dict key for a given providernet segment."""
-        if segment:
-            return "%s-%s-%s" % (segment['network_type'],
-                                 segment['physical_network'],
-                                 segment['segmentation_id'])
-        return None
-
-    def _extend_port_details(self, port_details):
-        """
-        Some features depend on extensions in the neutron-server.  If the
-        neutron server implementation is an unmodified openstack version then
-        we need to extend the port detail attributes with values from our
-        local configuration.
-        """
-        # This config option is used to determine whether the server supports
-        # this RPC function or not.  The alternative, trying to invoke this
-        # to find out, will end up generating logs on the server.
-        if cfg.CONF.AVS.managed_providers:
-            providernet_key = self.get_providernet_key(port_details)
-            provider_details = self.providernet_cache.get(providernet_key, {})
-            if not provider_details:
-                provider_details = self.plugin_rpc.get_provider_details(
-                    self.context, self.host, self.agent_id,
-                    port_details['network_type'],
-                    port_details['physical_network'],
-                    port_details['segmentation_id'])
-                self.providernet_cache[providernet_key] = provider_details
-        else:
-            provider_details = {}
-
-        # Extend with common fields
-        port_details[wrs_provider.MTU] = provider_details.get('mtu')
-
-        if port_details['network_type'] == n_const.PROVIDERNET_VXLAN:
-            # Extend with VXLAN specific fields
-            self._extend_port_vxlan_details(port_details, provider_details)
-
-    def _get_network_info(self, port_details):
-        """
-        Determine which network this port should be attached to.  The normal
-        case is that the network is specified by the neutron server based on
-        which tenant network the device was attached to.
-        """
-        network = port_details.get('network')
-        return network['id'], network['name']
-
-    def _get_provider_mapping(self, physical_network):
-        return self.interface_mappings[physical_network]
-
-    def _setup_network(self, network_uuid, network_name, details):
-        network = {
-            'name': network_name,
-            'network_type': details['network_type'],
-            'physical_network': details['physical_network'],
-            'segmentation_id': details['segmentation_id'],
-            'vlan_transparent': details['network'].get('vlan_transparent'),
-            'vxlan': details.get('vxlan', {}),
-            'mtu': details[wrs_provider.MTU]}
-        provider_uuid, nw_instance = self.vswitch_mgr.setup_network(
-            network_uuid, network)
-        self.interface_details[provider_uuid] = {
-            'network_id': details['network_id'],
-            'tenant_id': details['tenant_id']}
-        self.virtual_networks[network_uuid] = nw_instance
-        self.segment_cache[network_uuid] = {
-            'network_type': network['network_type'],
-            'physical_network': network['physical_network'],
-            'segmentation_id': network['segmentation_id']}
-
-    def find_network_by_name(self, network_name):
-        for network_id, network in six.iteritems(self.virtual_networks):
-            if network['name'] == network_name:
-                return network
-        return
-
-    def setup_interface(self, port, details, vlan_id=None):
-        port_uuid = port['uuid']
-        device_owner = details['device_owner']
-        LOG.debug("setup_interface for {} vlan {} with details {}".format(
-            port_uuid, vlan_id, details))
-
-        # Extend port details with extra attributes if they are not provided
-        # by the neutron server implementation
-        self._extend_port_details(details)
-
-        # Setup the network segment
-        network_uuid, network_name = self._get_network_info(details)
-        if self.manage_network_for_device(details):
-            self._setup_network(network_uuid, network_name, details)
-        else:
-            # The network will be created external to this process so wait for
-            # it.  This is the case in SDN where the controller may create some
-            # networks depending on what mode it is running in.
-            instance = self.find_network_by_name(network_name)
-            if not instance:
-                data = {'port': port, 'details': details}
-                self.deferred_ports[network_name][port_uuid] = data
-                LOG.warning("Deferring setup of {} port {} "
-                            "due to missing network {}".format(
-                                device_owner, port_uuid,
-                                network_name))
-                return
-            network_uuid = instance['uuid']
-
-        # Setup the tenant interface for a trunk
-        iface_uuid = details['port_id']  # subport
-        instance = self.interfaces.get(iface_uuid)
-        if not instance and vlan_id:
-            self.vswitch_mgr.add_vlan_interface(
-                iface_uuid, vlan_id,
-                details['network'].get('mtu'), port_uuid)
-
-        # Attach the interface to the network segment
-        if not instance or not getattr(instance, 'network-uuid', None):
-            self.vswitch_mgr.attach_interface(iface_uuid, network_uuid)
-
-        # Track the ownership of this interface of stats collection
-        self.interface_details[iface_uuid] = {
-            'network_id': details['network_id'],
-            'tenant_id': details['tenant_id']}
-
-        # TODO(alegacy): Move DVR attributes to AVR if possible
-        if device_owner == constants.DEVICE_OWNER_DVR_INTERFACE:
-            self.bind_dvr_router_interface(iface_uuid, details)
-        else:
-            self.bind_dvr_interface(iface_uuid, details)
-
-        # Add static layer2 table entry for DVR routers
-        if device_owner == constants.DEVICE_OWNER_DVR_INTERFACE:
-            mac_address = details['mac_address']
-            self.vswitch_mgr.add_network_entry(iface_uuid, mac_address)
-
-        return iface_uuid
-
-    def mark_port_for_refresh(self, port_uuid):
-        """
-        Mark a port to be updated with updated DB data.
-        """
-        port_details = self.port_details.get(port_uuid)
-        if port_details:
-            LOG.debug("forcing update of port {}".format(port_uuid))
-            port_details['_updated'] = True
-            self.updated_ports.add(port_uuid)
-
-    def get_port_details(self, port_uuid):
-        """
-        Retrieve the port detail info.  This references cached data if it
-        exists rather than accessing the DB unnecessary.  If the port is marked
-        as updated by an RPC call from the server then the data is refreshed.
-        """
-        port_details = self.port_details.get(port_uuid)
-
-        if not port_details or port_details.get('_updated', False):
-            trunk_id = port_details.get('_trunk_id') if port_details else 0
-            self.trunk_details.pop(trunk_id, None)
-            chain_id = port_details.get('_chain_id') if port_details else 0
-
-            self.sfc_details.pop(chain_id, None)
-            port_details = self.plugin_rpc.get_device_details(
-                self.context, port_uuid, self.agent_id, self.host)
-            if not port_details or len(port_details) == 1:
-                self.port_details.pop(port_uuid, None)
-                return None
-            LOG.debug("get_port_details for {} details {}".format(
-                port_uuid, port_details))
-            self.port_details[port_uuid] = port_details
-        return port_details
-
-    def get_trunk_details(self, port_uuid):
-        """
-        Retrieve the trunk detail info.  This references cached data if it
-        exists rather than accessing the DB unnecessarily.  If the port is
-        marked as updated by an RPC call from the server then the data is
-        refreshed because the '_trunk_id' attribute will be removed.
-        """
-        port_details = self.port_details[port_uuid]
-        if port_details['trunk_port'] and '_trunk_id' not in port_details:
-            trunk_details = self.trunk_plugin_rpc.get_trunk_details(
-                    self.context, port_uuid)
-            trunk_id = trunk_details['id'] if trunk_details else 0
-            if trunk_id:
-                LOG.debug("get_trunk_details for {} details {}".format(
-                    port_uuid, trunk_details))
-                self.trunk_details[trunk_id] = trunk_details
-            port_details['_trunk_id'] = trunk_id
-        trunk_id = port_details.get('_trunk_id', 0)
-        return self.trunk_details.get(trunk_id)
-
-    def get_sfc_details(self, port_uuids, ports):
-
-        chain_ids = []
-        for uuid in port_uuids:
-            pd = self.get_port_details(uuid)
-            if not pd:
-                # port may have been deleted, still want to notify the driver
-                try:
-                    self.sfc_agent.get_sfc_details(port_uuids)
-                except Exception as e:
-                    LOG.error("Failed to send SFC port notification: %s", e)
-                continue
-
-            chain_id = None
-            if '_chain_id' not in pd:
-                try:
-                    chain_id = self.sfc_agent.get_sfc_details(port_uuids)
-                except Exception as e:
-                    LOG.error("Failed to send SFC port notification: %s", e)
-
-                chain_id = chain_id[0] if chain_id else 0
-                if chain_id:
-                    self.sfc_details[chain_id] = chain_id
-
-                pd['_chain_id'] = chain_id
-
-            chain_id = pd.get('_chain_id', 0)
-            chain_ids.append(chain_id)
-
-        return chain_ids
-
-    @staticmethod
-    def get_fixed_subnet_ids(port_details):
-        """Return the list of subnet ids for which this port has an IP."""
-        fixed_ips = port_details.get('fixed_ips', [])
-        subnets = port_details.get('subnets', [])
-        subnet_ids = [s['subnet']['id'] for s in subnets]
-        fixed_subnet_list = [ip['subnet_id'] for ip in fixed_ips
-                             if ip['subnet_id'] in subnet_ids]
-        return fixed_subnet_list
-
-    def get_ports_on_dvr_subnet(self, subnet_uuid):
-        """This is a replacement for get_ports_on_host_by_subnet() that looks
-        at local data instead of needing to invoke a server RPC. Since the
-        vlan-transparent feature was enabled the port details include the
-        network context therefore we can tell which subnets each port is a
-        member of.
-        """
-        ports = set()
-        for port_uuid, details in six.iteritems(self.port_details):
-            fixed_subnet_list = self.get_fixed_subnet_ids(details)
-            if subnet_uuid not in fixed_subnet_list:
-                continue
-            ports.add(port_uuid)
-        return ports
-
-    def handle_updated_port(self, port, port_details):
-        """
-        Process a new or updated ports.  The intent of this method is to attach
-        the port's ethernet interface to the appropriate network.  The network
-        is created if it does not already exist.  The network is attached to
-        the appropriate provider network if it is not already attached.  If the
-        port has any VLAN interfaces then they are created here in the same way
-        that the base ethernet interface is created.
-        """
-        port_uuid = port['uuid']
-        vlans = set()
-        LOG.debug("handle_updated_port for {}".format(port_uuid))
-
-        # Lock the port immediately if it is in the incorrect state
-        if not port_details['admin_state_up'] and port['admin-state'] == "up":
-            self.vswitch_mgr.lock_port(port_uuid)
-            port['admin-state'] = "down"  # update cached state
-
-        # Setup the untagged interface
-        self.setup_interface(port, port_details)
-
-        # Setup the port for any trunk that may be overlaid.
-        trunk_details = self.get_trunk_details(port_uuid)
-        if trunk_details and trunk_details['admin_state_up']:
-            self.trunk_plugin_rpc.update_subport_bindings(
-                self.context, trunk_details.sub_ports)
-            for subport in trunk_details.sub_ports if trunk_details else []:
-                details = self.get_port_details(subport.port_id)
-                vlan_id = subport.segmentation_id
-                vlans.add(self.setup_interface(port, details, vlan_id=vlan_id))
-                # Report that the subport is UP.  This is not currently done in
-                # OVS or Linuxbridge, but our customers will definitely
-                # complain that the subport devices are in BUILD status.
-                self.plugin_rpc.update_device_up(
-                    self.context, self._get_device_name(subport.port_id),
-                    self.agent_id, cfg.CONF.host)
-
-        if port_uuid in self.interfaces:
-            # Remove any stale VLANs from pre-existing interfaces
-            existing = set(getattr(self.interfaces[port_uuid], 'vlans', []))
-            self.stale_interfaces |= (existing - vlans)
-
-        # Configure QoS policy information
-        self.update_qos_port_details(port_uuid, port_details)
-
-        # Update the port information
-        params = {'mac-filtering': port_details.get('port_security_enabled',
-                                                    False)}
-        self.vswitch_mgr.update_port(port_uuid, params)
-
-        # Only unlock the port once it is attached to its network
-        if port_details['admin_state_up'] and port['admin-state'] == "down":
-            self.vswitch_mgr.unlock_port(port_uuid)
-            port['admin-state'] = "up"  # update cached state
-
-    def prepare_sg_device_filters(self, devices):
-        # Base class ignores this type; only handled by default AVS agent
-        return
-
-    def remove_sg_device_filters(self, devices):
-        # Base class ignores this type; only handled by default AVS agent
-        return
-
-    def bind_dvr_router_interface(self, interface_uuid, port_details):
-        # Base class ignores this type; only handled by default AVS agent
-        return
-
-    def bind_dvr_interface(self, interface_uuid, port_details):
-        # Base class ignores this type; only handled by default AVS agent
-        return
-
-    def update_qos_port_details(self, port_uuid, port_details):
-        # Base class ignores this type; only handled by default AVS agent
-        return
-
-    def handle_updated_ports(self, uuids, ports):
-        """
-        Handle ports that were detected to have been added/updated to the
-        vswitch since our last scan.
-        """
-        if not uuids:
-            return
-        # Reduce the list of ports down to those that need to be handled
-        # while maintaining the original order.
-        updated_ports = [x for x in ports.keys() if x in uuids]
-        LOG.debug("{} ports(s) updated: {} ".format(
-            len(updated_ports), updated_ports))
-        devices = [self._get_device_name(uuid) for uuid in updated_ports]
-        self.prepare_sg_device_filters(devices)
-
-        for uuid in updated_ports:
-            try:
-                port_details = self.get_port_details(uuid)
-                if port_details:
-                    self.handle_updated_port(ports[uuid], port_details)
-                    self._report_port_state(ports[uuid])
-                    self._report_trunk_state(ports[uuid])
-                else:
-                    self._handle_stale_port(uuid, ports)
-            except manager.VSwitchManagerError as e:
-                LOG.exception(repr(e))
-
-        # Trigger an SFC update
-        self.get_sfc_details(updated_ports, ports)
-
-    def check_orphaned_networks(self, port_uuid, network_ids):
-        """
-        Given a list of network_ids check to ensure that none of them are
-        orphaned as a result of deleting the port specified by the port_uuid
-        parameter.  Interfaces that are currently being used by a provider
-        network connectivity test are preserved so that ongoing tests are not
-        interrupted.
-        """
-        in_use_interfaces = self._pnet_connectivity_interface_uuids()
-        # Delete any that are now orphaned
-        for network_id in network_ids:
-            if not self.vswitch_mgr.is_network_orphaned(network_id):
-                continue
-            LOG.warning("Last port {} deleted; deleting network {}".format(
-                port_uuid, network_id))
-            self.remove_network(network_id, in_use_interfaces)
-
-    def handle_removed_port(self, port_uuid):
-        """
-        Handle the deletion of a port
-        """
-        self.interface_details.pop(port_uuid, None)
-        port_details = self.port_details.pop(port_uuid, None)
-        if not port_details:
-            LOG.warning("Previously unknown port {} removed".format(
-                port_uuid))
-            return
-        trunk_id = port_details.get('_trunk_id')
-        trunk_details = self.trunk_details.pop(trunk_id, None)
-
-        chain_id = port_details.get('_chain_id')
-        self.sfc_details.pop(chain_id, None)
-
-        if not self.manage_network_for_device(port_details):
-            # Leave the network(s) as-is if we are not managing them.
-            return
-
-        network_ids = set()
-        network_ids.add(port_details.get('network_id'))
-
-        # Handle trunk subports.
-        for subport in trunk_details.sub_ports if trunk_details else []:
-            self.interface_details.pop(subport.port_id, None)
-            details = self.port_details.pop(subport.port_id, None)
-            if details:
-                network_uuid, _ = self._get_network_info(details)
-                network_ids.add(network_uuid)
-
-        # Prune the list of networks down to those that still exist
-        current_networks = self.virtual_networks
-        network_ids &= set(current_networks)
-        self.check_orphaned_networks(port_uuid, network_ids)
-
-    def handle_removed_ports(self, uuids, ports):
-        """
-        Handle ports that were detected to have been removed from the vswitch
-        since our last scan.
-        """
-        if not uuids:
-            return
-        LOG.debug("{} port(s) removed: {} ".format(len(uuids), uuids))
-        devices = [self._get_device_name(uuid) for uuid in uuids]
-        self.remove_sg_device_filters(devices)
-
-        # Trigger an SFC update
-        # NOTE(alegacy): do this before calling handle_removed_port because
-        # otherwise we will end up going back up to the server to do a
-        # get_device_details() and will leave stale information in the
-        # port_details cache.
-        self.get_sfc_details(uuids, ports)
-
-        for uuid in uuids:
-            try:
-                self.plugin_rpc.update_device_down(
-                    self.context, self._get_device_name(uuid), self.agent_id,
-                    cfg.CONF.host)
-                self.handle_removed_port(uuid)
-            except manager.VSwitchManagerError as e:
-                LOG.exception(repr(e))
-
-    def compare_ports(self, uuids, current, previous):
-        """
-        Compare existing ports to determine if a state change needs to be
-        reported to the plugin or if any port needs to be reconfigured.
-        """
-        updated = self.updated_ports & set(uuids)
-        self.updated_ports = set()
-        for uuid in uuids:
-            try:
-                new = current[uuid]
-                old = previous[uuid]
-                new['local-state'] = self._is_port_up(new)
-                if (new['created-timestamp'] != old['created-timestamp']):
-                    # The object has been deleted and re-added therefore we
-                    # need to add this to the list of ports that we need to
-                    # reconfigure.
-                    LOG.warning("port {} create timestamp changed;"
-                                "reconfiguring".format(uuid))
-                    updated.add(uuid)
-                elif (('local-state' not in old) or
-                        (new['local-state'] != old['local-state'])):
-                    # The local state has changed so inform the server
-                    self._report_port_state(new)
-                elif uuid in self.updated_ports:
-                    # The server state has changed so report our current local
-                    # port status back up to it.
-                    self._report_port_state(new)
-                    self._report_trunk_state(new)
-                self.updated_ports.discard(uuid)
-            except manager.VSwitchManagerError as e:
-                LOG.exception(repr(e))
-        self.handle_updated_ports(updated, current)
-
-    def _process_virtual_ports(self, current_ports, previous_ports):
-        """
-        Process the list of ports to determine if ports have been added,
-        removed, or modified.
-        """
-        current = set(current_ports.keys())
-        previous = set(previous_ports.keys())
-        added = current - previous
-        removed = previous - current
-        existing = current & previous
-        self.handle_updated_ports(added, current_ports)
-        self.handle_removed_ports(removed, previous_ports)
-        self.compare_ports(existing, current_ports, previous_ports)
-
-    def _virtual_ports_loop(self):
-        """
-        Retrieve the current list of virtual ports and compare against the
-        expected list of ports, updating accordingly
-        """
-        try:
-            # audit the virtual ports
-            previous = self.virtual_ports
-            self.virtual_ports = self.vswitch_mgr.get_virtual_port_list()
-            self._process_virtual_ports(self.virtual_ports, previous)
-        except Exception as e:
-            # Clear the device list and resync with the plugin
-            LOG.exception("Failed to process virtual "
-                          "port list, {}".format(e))
-            self.virtual_ports = {}
-
-    def handle_updated_interface(self, interface_uuid, port_details):
-        """
-        Process a new router interface attaching it to a network if necessary
-        """
-        self.setup_interface(interface_uuid, port_details)
-
-    def handle_removed_interface(self, port_uuid):
-        """
-        Handle the deletion of a router interface
-        """
-        # The delete operation is the same for ports and interfaces
-        self.handle_removed_port(port_uuid)
-
-    def handle_updated_interfaces(self, uuids, interfaces):
-        """
-        Handle interfaces that were detected to have been added/updated to the
-        vswitch since our last scan.
-        """
-        # Reduce the list of interfaces down to those that need to be handled
-        # while maintaining the original order.
-        updated_interfaces = [x for x in interfaces.keys() if x in uuids]
-        LOG.debug("{} interface(s) updated: {} ".format(
-            len(updated_interfaces), updated_interfaces))
-        for uuid in updated_interfaces:
-            try:
-                port_details = self.get_port_details(uuid)
-                if not port_details:
-                    continue  # not present in DB
-                self.handle_updated_interface(interfaces[uuid], port_details)
-                self.plugin_rpc.update_device_up(
-                    self.context, self._get_device_name(uuid),
-                    self.agent_id, cfg.CONF.host)
-            except manager.VSwitchManagerError as e:
-                LOG.exception(repr(e))
-
-    def handle_removed_interfaces(self, uuids):
-        """
-        Handle interfaces that were detected to have been removed from the
-        vswitch since our last scan.
-        """
-        for uuid in uuids:
-            try:
-                self.plugin_rpc.update_device_down(
-                    self.context, self._get_device_name(uuid), self.agent_id,
-                    cfg.CONF.host)
-                self.handle_removed_interface(uuid)
-            except manager.VSwitchManagerError as e:
-                LOG.exception(repr(e))
-
-    def compare_interfaces(self, uuids, current, previous):
-        """
-        Compare existing interfaces to determine if a state change needs to be
-        reported to the plugin or if any interface needs to be reconfigured.
-        """
-        updated = set()
-        for uuid in uuids:
-            try:
-                new = current[uuid]
-                old = previous[uuid]
-                if (new['created-timestamp'] != old['created-timestamp']):
-                    # The object has been deleted and re-added therefore we
-                    # need to add this to the list of ports that we need to
-                    # reconfigure.
-                    LOG.warning("router interface {} create timestamp "
-                                "changed; reconfiguring".format(uuid))
-                    updated.add(uuid)
-            except manager.VSwitchManagerError as e:
-                LOG.exception(repr(e))
-        self.handle_updated_interfaces(updated, current)
-
-    def _process_router_interfaces(self,
-                                   current_interfaces, previous_interfaces):
-        """
-        Process the list of ports to determine if ports have been added,
-        removed, or modified.
-        """
-        current = set(current_interfaces.keys())
-        previous = set(previous_interfaces.keys())
-        added = current - previous
-        removed = previous - current
-        existing = current & previous
-        self.handle_updated_interfaces(added, current_interfaces)
-        self.handle_removed_interfaces(removed)
-        self.compare_interfaces(
-            existing, current_interfaces, previous_interfaces)
-
-    def _router_interfaces_loop(self):
-        """
-        Retrieve the current list of router interfaces and compare against the
-        current list of ports, updating accordingly
-        """
-        try:
-            previous = self.router_interfaces
-            self.router_interfaces = (
-                self.vswitch_mgr.get_router_interface_list(
-                    interfaces=self.interfaces))
-            self._process_router_interfaces(self.router_interfaces, previous)
-        except Exception as e:
-            # Clear the interface list and resync with the plugin
-            LOG.exception("Failed to process router "
-                          "interface list, {}".format(e))
-            self.router_interfaces = {}
-
-    def _interfaces_loop(self):
-        """
-        Retrieve the current list of interfaces and cache the list for later
-        operations to reduce the number of API calls to AVS.
-        """
-        try:
-            self.interfaces = self.vswitch_mgr.get_interface_list()
-        except Exception as e:
-            # Clear the interface list and resync with the plugin
-            LOG.exception("Failed to cache interface list, {}".format(e))
-
-    def _report_port_state_fault(self, port):
-        """
-        Generate a fault management alarm condition for link state fault
-        """
-        LOG.debug("Report link state fault: {}".format(port['uuid']))
-        self.fm_driver.report_port_state_fault(self.host, port['uuid'],
-                                               fm.FM_SEVERITY_MAJOR)
-
-    def _clear_port_state_fault(self, port):
-        """
-        Clear a fault management alarm condition for link state fault
-        """
-        LOG.debug("Clear link state fault: {}".format(port['uuid']))
-        self.fm_driver.clear_port_state_fault(self.host, port['uuid'])
-
-    def _get_port_state_faults(self):
-        """
-        Get the current list of port faults
-        """
-        faults = self.fm_driver.get_port_state_faults(self.host)
-        return faults or []
-
-    def _report_interface_state_fault(self, interface, severity):
-        """
-        Generate a fault management alarm condition for interface state fault
-        """
-        LOG.debug("Report interface state fault: {}".format(interface['uuid']))
-        self.fm_driver.report_interface_state_fault(self.host,
-                                                    interface['uuid'],
-                                                    severity)
-
-    def _clear_interface_state_fault(self, interface):
-        """
-        Clear a fault management alarm condition for interface state fault
-        """
-        LOG.debug("Clear interface state fault: {}".format(interface['uuid']))
-        self.fm_driver.clear_interface_state_fault(self.host,
-                                                   interface['uuid'])
-
-    def _get_interface_state_faults(self):
-        """
-        Get the current list of interface faults
-        """
-        faults = self.fm_driver.get_interface_state_faults(self.host)
-        return faults or []
-
-    def _collect_engine_statistics(self, timestamp):
-        """
-        Retrieve the current engine statistics and reports it
-        through the notification API for the metering listener
-        to consume
-        """
-
-        engine_metrics = []
-        engine_stats = self.vswitch_mgr.get_engine_stats()
-        for stats in engine_stats:
-            data = stats.to_dict()
-            cycles_total = (float(stats['cycles-busy']) +
-                            float(stats['cycles-idle']))
-            if cycles_total:
-                cpu_util = float(stats['cycles-busy']) / cycles_total * 100
-            else:
-                cpu_util = 0
-
-            data['timestamp'] = timestamp
-            data['host'] = self.host
-            data['cpu_id'] = stats['cpuid']
-            data['cpu_util'] = cpu_util
-            data['rx_discard'] = stats['rx-discard-priority']
-            data['tx_discard'] = (long(stats['tx-discard']) +
-                                  long(stats['tx-timeout']) +
-                                  long(stats['tx-discard-priority']) +
-                                  long(stats['tx-discard-provider']))
-
-            engine_metrics.append(data)
-
-        self._notifier.info(self.context, 'vswitch.meter.engine',
-                            {'engine-metrics': engine_metrics})
-
-    @staticmethod
-    def _ethernet_frame_overhead(link_speed):
-        """
-        Return the packet framing overhead based on link speed (speed in
-        megabits/second)
-        """
-        if link_speed == 40000 or link_speed == 100000:
-            gap = 1
-        elif link_speed == 10000:
-            gap = 5
-        elif link_speed == 1000:
-            gap = 8
-        else:
-            gap = 12
-
-        # 24 bytes overhead per packet/frame (1-12 gap, 8 preamble, 4 crc)
-        return gap + 8 + 4
-
-    def _compute_port_utilisation(self, byte_count, packet_count,
-                                  duration, link_speed):
-        """
-        Calculates the port link utilisation given the current data rate
-        and speed.
-        byte_count - packet byte count in period
-        packet_count - packet count in period
-        duration - period in seconds
-        link_speed - link speed in megabits/second
-        """
-        if not packet_count:
-            return 0
-
-        ether_overhead = self._ethernet_frame_overhead(link_speed)
-        packet_overhead = packet_count * ether_overhead
-
-        if duration and link_speed:
-            data_rate = float(byte_count + packet_overhead) / float(duration)
-            port_util = (float(data_rate) /
-                         (float((link_speed * 1000 * 1000) / 8))) * 100
-            return port_util
-        else:
-            return 0
-
-    def _collect_port_statistics(self, timestamp):
-        """
-        Retrieves the current port statistics and reports it
-        through the notification API for the metering listener
-        to consume
-        """
-        duration = timestamp - self.metering_timestamp
-
-        # retrieve physical port list to obtain port link-speed
-        self.phys_ports = self.vswitch_mgr.get_physical_port_list()
-
-        port_metrics = []
-        port_stats = self.vswitch_mgr.get_port_stats()
-        for stats in port_stats:
-            data = stats.to_dict()
-            uuid = stats['uuid']
-            data['timestamp'] = timestamp
-            data['host'] = self.host
-            data['tenant_id'] = self._get_port_tenant_id(uuid)
-            data['network_id'] = self._get_port_network_id(uuid)
-            data['link-speed'] = self._get_port_link_speed(uuid)
-
-            # compute link utilisation if possible
-            prev = self.port_stats.get(uuid, None)
-            if prev and data['link-speed']:
-                rx_packets = (long(stats['rx-packets']) -
-                              long(prev['rx-packets']))
-                tx_packets = (long(stats['tx-packets']) -
-                              long(prev['tx-packets']))
-                rx_bytes = (long(stats['rx-bytes']) -
-                            long(prev['rx-bytes']))
-                tx_bytes = (long(stats['tx-bytes']) -
-                            long(prev['tx-bytes']))
-
-                link_speed = data['link-speed']
-
-                data['rx-util'] = self._compute_port_utilisation(
-                    rx_bytes, rx_packets, duration, link_speed)
-                data['tx-util'] = self._compute_port_utilisation(
-                    tx_bytes, tx_packets, duration, link_speed)
-            else:
-                data['rx-util'] = None
-                data['tx-util'] = None
-
-            # save stats for next iteration computation
-            self.port_stats[uuid] = stats
-
-            port_metrics.append(data)
-
-        self._notifier.info(self.context, 'vswitch.meter.port',
-                            {'port-metrics': port_metrics})
-
-    def _collect_interface_statistics(self, timestamp):
-        """
-        Retrieves the current interface statistics and reports it
-        through the notification API for the metering listener
-        to consume
-        """
-
-        interface_metrics = []
-        interface_stats = self.vswitch_mgr.get_interface_stats()
-        for stats in interface_stats:
-            data = stats.to_dict()
-
-            uuid = data['uuid']
-            data['timestamp'] = timestamp
-            data['host'] = self.host
-            data['tenant_id'] = self._get_interface_tenant_id(uuid)
-            data['network_uuid'] = self._get_interface_network_id(uuid)
-
-            interface_metrics.append(data)
-
-        self._notifier.info(self.context, 'vswitch.meter.interface',
-                            {'interface-metrics': interface_metrics})
-
-    def _metering_loop(self):
-        """
-        Retrieve the current vswitch statistics and report it to
-        the metering notification collector.
-        """
-        try:
-            timestamp = int(time.time())
-            delta = timestamp - self.metering_timestamp
-            if delta > self.metering_interval:
-                if self._is_agent_enabled():
-                    self._collect_engine_statistics(timestamp)
-                    self._collect_port_statistics(timestamp)
-                    self._collect_interface_statistics(timestamp)
-                self.metering_timestamp = timestamp
-        except Exception as e:
-            # Collection failed, log error and retry at next interval
-            LOG.exception("Failed to collect metering data, {}".format(e))
-
-    def manage_network_for_device(self, port_details):
-        return True
-
-    def _process_virtual_networks(self, current_networks, previous_networks):
-        # No action required in non-SDN deployments
-        pass
-
-    def _virtual_networks_loop(self):
-        try:
-            # audit the virtual networks
-            previous = self.virtual_networks
-            current = self.vswitch_mgr.get_networks()
-            self.virtual_networks = current
-            self._process_virtual_networks(current, previous)
-        except Exception as e:
-            # Clear the device list and resync with the plugin
-            LOG.exception("Failed to process virtual "
-                          "network list, {}".format(e))
-            self.virtual_networks = {}
-
-    def _delete_interface(self, interface_uuid):
-        instance = self.interfaces[interface_uuid]
-        network_uuid = getattr(instance, 'network-uuid', None)
-        self.vswitch_mgr.delete_interface(interface_uuid)
-        self.check_orphaned_networks(interface_uuid, [network_uuid])
-
-    def _stale_interfaces_loop(self):
-        """
-        Handle any interfaces that were flagged as stale.  These could be any
-        interface in AVS that no longer maps to and actual neutron port but
-        more likely they are VLAN interfaces that map to a neutron port trunk
-        or subport that no longer exists or is administratively disabled.
-        """
-        try:
-            for vlan_uuid in self.stale_interfaces:
-                LOG.warning("Removing VNIC VLAN interface {}\n".format(
-                    vlan_uuid))
-                self._delete_interface(vlan_uuid)
-        except Exception as e:
-            # Clear the device list and resync with the plugin
-            LOG.exception("Failed to process stale "
-                          "interface list, {}".format(e))
-        self.stale_interfaces = set()
-
-    def daemon_loop_body(self):
-        self._virtual_networks_loop()
-        self._interfaces_loop()
-        self._router_interfaces_loop()
-        self._virtual_ports_loop()
-        self._metering_loop()
-        self._stale_interfaces_loop()
-        if self.vif_event.wait(self.polling_interval):
-            self.vif_event.clear()
-
-    def daemon_loop(self):
-        """
-        Scan the vswitch at fixed intervals to determine if ports have been
-        added, removed, or modified and to collect metering data.
-        """
-        LOG.info("vSwitch Agent RPC Daemon Started")
-        while True:
-            self.daemon_loop_body()
-
-
-class VSwitchNeutronAgent(VSwitchBaseNeutronAgent,
-                          VSwitchRpcCallbacksMixin):
-    def __init__(self,
-                 interface_mappings,
-                 polling_interval,
-                 metering_interval,
-                 status_interval,
-                 vswitch_api,
-                 enable_distributed_routing=False):
-        self.dvr_mac_audit_timestamp = 0
-        self.pnet_connectivity_audit_uuid = None
-        self.pnet_connectivity_manager = self
-        self.pnet_connectivity_interfaces = []
-        self.link_local_address = None
-        self.fdb_cache = VSwitchFDBCache()
-        self.fdb_audits = {}
-
-        super(VSwitchNeutronAgent, self).__init__(
-            interface_mappings,
-            polling_interval,
-            metering_interval,
-            status_interval,
-            vswitch_api,
-            enable_distributed_routing)
-        self._remove_unattached_provider_interfaces()
-        self.qos_agent = qos_rpc.QoSAgentRpc(self.context, self.qos_plugin_rpc)
-        self.qos_agent.register_manager(self.vswitch_mgr)
-
-        self.sg_agent = VSwitchSecurityGroupAgentRpc(self.context,
-                                                     self.sg_plugin_rpc)
-        self.sg_agent.register_manager(self.vswitch_mgr)
-
-        self.dvr_agent = dvr.VswitchDVRNeutronAgent(
-            self.context,
-            self.dvr_plugin_rpc,
-            self,
-            self.host,
-            self.enable_distributed_routing)
-
-        self.dvr_agent.register_manager(self.vswitch_mgr)
-
-        self.sfc_agent = sfc.VswitchSFCNeutronAgent(
-            self.context,
-            self,
-            self.host)
-
-        self.sfc_agent.register_manager(self.vswitch_mgr)
-
-    def remove_network(self, network_id, in_use_interfaces):
-        super(VSwitchNeutronAgent, self).remove_network(
-            network_id, in_use_interfaces)
-        # NOTE(alegacy): whenever a network is removed we need to flush the
-        # FDB cache because AVS will have automatically removed any learned
-        # or programmed layer2/layer3 entries.
-        interface_uuid = self.fdb_cache.unmap_network(network_id)
-        if interface_uuid:
-            self.fdb_cache.remove_interface(interface_uuid)
-
-    def rpc_consumers(self):
-        result = super(VSwitchNeutronAgent, self).rpc_consumers()
-        result.extend([[topics.SECURITY_GROUP, topics.UPDATE],
-                       [topics.QOS, topics.UPDATE],
-                       [topics.DVR, topics.UPDATE],
-                       [topics.PNET_CONNECTIVITY, topics.UPDATE, self.host],
-                       [topics.L2POPULATION, topics.UPDATE]])
-        return result
-
-    def setup_rpc(self):
-        self.sg_plugin_rpc = sg_rpc.SecurityGroupServerRpcApi(topics.PLUGIN)
-        self.dvr_plugin_rpc = dvr_rpc.DVRServerRpcApi(topics.PLUGIN)
-        self.qos_plugin_rpc = qos_rpc.QoSServerRpcApi(topics.PLUGIN)
-        self.pnet_connectivity_api = \
-            pnet_connectivity_rpc.PnetConnectivityRpcApi(topics.PLUGIN)
-        self.trunk_plugin_rpc = VSwitchTrunkStub()
-        return super(VSwitchNeutronAgent, self).setup_rpc()
-
-    def prepare_sg_device_filters(self, devices):
-        super(VSwitchNeutronAgent, self).prepare_sg_device_filters(devices)
-        self.sg_agent.prepare_devices_filter(devices)
-
-    def remove_sg_device_filters(self, devices):
-        super(VSwitchNeutronAgent, self).remove_sg_device_filters(devices)
-        self.sg_agent.remove_devices_filter(devices)
-
-    def bind_dvr_router_interface(self, interface_uuid, port_details):
-        return self.dvr_agent.bind_router_interface_to_dvr(
-            interface_uuid, port_details)
-
-    def bind_dvr_interface(self, interface_uuid, port_details):
-        return self.dvr_agent.bind_interface_to_dvr(
-            interface_uuid, port_details)
-
-    def update_qos_port_details(self, port_uuid, port_details):
-        port_qos_policy = port_details.get('port_qos_policy', None)
-        if port_qos_policy is not None:
-            self.qos_agent.qos.port_qos_updated(port_qos_policy, port_uuid)
-
-        network_qos_policy = port_details.get('network_qos_policy', None)
-        if network_qos_policy is not None:
-            self.qos_agent.qos.network_qos_updated(
-                network_qos_policy, port_details['network_id'])
-
-    def _pnet_connectivity_interface_uuids(self):
-        """
-        Return list of interfaces currently in use for
-        providernet connectivity testing
-        """
-        return [i.interface_uuid for i in self.pnet_connectivity_interfaces]
-
-    def _remove_unattached_provider_interfaces(self, interface_list=None):
-        """Removes all provider interfaces that are lacking a network uuid"""
-        current_interfaces = self.vswitch_mgr.get_interface_list()
-        if interface_list:
-            interface_dict = {uuid: current_interfaces[uuid]
-                              for uuid in interface_list
-                              if uuid in current_interfaces}
-        else:
-            interface_dict = current_interfaces
-        mapped_interface_uuids = self.interface_mappings.values()
-        for interface_uuid, interface in six.iteritems(interface_dict):
-            if interface_uuid in mapped_interface_uuids:
-                continue
-            iftype = interface['type']
-            if (iftype == avs_constants.VSWITCH_VXLAN_INTERFACE or
-                    iftype == avs_constants.VSWITCH_VLAN_INTERFACE):
-                ifclass = interface['class']
-                if ifclass == avs_constants.VSWITCH_PROVIDER_INTERFACE:
-                    if 'network-uuid' not in interface:
-                        self.vswitch_mgr.delete_interface(interface_uuid)
-
-    def _setup_connectivity_audit(self, providernet, segments, extra_data):
-        """Sets up a connectivity audit and return link-local address"""
-        # Determine which logical interface implements this provider network
-        self.pnet_connectivity_interfaces = []
-        providernet_id, providernet_name, providernet_type = providernet
-        lower_uuid = self._get_provider_mapping(providernet_name)
-        lower_interface = self.vswitch_mgr.get_interface(lower_uuid)
-        network = {'network_type': providernet_type,
-                   'physical_network': providernet_name,
-                   'mtu': extra_data[wrs_provider.MTU]}
-        if providernet_type == n_const.PROVIDERNET_VLAN:
-            for segmentation_id in segments:
-                network.update({'segmentation_id': segmentation_id})
-                interface_uuid = self.vswitch_mgr.setup_provider_interface(
-                    lower_uuid, network)
-                segment_iface = VSwitchNetworkSegmentInterface(
-                    providernet_id, providernet_name, providernet_type,
-                    segmentation_id, interface_uuid
-                )
-                self.pnet_connectivity_interfaces.append(segment_iface)
-        elif providernet_type == n_const.PROVIDERNET_VXLAN:
-            for segment in segments:
-                network.update({'segmentation_id': segment['minimum'],
-                                'vxlan': segment['vxlan']})
-                interface_uuid = self.vswitch_mgr.setup_provider_interface(
-                    lower_uuid, network)
-                # Rather than run the test over the VXLAN interface we run
-                # it on the lower interface.  This is to support static
-                # VXLAN mode where, without learning or static endpoints,
-                # it is not possible to ping an arbitrary node.  We would
-                # need to preprovision a mesh of static endpoints and that
-                # is not practical.
-                segment_iface = VSwitchNetworkSegmentInterface(
-                    providernet_id, providernet_name, providernet_type,
-                    segment['id'], interface_uuid, lower_uuid=lower_uuid
-                )
-                self.pnet_connectivity_interfaces.append(segment_iface)
-        elif providernet_type == n_const.PROVIDERNET_FLAT:
-            interface_uuid = self.vswitch_mgr.setup_provider_interface(
-                lower_uuid, network)
-            segment_iface = VSwitchNetworkSegmentInterface(
-                providernet_id, providernet_name, providernet_type,
-                n_const.PROVIDERNET_FLAT, interface_uuid
-            )
-            self.pnet_connectivity_interfaces.append(segment_iface)
-
-        mac_address = lower_interface['mac-address']
-        self.link_local_address = ipv6_utils.get_link_local_address_by_mac(
-            mac_address
-        )
-        return self.link_local_address
-
-    def _calculate_packet_size_for_ping(self, providernet_mtu):
-        """
-        For a given MTU, return the maximum length for ping,
-        or return default size if no MTU is specified
-        """
-        if providernet_mtu:
-            length = (providernet_mtu -
-                      avs_constants.VSWITCH_IPV6_ICMP_HEADER_SIZE)
-        else:
-            length = avs_constants.VSWITCH_PING_MINIMUM_SIZE
-        return length
-
-    def _test_interface_connectivity_to_address(self, destination_address,
-                                                interface_uuid, length=None):
-        """Returns whether an interface can ping a given address"""
-        length = length or avs_constants.VSWITCH_PING_MINIMUM_SIZE
-        for i in range(n_const.PROVIDERNET_CONNECTIVITY_TEST_ATTEMPTS):
-            if self.vswitch_mgr.ping(destination_address,
-                                     interface_uuid, length):
-                return True
-        return False
-
-    def _get_reason_for_failure(self, mtu=None):
-        """Provide a reason a test failed based on the MTU"""
-        if mtu:
-            return "Failed with MTU %s" % str(mtu)
-        return "Failed to ping target"
-
-    def _run_connectivity_tests(self, common_tuple, master_address,
-                                extra_data):
-        """
-        Test connectivity to address for all interfaces and return a list
-         of tuples with the results of each test containing:
-         (local_hostname, master_hostname, providernet_id, segment, state).
-        """
-        mtu = extra_data[wrs_provider.MTU]
-        test_results = []
-        for segment_iface in self.pnet_connectivity_interfaces:
-            segment_details = (segment_iface.providernet_id,
-                               segment_iface.segment)
-            length = self._calculate_packet_size_for_ping(mtu)
-            interface_uuid = segment_iface.interface_uuid
-            physical_network = segment_iface.providernet_name
-            if segment_iface.providernet_type == n_const.PROVIDERNET_VXLAN:
-                # Pick a compatible IP address for this provider network.
-                agent_ips = extra_data.get('agent-ips', {})
-                agent_ip = agent_ips[common_tuple[1]]
-                if agent_ip:
-                    # TODO(alegacy): this can be removed in R6 because by
-                    # then this data will always be present.  Currently it
-                    # is only present when the master nodes have been
-                    # upgraded to R5 and until then we need to continue
-                    # using the original link-local address test over a VNI.
-                    master_address = self._select_local_agent_ip(
-                        physical_network, agent_ip)
-                    interface_uuid = segment_iface.lower_uuid
-                    # Inflate the size of the packet to simulate what it
-                    # would look like if it was originated from behind the
-                    # VXLAN interface.
-                    length += n_const.VXLAN_MTU_OVERHEAD
-
-            if (master_address == self.link_local_address or
-                    self._is_local_agent_ip(physical_network, master_address)):
-                # Fake tests to our own address
-                test_results.append(
-                    common_tuple + segment_details +
-                    (n_const.PROVIDERNET_CONNECTIVITY_PASS, ""))
-                continue
-
-            if self._test_interface_connectivity_to_address(
-                    master_address, interface_uuid):
-                test_result = (n_const.PROVIDERNET_CONNECTIVITY_PASS, "")
-            else:
-                test_result = (
-                    n_const.PROVIDERNET_CONNECTIVITY_FAIL,
-                    self._get_reason_for_failure()
-                )
-                test_results.append(common_tuple + segment_details +
-                                    test_result)
-                continue
-
-            if self._test_interface_connectivity_to_address(
-                    master_address, interface_uuid, length):
-                test_result = (n_const.PROVIDERNET_CONNECTIVITY_PASS, "")
-            else:
-                test_result = (
-                    n_const.PROVIDERNET_CONNECTIVITY_FAIL,
-                    self._get_reason_for_failure(mtu)
-                )
-                test_results.append(common_tuple + segment_details +
-                                    test_result)
-                continue
-
-            test_results.append(common_tuple + segment_details +
-                                test_result)
-        return test_results
-
-    def _run_connectivity_audit(self, providernet, masters, extra_data):
-        """Run tests to a given list of masters"""
-        connectivity_tests_results = []
-        local_hostname = self.host
-        for master_hostname, link_local_address in masters:
-
-            common_tuple = (local_hostname, master_hostname)
-            test_results = self._run_connectivity_tests(common_tuple,
-                                                        link_local_address,
-                                                        extra_data)
-            connectivity_tests_results.extend(test_results)
-        return connectivity_tests_results
-
-    def _teardown_connectivity_audit(self, clearall=False):
-        """Removes interfaces created for the most recent audit"""
-        if clearall:
-            interfaces_to_remove = None
-        else:
-            interfaces_to_remove = [segment_iface.interface_uuid
-                                    for segment_iface in
-                                    self.pnet_connectivity_interfaces]
-        self._remove_unattached_provider_interfaces(interfaces_to_remove)
-        self.pnet_connectivity_interfaces = []
-        return True
-
-    def _start_connectivity_audit(self, audit_uuid, masters, hosts,
-                                  providernet, segments, extra_data):
-        """Setup iff on a slave, run tests, then teardown iff on a slave"""
-        local_hostname = self.host
-        self.pnet_connectivity_audit_uuid = audit_uuid
-        # Only run on specified hosts
-        if local_hostname not in hosts:
-            return
-
-        # get list of master hostnames to use to check if on master
-        master_hostnames = [hostname for hostname, _ in masters]
-
-        # On masters, run separately and wait for response
-        if local_hostname not in master_hostnames:
-            self._setup_connectivity_audit(providernet,
-                                           segments, extra_data)
-
-        # Add a slight delay in case port isn't ready
-        time.sleep(2)
-
-        # Run on all nodes including masters
-        results = self._run_connectivity_audit(
-            providernet, masters, extra_data)
-
-        # On masters, run separately and wait for response
-        if local_hostname not in master_hostnames:
-            self._teardown_connectivity_audit()
-
-        # report results at the end of call
-        self._report_connectivity_results(results)
-
-    def _report_connectivity_results(self, results_list):
-        """Use RPC API to contact controller to write results to database"""
-        audit_uuid = \
-            self.pnet_connectivity_manager.pnet_connectivity_audit_uuid
-        self.pnet_connectivity_api.report_connectivity_results(self.context,
-                                                               results_list,
-                                                               audit_uuid)
-
-    def _audit_dvr_mac_addresses(self):
-        """
-        Retrieve the current list of DVR MAC addresses to make sure we have an
-        up to date copy.
-        """
-        try:
-            timestamp = int(time.time())
-            if timestamp >= self.dvr_mac_audit_timestamp:
-                self.dvr_agent.get_peer_dvr_mac_addresses()
-                self.dvr_mac_audit_timestamp = (
-                    timestamp + DVR_MAC_ADDRESS_AUDIT_INTERVAL)
-        except Exception:
-            LOG.exception("Failed to audit peer DVR MAC address list")
-
-    def _stale_fdb_loop(self):
-        """Handle any mismatches between AVS and the local FDB records."""
-        self.fdb_audit()
-
-    def daemon_loop_body(self):
-        self._audit_dvr_mac_addresses()
-        super(VSwitchNeutronAgent, self).daemon_loop_body()
-        self._stale_fdb_loop()
-
-
-class VSwitchSdnNeutronAgent(VSwitchBaseNeutronAgent,
-                             VSwitchSdnRpcCallbacksMixin):
-
-    def __init__(self,
-                 interface_mappings,
-                 polling_interval,
-                 metering_interval,
-                 status_interval,
-                 vswitch_api,
-                 enable_distributed_routing=False):
-        super(VSwitchSdnNeutronAgent, self).__init__(
-            interface_mappings,
-            polling_interval,
-            metering_interval,
-            status_interval,
-            vswitch_api,
-            enable_distributed_routing)
-
-    def _pnet_connectivity_interface_uuids(self):
-        # Feature not supported in SDN mode so always return an empty list
-        return []
-
-    def get_trunk_details(self, port_uuid):
-        # Feature not supported in SDN mode so always return no data
-        return None
-
-    def get_sfc_details(self, port_uuids, ports):
-        # Feature not supported in SDN mode so always return no data
-        return None
-
-    def _get_network_info(self, port_details):
-        """
-        Determine which network this port should be attached to.  The normal
-        case is that the network is specified by the neutron server based on
-        which tenant network the device was attached to.  For SDN all ports are
-        attached to the integration bridge (br-int).
-        """
-        network_name = cfg.CONF.SDN.integration_bridge_name
-        network_uuid = self.vswitch_mgr.get_openflow_bridge_uuid(
-            network_name)
-        return network_uuid, network_name
-
-    def _handle_new_virtual_network(self, network_name, network):
-        """
-        Handles the addition of a new tenant network in AVS.  This means that
-        we need to consult our deferred port and router interface list and
-        attach any objects that were waiting for this network.
-        """
-        # Attach all deferred ports
-        ports = copy.deepcopy(self.deferred_ports[network_name])
-        for port_uuid, data in six.iteritems(ports):
-            port_details = data['details']
-            device_owner = port_details['device_owner']
-            if is_avs_port(device_owner):
-                self.handle_updated_port(data['port'], port_details)
-            else:
-                self.handle_updated_interface(data['port'], port_details)
-            del self.deferred_ports[network_name][port_uuid]
-
-    def _process_virtual_networks(self, current_networks, previous_networks):
-        """
-        Process the list of virtual networks and handle any networks that were
-        added while we were waiting.   This should only ever pick up networks
-        that are created by the SDN controller (br-int, br-ex).
-        """
-        current = set(current_networks)
-        previous = set(previous_networks)
-        added = current - previous
-        for network_uuid in added:
-            network = current_networks[network_uuid]
-            network_name = network['name']
-            self._handle_new_virtual_network(network_name, network)
-        return current_networks
-
-    def manage_network_for_device(self, port_details):
-        # SDN no longer support both br-int and br-ex therefore all networks
-        # are managed by the SDN controller.
-        return False
-
-    def handle_removed_port(self, uuid):
-        # Run default/base actions to delete the port
-        super(VSwitchSdnNeutronAgent, self).handle_removed_port(uuid)
-        # Check whether we were waiting for a network to appear for this port
-        # or interface object.
-        for network_name in self.deferred_ports.keys():
-            ports = copy.deepcopy(self.deferred_ports[network_name])
-            for port_uuid, data in six.iteritems(ports):
-                if port_uuid == uuid:
-                    del self.deferred_ports[network_name][port_uuid]
-        return
-
-
-def _parse_physical_interface_mappings(mapping_list):
-    """Parse configuration physical_interface_mappings parameter"""
-    mappings = {}
-    for mapping in mapping_list:
-        # split in to key=value pair
-        uuid_str, networks = mapping.split('=')
-        if not uuid_str or not networks:
-            msg = "Failed to parse key=value pair \'{}\'".format(mapping)
-            LOG.error(msg)
-            raise ValueError(msg)
-        # Validate that the string is a valid UUID
-        uuidutils.is_uuid_like(uuid_str)
-        # Parse out the list of provider networks assigned to the UUID
-        for network in networks.split(':'):
-            if network in mappings:
-                msg = "Provider network {} already mapped to {}".format(
-                      network, mappings[network])
-                LOG.error(msg)
-                raise ValueError(msg)
-            mappings.update({network: uuid_str})
-    return mappings
-
-
-def _register_opts(conf):
-    conf.register_opts(avs_opts, "AVS")
-    conf.register_opts(agent_opts, "AGENT")
-    conf.register_opts(vxlan_opts, "VXLAN")
-    conf.register_opts(sdn_opts, "SDN")
-    config.register_agent_state_opts_helper(conf)
-    config.register_availability_zone_opts_helper(conf)
-    config.register_root_helper(conf)
-
-
-def main():
-    _register_opts(cfg.CONF)
-    common_config.init(sys.argv[1:])
-    common_config.setup_logging()
-
-    LOG.info("AVS Agent initializing... ")
-
-    try:
-        interface_mappings = _parse_physical_interface_mappings(
-            cfg.CONF.AGENT.physical_interface_mappings)
-    except ValueError as e:
-        LOG.error("Parsing physical_interface_mappings failed: %s."
-                  " Agent terminated!", e)
-        sys.exit(1)
-
-    enable_dvr = cfg.CONF.AGENT.enable_distributed_routing
-
-    polling_interval = cfg.CONF.AVS.polling_interval
-    metering_interval = cfg.CONF.AVS.metering_interval
-    status_interval = cfg.CONF.AVS.status_interval
-
-    vswitch_api = api.VSwitchManagementAPI()
-
-    if tsconfig.sdn_enabled.lower() == 'yes':
-        agent_class = VSwitchSdnNeutronAgent
-    else:
-        agent_class = VSwitchNeutronAgent
-
-    agent = agent_class(interface_mappings,
-                        polling_interval,
-                        metering_interval,
-                        status_interval,
-                        vswitch_api,
-                        enable_dvr)
-
-    LOG.info("AVS Agent initialized successfully")
-    agent.daemon_loop()
-    sys.exit(0)
-
-if __name__ == "__main__":
-    main()
diff --git a/neutron/plugins/wrs/agent/avs/dvr.py b/neutron/plugins/wrs/agent/avs/dvr.py
index ccacdc6..8b13789 100644
--- a/neutron/plugins/wrs/agent/avs/dvr.py
+++ b/neutron/plugins/wrs/agent/avs/dvr.py
@@ -1,300 +1 @@
-#!/usr/bin/env python
-#
-# All Rights Reserved.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-#
-# Copyright (c) 2015-2017 Wind River Systems, Inc.
-#
-# The right to copy, distribute, modify, or otherwise make use
-# of this software may be licensed only pursuant to the terms
-# of an applicable Wind River license agreement.
-#
 
-#
-#
-# Based on the structure of the OpenVSwitch DVR agent in the
-# Neutron OpenVSwitch Plugin.
-
-import netaddr
-
-import six
-
-from oslo_log import log as logging
-
-LOG = logging.getLogger(__name__)
-
-
-# A class to represent a DVR-hosted subnet including vif_ports resident on
-# that subnet
-class LocalDVRSubnetMapping(object):
-    def __init__(self, subnet):
-        # set of compute ports on on this dvr subnet
-        self.interfaces = set()
-        self.subnet = subnet
-        self.dvr_owned = False
-
-    def __str__(self):
-        return ("subnet = %s interfaces = %s is_dvr_owned = %s" %
-                (self.subnet, self.interfaces, self.is_dvr_owned()))
-
-    def get_subnet_info(self):
-        return self.subnet
-
-    def set_dvr_owned(self, owned):
-        self.dvr_owned = owned
-
-    def is_dvr_owned(self):
-        return self.dvr_owned
-
-    def add_interface(self, interface_uuid):
-        """
-        Track which interfaces belong to which DVR subnet.
-        """
-        LOG.info("DVR: adding interface {} to subnet {}".format(
-            interface_uuid, self.subnet['id']))
-        self.interfaces.add(interface_uuid)
-
-    def remove_interface(self, interface_uuid):
-        """
-        Track which ports belong to which DVR subnet.
-        """
-        LOG.info("DVR: removing interface {} from subnet {}".format(
-            interface_uuid, self.subnet['id']))
-        self.interfaces.discard(interface_uuid)
-
-
-class VswitchDVRNeutronAgent(object):
-    """
-    Implements Vswitch-based DVR(Distributed Virtual Router), for overlay
-    networks.
-    """
-    # history
-    #   1.0 Initial version
-
-    def __init__(self, context, plugin_rpc,
-                 agent,
-                 host=None,
-                 enable_distributed_routing=False):
-        self.context = context
-        self.plugin_rpc = plugin_rpc
-        self.agent = agent
-        self.host = host
-        self.enable_distributed_routing = enable_distributed_routing
-        self.local_dvr_map = {}
-        self.vswitch_mgr = None
-        self.registered_dvr_macs = {}
-        self.dvr_mac_address = None
-
-    def register_manager(self, manager):
-        self.vswitch_mgr = manager
-
-    @staticmethod
-    def _format_mac_avs(mac_address):
-        return str(netaddr.EUI(mac_address, dialect=netaddr.mac_unix_expanded))
-
-    def get_peer_dvr_mac_addresses(self):
-        """Find our local unique mac address as well as those of other hosts"""
-        # get the list of local/unique DVR MAC addresses
-        dvr_mac_list = self.plugin_rpc.get_dvr_mac_address_list(self.context)
-        LOG.debug("DVR: Server returned these local/unique "
-                  "MAC addresses {}".format(dvr_mac_list))
-        # parse the list and store a copy of the results
-        current_dvr_macs = {}
-        for mac in dvr_mac_list:
-            if mac['host'] == self.host:
-                continue
-            current_dvr_macs[mac['host']] = mac['mac_address']
-        # Update the cached copy and log any changes
-        self._update_peer_dvr_mac_addresses(current_dvr_macs)
-        # Send an update to AVS with the updated list
-        self._configure_avs_host_macs()
-
-    def get_dvr_mac_address(self):
-        """
-        Return the cached copy of our local unique MAC address or fetch it
-        from the server if we have not yet retrieved it.
-        """
-        if self.dvr_mac_address is None:
-            details = self.plugin_rpc.get_dvr_mac_address_by_host(
-                self.context, self.host)
-            LOG.info("DVR: local MAC address for host {} is {}".format(
-                self.host, details['mac_address']))
-            self.dvr_mac_address = self._format_mac_avs(details['mac_address'])
-        return self.dvr_mac_address
-
-    def _get_interfaces_on_dvr_subnet(self, subnet_uuid):
-        ldm = self.local_dvr_map[subnet_uuid]
-        return list(ldm.interfaces)
-
-    def _get_local_interfaces_on_host_by_subnet(self, subnet):
-        local_ports = self.agent.get_ports_on_dvr_subnet(subnet['id'])
-        LOG.info("DVR: subnet {} local ports {}".format(
-            subnet['id'], local_ports))
-        return local_ports
-
-    def _get_peer_mac_addresses(self):
-        return [{'hostname': k, 'mac-address': self._format_mac_avs(v)}
-                for k, v in six.iteritems(self.registered_dvr_macs)]
-
-    def _configure_avs_host_macs(self):
-        """
-        Update AVS with the list of known/unique MAC addresses.
-        """
-        dvr_peer_mac_addresses = self._get_peer_mac_addresses()
-        LOG.debug("DVR: configuring AVS with known/unique "
-                  "MAC addresses: {}".format(dvr_peer_mac_addresses))
-        self.vswitch_mgr.update_dvr_host_macs(dvr_peer_mac_addresses)
-
-    def _configure_avs_router_interface(self, interface_uuid,
-                                        subnet_uuid, gateway_ip):
-        """
-        Update the AVS AVR interface to configure it with DVR subnet
-        information.
-        """
-        dvr_interface_uuids = self._get_interfaces_on_dvr_subnet(subnet_uuid)
-        params = {'dvr-router-info':
-                  {'dvr-mac-address': self.get_dvr_mac_address(),
-                   'dvr-subnet-id': subnet_uuid,
-                   'dvr-ip-address': gateway_ip,
-                   'dvr-interfaces': dvr_interface_uuids}}
-        LOG.info("DVR: configuring router interface {} with {}".format(
-            interface_uuid, params))
-        self.vswitch_mgr.update_interface(interface_uuid, params)
-
-    def _configure_avs_interface(self, interface_uuid, subnet_uuid):
-        """
-        Update the AVS interface to configure it against the DVR enabled
-        subnet specified by subnet_uuid
-        """
-        params = {'dvr-interface-info':
-                  {'dvr-subnet-id': subnet_uuid}}
-        LOG.info("DVR: configuring interface {} with {}".format(
-            interface_uuid, params))
-        self.vswitch_mgr.update_interface(interface_uuid, params)
-
-    @staticmethod
-    def _find_subnet_details(subnet_uuid, port_details):
-        for s in port_details['subnets']:
-            subnet = s['subnet']
-            if subnet['id'] == subnet_uuid:
-                return subnet
-        return None
-
-    def bind_router_interface_to_dvr(self, interface_uuid, port_details):
-        """
-        Track which DVR subnet this router is attached to.
-        """
-        if not self.enable_distributed_routing:
-            return
-        # Router interfaces are only associated to a single subnet
-        fixed_ips = port_details['fixed_ips']
-        fixed_ip = fixed_ips[0]
-        subnet_uuid = fixed_ip['subnet_id']
-        gateway_ip = fixed_ip['ip_address']
-        LOG.info("DVR: binding router interface {} "
-                 "with IP {} on subnet {}".
-                 format(interface_uuid, gateway_ip, subnet_uuid))
-        if subnet_uuid in self.local_dvr_map:
-            ldm = self.local_dvr_map[subnet_uuid]
-        else:
-            # set up LocalDVRSubnetMapping available for this subnet
-            subnet_info = self._find_subnet_details(subnet_uuid, port_details)
-            if not subnet_info:
-                LOG.error("DVR: Unable to retrieve subnet information"
-                          " for subnet_id %s", subnet_uuid)
-                return
-            ldm = LocalDVRSubnetMapping(subnet_info)
-            self.local_dvr_map[subnet_uuid] = ldm
-        ldm.set_dvr_owned(True)
-        subnet_info = ldm.get_subnet_info()
-        # Fetch the current interfaces that hosted locally
-        local_interfaces = self._get_local_interfaces_on_host_by_subnet(
-            subnet_info)
-        for local_uuid in local_interfaces:
-            ldm.add_interface(local_uuid)
-        self._configure_avs_router_interface(
-            interface_uuid, subnet_uuid, gateway_ip)
-
-    def bind_interface_to_dvr(self, interface_uuid, port_details):
-        """
-        Track which DVR subnets this interface belongs to.
-        """
-        if not self.enable_distributed_routing:
-            return
-        fixed_subnet_list = self.agent.get_fixed_subnet_ids(port_details)
-        subnets = port_details.get('subnets', [])
-        for s in subnets:
-            subnet_uuid = s['subnet']['id']
-            if subnet_uuid not in fixed_subnet_list:
-                LOG.debug("DVR: interface {} has no IP in subnet {}; ignoring".
-                          format(interface_uuid, subnet_uuid))
-                continue
-            if subnet_uuid not in self.local_dvr_map:
-                LOG.debug("DVR: subnet {} not DVR enabled ignoring {}".format(
-                    subnet_uuid, interface_uuid))
-                continue
-            ldm = self.local_dvr_map[subnet_uuid]
-            if not ldm.is_dvr_owned():
-                LOG.debug("DVR: subnet {} not owned by DVR router {}".format(
-                    subnet_uuid, interface_uuid))
-                continue
-            ldm.add_interface(interface_uuid)
-            self._configure_avs_interface(interface_uuid, subnet_uuid)
-            # Stop at first DVR enabled subnet
-            return
-
-    def _update_peer_dvr_mac_addresses(self, current_dvr_macs):
-        if current_dvr_macs == self.registered_dvr_macs:
-            LOG.debug("DVR: MAC address list is already up to date")
-            return
-        existing_hosts = set(self.registered_dvr_macs.keys())
-        current_hosts = set(current_dvr_macs.keys())
-        # Calculate which hosts have been added/removed/updated
-        added = current_hosts - existing_hosts
-        removed = existing_hosts - current_hosts
-        updated = existing_hosts & current_hosts
-        # Update the stored MAC address list
-        for host in removed:
-            LOG.info("DVR: Removed unique MAC address {}={}".format(
-                host, self.registered_dvr_macs[host]))
-            self.registered_dvr_macs.pop(host, None)
-        for host in added:
-            LOG.info("DVR: Added unique MAC address {}={}".format(
-                host, current_dvr_macs[host]))
-            self.registered_dvr_macs[host] = current_dvr_macs[host]
-        for host in updated:
-            if current_dvr_macs[host] != self.registered_dvr_macs[host]:
-                LOG.info("DVR: Updated unique MAC address {}={}; "
-                         "previous was {}".format(
-                             host, current_dvr_macs[host],
-                             self.registered_dvr_macs[host]))
-                self.registered_dvr_macs[host] = current_dvr_macs[host]
-
-    def dvr_mac_address_update(self, dvr_macs):
-        """
-        Receive an updated list of unique host MAC addresses from the server
-        via RPC.  The server sends the full list whenever any one MAC changes.
-        """
-        if not self.enable_distributed_routing:
-            return
-        LOG.info("DVR: peer MAC address update: {}".format(dvr_macs))
-        current_dvr_macs = {}
-        for entry in dvr_macs:
-            if entry['host'] == self.host:
-                continue
-            current_dvr_macs[entry['host']] = entry['mac_address']
-        # Update the cached copy and log any changes
-        self._update_peer_dvr_mac_addresses(current_dvr_macs)
-        # Send an update to AVS with the updated list
-        self._configure_avs_host_macs()
diff --git a/neutron/plugins/wrs/agent/avs/sfc.py b/neutron/plugins/wrs/agent/avs/sfc.py
index 7fe1a8d..8b13789 100644
--- a/neutron/plugins/wrs/agent/avs/sfc.py
+++ b/neutron/plugins/wrs/agent/avs/sfc.py
@@ -1,114 +1 @@
-#!/usr/bin/env python
-#
-# All Rights Reserved.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-#
-# Copyright (c) 2017 Wind River Systems, Inc.
-#
-# The right to copy, distribute, modify, or otherwise make use
-# of this software may be licensed only pursuant to the terms
-# of an applicable Wind River license agreement.
-#
 
-from oslo_config import cfg
-from oslo_log import log as logging
-import oslo_messaging
-
-from networking_sfc.services.sfc.agent.extensions.vswitch import sfc_driver
-from networking_sfc.services.sfc.drivers.avs import rpc_topics as sfc_topics
-
-from neutron.agent import rpc as agent_rpc
-from neutron.common import rpc as n_rpc
-from neutron.common import topics
-
-LOG = logging.getLogger(__name__)
-
-
-class SfcPluginApi(object):
-    def __init__(self, topic, host):
-        self.host = host
-        self.target = oslo_messaging.Target(topic=topic, version='1.0')
-        self.client = n_rpc.get_client(self.target)
-
-    def get_sfc_details(self, context, port_ids):
-        cctxt = self.client.prepare()
-        return cctxt.call(
-            context, 'get_sfc_details',
-            port_ids=port_ids)
-
-
-class VswitchSFCNeutronAgent(object):
-    """
-    Implements Vswitch-based SFC(Service Function Chaining).
-    """
-    # history
-    #   1.0 Initial version
-
-    def __init__(self, context,
-                 agent,
-                 host=None):
-        self.context = context
-        self.agent = agent
-        self.host = host
-        self.vswitch_mgr = None
-        self.sfc_driver = sfc_driver.SfcAVSAgentDriver()
-        self._sfc_setup_rpc()
-        self.paths = []
-        self.init = True
-
-    def register_manager(self, manager):
-        self.vswitch_mgr = manager
-        self.sfc_driver.consume_api(self.vswitch_mgr)
-
-    def get_sfc_details(self, port_ids):
-        if self.init or len(self.paths) > 0:
-            self.sfc_plugin_rpc.get_sfc_details(self.context, port_ids)
-            self.init = False
-
-    def _sfc_setup_rpc(self):
-        self.sfc_plugin_rpc = SfcPluginApi(
-            sfc_topics.SFC_PLUGIN, cfg.CONF.host)
-
-        self.topic = sfc_topics.SFC_AGENT
-        self.endpoints = [self]
-        consumers = [
-            [sfc_topics.SERVICEPATH, topics.UPDATE],
-            [sfc_topics.SERVICEPATH, topics.DELETE],
-            [sfc_topics.CLASSIFIER, topics.UPDATE],
-            [sfc_topics.CLASSIFIER, topics.DELETE]
-        ]
-
-        # subscribe sfc plugin message
-        self.connection = agent_rpc.create_consumers(
-            self.endpoints,
-            self.topic,
-            consumers)
-
-    def update_service_paths(self, context, **kwargs):
-        paths = kwargs['service_paths']
-        self.sfc_driver.update_service_paths(paths)
-        self.paths = [path.id for path in self.sfc_driver.get_service_paths()]
-
-    def update_classifiers(self, context, **kwargs):
-        fcs = kwargs['classifiers']
-        self.sfc_driver.update_classifiers(fcs)
-
-    def delete_service_paths(self, context, **kwargs):
-        paths = kwargs['service_paths']
-        self.sfc_driver.delete_service_paths(paths)
-        self.paths = [path.id for path in self.sfc_driver.get_service_paths()]
-
-    def delete_classifiers(self, context, **kwargs):
-        fcs = kwargs['classifiers']
-        self.sfc_driver.delete_classifiers(fcs)
diff --git a/neutron/plugins/wrs/drivers/firewall.py b/neutron/plugins/wrs/drivers/firewall.py
deleted file mode 100644
index 00754cd..0000000
--- a/neutron/plugins/wrs/drivers/firewall.py
+++ /dev/null
@@ -1,174 +0,0 @@
-# Copyright (c) 2014 OpenStack Foundation
-# All Rights Reserved.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-#
-# Copyright (c) 2013-2014 Wind River Systems, Inc.
-#
-# The right to copy, distribute, modify, or otherwise make use
-# of this software may be licensed only pursuant to the terms
-# of an applicable Wind River license agreement.
-#
-
-import uuid
-
-import netaddr
-
-from oslo_log import log as logging
-
-from neutron.agent import firewall
-from neutron_lib import constants as n_const
-
-LOG = logging.getLogger(__name__)
-
-DIRECTION_IP_PREFIX = {'ingress': 'source_ip_prefix',
-                       'egress': 'dest_ip_prefix'}
-
-METADATA_DEFAULT_PREFIX = 32
-METADATA_DEFAULT_IP = '169.254.169.254'
-METADATA_DEFAULT_CIDR = '%s/%d' % (METADATA_DEFAULT_IP,
-                                   METADATA_DEFAULT_PREFIX)
-METADATA_DEFAULT_PORT = 80
-
-
-class VSwitchFirewallDriver(firewall.FirewallDriver):
-    """VSwitch Firewall Driver."""
-
-    vswitch_mgr = None
-
-    def __init__(self):
-        # list of port which has security groups
-        self.filtered_ports = {}
-
-    def add_ingress_metadata_rule(self, port):
-        rule = {'direction': 'ingress',
-                'ethertype': n_const.IPv4,
-                'protocol': 'tcp',
-                'source_ip_prefix': METADATA_DEFAULT_CIDR,
-                'port_range_min': METADATA_DEFAULT_PORT,
-                'port_range_max': METADATA_DEFAULT_PORT}
-        #Required to avoid duplicates of rule
-        if rule not in port['security_group_rules']:
-            port['security_group_rules'].append(rule)
-
-    def register_manager(self, manager):
-        self.vswitch_mgr = manager
-
-    def update_security_group_rules(self, sg_id, sg_rules):
-        LOG.debug("Update rules of security group (%s)", sg_id)
-
-    def update_security_group_members(self, sg_id, sg_members):
-        LOG.debug("Update members of security group (%s)", sg_id)
-
-    def prepare_port_filter(self, port):
-        LOG.debug("Preparing port (%s) filter", port['device'])
-        self.filtered_ports[port['device']] = port
-        self._update_port_rules(port)
-
-    def update_port_filter(self, port):
-        LOG.debug("Update port (%s) filter", port['device'])
-        self.filtered_ports[port['device']] = port
-        self._update_port_rules(port)
-
-    def remove_port_filter(self, port):
-        LOG.debug("Remove port (%s) filter", port['device'])
-        self.filtered_ports.pop(port['device'], None)
-        self._remove_port_rules(port)
-
-    @property
-    def ports(self):
-        return self.filtered_ports
-
-    def _update_port_rules(self, port):
-        rules = []
-        if port['security_group_rules']:
-            self.add_ingress_metadata_rule(port)
-        for sg_rule in port['security_group_rules']:
-            rules.append(self._convert_security_group_rule(sg_rule))
-        self.vswitch_mgr.update_port_filters(port['id'], rules)
-
-    def _remove_port_rules(self, port):
-        rules = []
-        for sg_rule in port['security_group_rules']:
-            rules.append({'uuid': sg_rule['id']})
-        self.vswitch_mgr.remove_port_filters(port['id'], rules)
-
-    @classmethod
-    def _convert_security_group_rule(cls, sg_rule):
-
-        # build match criteria
-        direction = str(sg_rule.get('direction')).lower()
-        ethertype = str(sg_rule.get('ethertype')).lower()
-
-        match = {
-            "direction": direction,
-            "ethernet": {
-                "type-name": ethertype
-            }
-        }
-
-        ip_protocol = sg_rule.get('protocol', None)
-        ip_prefix = sg_rule.get(DIRECTION_IP_PREFIX[direction], None)
-        if ip_protocol or ip_prefix:
-            match['ip'] = {}
-            if ip_protocol:
-                if ip_protocol in ["tcp", "udp"]:
-                    match['ip']['protocol-name'] = ip_protocol
-
-                    # setup destination port range
-                    port_min = sg_rule.get('port_range_min', None)
-                    port_max = sg_rule.get('port_range_max', None)
-                    if port_min is not None:
-                        match.setdefault(ip_protocol, {})
-                        match[ip_protocol]['dst-port-min'] = port_min
-                    if port_max is not None:
-                        match.setdefault(ip_protocol, {})
-                        match[ip_protocol]['dst-port-max'] = port_max
-
-                elif ip_protocol == "icmp":
-                    if ethertype == n_const.IPv4.lower():
-                        match['ip']['protocol-name'] = "icmpv4"
-                    else:
-                        match['ip']['protocol-name'] = "icmpv6"
-
-                    # setup icmp type/code (stored in min/max range field)
-                    icmp_type = sg_rule.get('port_range_min', None)
-                    icmp_code = sg_rule.get('port_range_max', None)
-                    if (icmp_type is not None) and (icmp_code is not None):
-                        match['icmp'] = {
-                            'type': icmp_type,
-                            'code': icmp_code
-                        }
-                else:
-                    # custom protocol, if it is not valid, then an exception
-                    # will be raised
-                    match['ip']['protocol-value'] = int(ip_protocol)
-
-            if ip_prefix:
-                ip_network = netaddr.IPNetwork(ip_prefix)
-                match['ip']['remote-network'] = {
-                    'family': 'ipv{}'.format(ip_network.version),
-                    'prefix-length': ip_network.prefixlen,
-                    'address': str(ip_network.ip)
-                }
-
-        # generate a unique rule identifier for generated rule
-        rule_id = str(uuid.uuid5(uuid.NAMESPACE_OID,
-                                 str(match).encode('utf-8')))
-        sg_rule['id'] = rule_id
-
-        rule = {"uuid": rule_id, "match": match}
-
-        LOG.debug("sg_rule {} converted to rule {}".format(sg_rule, rule))
-
-        return rule
diff --git a/neutron/plugins/wrs/drivers/fm.py b/neutron/plugins/wrs/drivers/fm.py
index a33a121..d73f3be 100644
--- a/neutron/plugins/wrs/drivers/fm.py
+++ b/neutron/plugins/wrs/drivers/fm.py
@@ -99,21 +99,6 @@ class DefaultFmDriver(fm.FmDriver):
                                     agent_id)
 
     @staticmethod
-    def _get_bgp_peer_entity_type_id():
-        return "{}.{}.{}".format(fm_constants.FM_ENTITY_TYPE_HOST,
-                                 fm_constants.FM_ENTITY_TYPE_AGENT,
-                                 fm_constants.FM_ENTITY_TYPE_BGP_PEER)
-
-    @staticmethod
-    def _get_bgp_peer_entity_instance_id(host_id, agent_id, bgp_peer_id):
-        return "{}={}.{}={}.{}={}".format(fm_constants.FM_ENTITY_TYPE_HOST,
-                                          host_id,
-                                          fm_constants.FM_ENTITY_TYPE_AGENT,
-                                          agent_id,
-                                          fm_constants.FM_ENTITY_TYPE_BGP_PEER,
-                                          bgp_peer_id)
-
-    @staticmethod
     def _get_ml2_driver_entity_type_id():
         return "{}.{}".format(fm_constants.FM_ENTITY_TYPE_HOST,
                               fm_constants.FM_ENTITY_TYPE_ML2DRIVER)
@@ -298,44 +283,6 @@ class DefaultFmDriver(fm.FmDriver):
                                                                 agent_id)
         self.fm_api.clear_fault(fm_constants.FM_ALARM_ID_NETWORK_AGENT,
                                 entity_instance_id)
-        self.fm_api.clear_all("%s.bgp-peer" % entity_instance_id)
-
-    def report_bgp_peer_down_fault(self, host_id, agent_id, bgp_peer_id):
-        """
-        Generate a fault management alarm condition for BGP peer down
-        """
-        entity_type_id = self._get_bgp_peer_entity_type_id()
-        entity_instance_id = self._get_bgp_peer_entity_instance_id(host_id,
-                                                                   agent_id,
-                                                                   bgp_peer_id)
-        reason_text = (_("Dynamic routing agent %(agent_id)s lost connectivity"
-                         " to peer %(bgp_peer_id)s.") %
-                       {"agent_id": agent_id, "bgp_peer_id": bgp_peer_id})
-
-        fault = fm_api.Fault(
-            alarm_id=fm_constants.FM_ALARM_ID_NETWORK_BGP_PEER,
-            alarm_state=fm_constants.FM_ALARM_STATE_SET,
-            entity_type_id=entity_type_id,
-            entity_instance_id=entity_instance_id,
-            severity=fm_constants.FM_ALARM_SEVERITY_MAJOR,
-            reason_text=reason_text,
-            alarm_type=fm_constants.FM_ALARM_TYPE_7,
-            probable_cause=fm_constants.ALARM_PROBABLE_CAUSE_55,
-            proposed_repair_action=(
-                _("If condition persists, fix connectivity to peer.")),
-            service_affecting=True,
-            suppression=True)
-        self.fm_api.set_fault(fault)
-
-    def clear_bgp_peer_down_fault(self, host_id, agent_id, bgp_peer_id):
-        """
-        Clear a fault management alarm condition for BGP peer down
-        """
-        entity_instance_id = self._get_bgp_peer_entity_instance_id(host_id,
-                                                                   agent_id,
-                                                                   bgp_peer_id)
-        self.fm_api.clear_fault(fm_constants.FM_ALARM_ID_NETWORK_BGP_PEER,
-                                entity_instance_id)
 
     def report_ml2_driver_fault(self, hostname, driver, reason):
         """
diff --git a/setup.cfg b/setup.cfg
index 8c62faa..c434412 100644
--- a/setup.cfg
+++ b/setup.cfg
@@ -149,7 +149,6 @@ oslo.config.opts =
     neutron.ml2.sriov.agent = neutron.opts:list_sriov_agent_opts
     neutron.ml2.xenapi = neutron.opts:list_xenapi_opts
     neutron.settings = neutron.opts:list_settings_opts
-    neutron.avs.agent = neutron.opts:list_avs_agent_opts
     nova.auth = neutron.opts:list_auth_opts
 oslo.config.opts.defaults =
     neutron = neutron.common.config:set_cors_middleware_defaults
-- 
2.7.4

